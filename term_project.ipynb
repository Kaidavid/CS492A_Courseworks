{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kaidavid/CS492A_Courseworks/blob/master/term_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTvx5gsbV7kn"
      },
      "source": [
        "# **GPU and RAM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUED00mlWAX5",
        "outputId": "b68caf8c-cb31-4b76-ee89-5915a04414ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jun  4 13:15:46 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoGvPxGPsJ1Y"
      },
      "source": [
        "# **Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_EvqD_kTSnaa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "import copy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "from datetime import timedelta\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from tensorflow import keras\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score\n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Mount G-Drive**"
      ],
      "metadata": {
        "id": "KTECLf2mHy4U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xp7XdgdZBQkg",
        "outputId": "64490d81-3edc-4189-d98d-ad32879eae61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "'8m 21s node_embedding1_connected.csv'\t test_classification_question.csv\n",
            " description.pdf\t\t\t test_completion_question.csv\n",
            " node_ingredient.csv\t\t\t train.csv\n",
            " report_template\t\t\t validation_classification_answer.csv\n",
            " report_template.zip\t\t\t validation_classification_question.csv\n",
            " results\t\t\t\t validation_completion_answer.csv\n",
            " term_project.ipynb\t\t\t validation_completion_question.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/gdrive')\n",
        "# Specify the directory path where `term_project.ipynb` exists.\n",
        "# then set root = '/gdrive/My Drive/Data Mining/project'\n",
        "\n",
        "root = '/gdrive/My Drive/Data Mining/project'\n",
        "### Change the working directory to root ###\n",
        "os.chdir(root)\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SKlRDxPsZRq"
      },
      "source": [
        "# **Installation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrxnBWlLo7-r"
      },
      "outputs": [],
      "source": [
        "# !pip install torchtext==0.11.0\n",
        "# !pip install torch==1.10.0+cu111 torchvision==0.11.0+cu111 torchaudio==0.10.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab6NmYXSnXow"
      },
      "outputs": [],
      "source": [
        "# def format_pytorch_version(version):\n",
        "#     return version.split('+')[0]\n",
        "\n",
        "# def format_cuda_version(version):\n",
        "#     return 'cu' + version.replace('.', '')\n",
        "\n",
        "# TORCH_version = torch.__version__\n",
        "# TORCH = format_pytorch_version(TORCH_version)\n",
        "# CUDA_version = torch.version.cuda\n",
        "# CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "# !pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "# !pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "# !pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "# !pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "# !pip install torch-geometric\n",
        "# !pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVK7X8WYsdrd"
      },
      "outputs": [],
      "source": [
        "# import torch_geometric\n",
        "# import torch_geometric.transforms as T\n",
        "# from torch_geometric.utils import to_networkx\n",
        "# from torch_geometric.data import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-_7I9HO9lUeb"
      },
      "outputs": [],
      "source": [
        "!pip install -q stellargraph[demos]==1.2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6OlMsUI9lY_7"
      },
      "outputs": [],
      "source": [
        "import stellargraph as sg\n",
        "from stellargraph.data import BiasedRandomWalk\n",
        "from stellargraph.data import UnsupervisedSampler"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Helper Functions**"
      ],
      "metadata": {
        "id": "a-gftenuH2Xe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Mb4cp8g9RA-1"
      },
      "outputs": [],
      "source": [
        "def get_ingredient_name(ing_ids):\n",
        "  if ing_ids == None:\n",
        "    return None\n",
        "  \n",
        "  with open (\"node_ingredient.csv\", \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "    if type(ing_ids) == list:\n",
        "      # make sure they are numeric values\n",
        "      for id in ing_ids:\n",
        "        if not id.isnumeric():\n",
        "          return\n",
        "      return [lines[int(x)].strip() for x in ing_ids]\n",
        "    else:\n",
        "      if not ing_ids.isnumeric():\n",
        "          return\n",
        "      return lines[int(ing_ids)].strip()\n",
        "\n",
        "\n",
        "def get_unused_ingredient(arr):\n",
        "  unused = np.nonzero(np.sum(arr, axis=1)== 0)[0].tolist()\n",
        "  unused = [str(idx) for idx in unused]\n",
        "  return get_ingredient_name(unused)\n",
        "\n",
        "\n",
        "def data_info(path, index):\n",
        "  with open (path, \"r\") as f:\n",
        "    data = f.readlines()\n",
        "    if index >= len(data):\n",
        "      return \"Index out of bound\"\n",
        "    value = data[index].strip().split(\",\")\n",
        "    label = None\n",
        "    missing = None\n",
        "    \n",
        "    if path == \"train.csv\":\n",
        "      label = value.pop()\n",
        "\n",
        "    elif path == \"validation_classification_question.csv\":\n",
        "      label = \"Found in validation_classification_answer.csv\"\n",
        "    elif path == \"validation_classification_answer.csv\":\n",
        "      label = value[0]\n",
        "      value = \"Found in validation_classification_question.csv\"\n",
        "    elif path == \"test_classification_question.csv\":\n",
        "      label = \"?????\"\n",
        "\n",
        "    elif path == \"validation_completion_question.csv\":\n",
        "      missing = \"Found in validation_completion_answer.csv\"\n",
        "    elif path == \"validation_completion_answer.csv\":\n",
        "      missing = value[0]\n",
        "      value = \"Found in validation_completion_question.csv\"\n",
        "    elif path == \"test_completion_question.csv\":\n",
        "      missing = \"?????\"\n",
        "    else:\n",
        "      return \"Wrong input path\"\n",
        "    \n",
        "    if type(value) == list and type(value[0]) == int:\n",
        "      value = [int(x) for x in value]\n",
        "    print(f\"Recipe Number: {index}/{len(data)} from {path}\")\n",
        "    print(f\"Recipe Origin: {label}\")\n",
        "    print(f\"Missing ingredient: ID = {missing}, Name = {get_ingredient_name(missing)}\")\n",
        "    print(f\"Ingredients ID: {value}\")\n",
        "    print(f\"Ingredients Name: {get_ingredient_name(value)}\")\n",
        "\n",
        "\n",
        "def node_feature_pair(node_features):\n",
        "  pair = {}\n",
        "  for i in range(node_features.shape[0]):\n",
        "    pair[i] = node_features[i].tolist()\n",
        "  return pair\n",
        "\n",
        "\n",
        "def connected_graph(arr):\n",
        "  edges = []\n",
        "  for i in range(len(arr) - 1):\n",
        "    edges.append((arr[i], arr[i+1]))\n",
        "  edges.append((arr[-1], arr[0]))\n",
        "  return edges"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_info(\"validation_completion_question.csv\", 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdvqSOQcClUI",
        "outputId": "d6480456-7b95-431f-e75d-d27d7bc1865d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recipe Number: 100/7848 from validation_completion_question.csv\n",
            "Recipe Origin: None\n",
            "Missing ingredient: ID = Found in validation_completion_answer.csv, Name = None\n",
            "Ingredients ID: ['167', '281', '791', '909', '1308', '1953', '2651', '2945', '5379', '5418', '6187']\n",
            "Ingredients Name: ['vegetable oil', 'flour', 'flank steak', 'baking soda', 'sugar', 'corn starch', 'brown sugar', 'water', 'broccoli', 'low sodium soy sauce', 'garlic']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7VcttYAaNAD"
      },
      "source": [
        "# **Node Featurizing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "2yPsEYKSXE3R"
      },
      "outputs": [],
      "source": [
        "from easydict import EasyDict\n",
        "from pathlib import Path\n",
        "\n",
        "args = EasyDict()\n",
        "args.dim = 20\n",
        "args.walk_number = 10   # number of random walks per root node\n",
        "args.walk_length = 30    # maximum length of a random walk 50\n",
        "\n",
        "args.batch_size = 64\n",
        "args.lr = 1e-3\n",
        "args.momentum = 0.9\n",
        "args.weight_decay = 5e-4\n",
        "args.epoch = 4\n",
        "args.epoch_ = 100\n",
        "args.random = 30\n",
        "args.graph_method = \"complete\"\n",
        "args.tensorboard = True\n",
        "args.gpu = True\n",
        "args.b1 = 0.5\n",
        "args.b2 = 0.999\n",
        "args.pred_dim = 128\n",
        "args.pred_epochs = 50\n",
        "args.pred_lr = 1e-5\n",
        "args.latent_dim = 100\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() and args.gpu else 'cpu'\n",
        "\n",
        "results = Path(root) / 'results'\n",
        "results.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "labels = {\n",
        "    'brazilian': 0, 'british': 1, 'cajun_creole': 2, 'chinese': 3, 'filipino': 4, 'french': 5, 'greek': 6, 'indian': 7, 'irish': 8, 'italian': 9, 'jamaican': 10,\n",
        "    'japanese': 11, 'korean': 12, 'mexican': 13, 'moroccan': 14, 'russian': 15, 'southern_us': 16, 'spanish': 17, 'thai': 18, 'vietnamese': 19\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_graph(labels, graph_method, randomize=False):\n",
        "  G = nx.Graph()\n",
        "  \n",
        "  #   Create node feature array\n",
        "  with open (\"node_ingredient.csv\", \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "    node_feature = np.zeros((len(lines), len(labels)))\n",
        "  \n",
        "  #   Create graph from training data\n",
        "  with open (\"train.csv\", \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "    random_recipes = sorted(random.sample(range(0, len(lines)), args.random)) if randomize else [i for i in range(len(lines))]\n",
        "    if graph_method == \"connected\":\n",
        "      for num in random_recipes:\n",
        "        recipe = lines[num].strip().split(\",\")\n",
        "        label = recipe.pop()\n",
        "        recipe = [int(x) for x in recipe]\n",
        "        \n",
        "        #   Create a complete graph between the ingredients in one cuisine and add them to the main graph G\n",
        "        G.add_edges_from(connected_graph(recipe))\n",
        "\n",
        "        #   Each node (ingredient) will be featurized by the countries (labels) its used at\n",
        "        for ingredient in recipe:\n",
        "          node_feature[ingredient, labels[label]] += 1\n",
        "    elif graph_method == \"complete\":\n",
        "      for num in random_recipes:\n",
        "        recipe = lines[num].strip().split(\",\")\n",
        "        label = recipe.pop()\n",
        "        recipe = [int(x) for x in recipe]\n",
        "        \n",
        "        #   Create a complete graph between the ingredients in one cuisine and add them to the main graph G\n",
        "        G.add_edges_from(list(nx.complete_graph(recipe).edges))\n",
        "\n",
        "        #   Each node (ingredient) will be featurized by the countries (labels) its used at\n",
        "        for ingredient in recipe:\n",
        "          node_feature[ingredient, labels[label]] += 1\n",
        "  \n",
        "  #   Include validation data in the graph\n",
        "  with open (\"validation_classification_answer.csv\", \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "    val_clf_answer = []\n",
        "    for line in lines:\n",
        "      val_clf_answer.append(line.strip())\n",
        "\n",
        "  with open (\"validation_classification_question.csv\", \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "    random_recipes = sorted(random.sample(range(0, len(lines)), args.random//2)) if randomize else [i for i in range(len(lines))]\n",
        "    if graph_method == \"connected\":\n",
        "      for num in random_recipes:\n",
        "        recipe = lines[num].strip().split(\",\")\n",
        "        recipe = [int(x) for x in recipe]\n",
        "        label = val_clf_answer[num]\n",
        "        \n",
        "        #   Create a complete graph between the ingredients in one cuisine and add them to the main graph G\n",
        "        G.add_edges_from(connected_graph(recipe))\n",
        "\n",
        "        #   Each node (ingredient) will be featurized by the countries (labels) its used at\n",
        "        for ingredient in recipe:\n",
        "          node_feature[ingredient, labels[label]] += 1\n",
        "\n",
        "    elif graph_method == \"complete\":\n",
        "      for num in random_recipes:\n",
        "        recipe = lines[num].strip().split(\",\")\n",
        "        recipe = [int(x) for x in recipe]\n",
        "        label = val_clf_answer[num]\n",
        "        \n",
        "        #   Create a complete graph between the ingredients in one cuisine and add them to the main graph G\n",
        "        G.add_edges_from(list(nx.complete_graph(recipe).edges))\n",
        "\n",
        "        #   Each node (ingredient) will be featurized by the countries (labels) its used at\n",
        "        for ingredient in recipe:\n",
        "          node_feature[ingredient, labels[label]] += 1\n",
        "  \n",
        "  #   Include unused ingredients as nodes with 0 degrees\n",
        "  unused = np.nonzero(np.sum(node_feature, axis=1) == 0)[0].tolist()\n",
        "  G.add_nodes_from(unused)\n",
        "\n",
        "  return G, node_feature"
      ],
      "metadata": {
        "id": "7nk7hjjYGqAH"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G, node_features = create_graph(labels, args.graph_method)"
      ],
      "metadata": {
        "id": "P5Q3xeTvCmRL"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "1fODnPzU9ylP"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler().fit(node_features)\n",
        "scaled_node_features = scaler.transform(node_features)\n",
        "df = pd.DataFrame(scaled_node_features, columns = labels.keys())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of Node: \", G.number_of_nodes())\n",
        "print(f\"Number of Edges: \", G.number_of_edges())\n",
        "print(f\"Top10 Nodes with highest degree (Ingredient, Dishes): \", sorted(G.degree, key=lambda x: x[1], reverse=True)[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxFcNQObECv2",
        "outputId": "2266b20b-0d16-4d10-ca0b-302ce52cead8"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Node:  6714\n",
            "Number of Edges:  421566\n",
            "Top10 Nodes with highest degree (Ingredient, Dishes):  [(937, 4537), (2945, 3593), (5536, 3386), (6187, 3285), (1308, 3186), (5377, 3182), (2122, 2984), (2518, 2809), (167, 2784), (5648, 2716)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBxioxaEO_dp",
        "outputId": "ece89516-ef25-4f52-9272-135ff31aac65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most used ingredient of each country (Dishes, Ingredient, Country):  [(152.0, 'salt', 'brazilian'), (329.0, 'salt', 'british'), (580.0, 'salt', 'cajun_creole'), (1083.0, 'soy sauce', 'chinese'), (338.0, 'salt', 'filipino'), (960.0, 'salt', 'french'), (446.0, 'salt', 'greek'), (1514.0, 'salt', 'indian'), (297.0, 'salt', 'irish'), (2741.0, 'salt', 'italian'), (252.0, 'salt', 'jamaican'), (438.0, 'soy sauce', 'japanese'), (317.0, 'soy sauce', 'korean'), (2155.0, 'salt', 'mexican'), (331.0, 'olive oil', 'moroccan'), (233.0, 'salt', 'russian'), (1773.0, 'salt', 'southern_us'), (360.0, 'salt', 'spanish'), (480.0, 'fish sauce', 'thai'), (321.0, 'fish sauce', 'vietnamese')]\n"
          ]
        }
      ],
      "source": [
        "x = list(zip(np.max(node_features, axis=0), get_ingredient_name([str(idx) for idx in list(np.argmax(node_features, axis=0))]), labels.keys()))\n",
        "print(f\"Most used ingredient of each country (Dishes, Ingredient, Country): \", x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdDJ9JT6-s3Q",
        "outputId": "c112b5d2-b565-4493-afca-cc26f44c35c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Out of 6714 ingredients 410 ingredients are not used in any of the given recipes\n"
          ]
        }
      ],
      "source": [
        "unused = get_unused_ingredient(node_features)\n",
        "print(f\"Out of {node_features.shape[0]} ingredients {len(unused)} ingredients are not used in any of the given recipes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6B-KCIrfpnS_",
        "outputId": "ff0c4597-995b-438e-c4dd-57e3ab71d50b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "StellarGraph: Undirected multigraph\n",
            " Nodes: 6714, Edges: 421566\n",
            "\n",
            " Node types:\n",
            "  default: [6714]\n",
            "    Features: float32 vector, length 20\n",
            "    Edge types: default-default->default\n",
            "\n",
            " Edge types:\n",
            "    default-default->default: [421566]\n",
            "        Weights: all 1 (default)\n",
            "        Features: none\n"
          ]
        }
      ],
      "source": [
        "pairs = node_feature_pair(node_features)\n",
        "G_w_node_feature = sg.StellarGraph.from_networkx(G, node_features=zip(pairs.keys(), pairs.values()))\n",
        "print(G_w_node_feature.info())\n",
        "\n",
        "# G_w_node_feature = sg.StellarGraph.from_networkx(G, node_features=zip([i for i in range(0, node_features.shape[0])], node_features.tolist())) \n",
        "# print(G_w_node_feature.info())\n",
        "\n",
        "\n",
        "# G_wo_node_feature = sg.StellarGraph.from_networkx(G)\n",
        "# print(G_wo_node_feature.info())\n",
        "\n",
        "# Make sure every ingredient is represented as a node in the graph\n",
        "assert(list(pairs.keys()) == [x for x in range(node_features.shape[0])])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0k9-o5Gq3zqo"
      },
      "source": [
        "# **Building Embedding Graph Models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkPn5Ylw5DHl"
      },
      "outputs": [],
      "source": [
        "def create_biased_random_walker(graph, p, q):\n",
        "  #   p: defines (unormalised) probability, 1/p, of returning to source node\n",
        "  #   q: defines (unormalised) probability, 1/q, for moving away from source node\n",
        "  return BiasedRandomWalk(graph, n=args.walk_number, length=args.walk_length, p=p, q=q)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Word2Vec**"
      ],
      "metadata": {
        "id": "UoRalqQYLnVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def word2vec_embedding(G):\n",
        "  random_walk = BiasedRandomWalk(G)\n",
        "  walker = random_walk.run(nodes=list(G.nodes()), n=args.walk_number, length=args.walk_length, p=0.5, q=0.2)\n",
        "  str_walks = [[str(n) for n in walk] for walk in walker]\n",
        "  model = Word2Vec(str_walks, size=args.dim, window=5, min_count=0, sg=1, workers=2, iter=1)\n",
        "  return model.wv.vectors"
      ],
      "metadata": {
        "id": "3EQDIamZLlqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Node2Vec**"
      ],
      "metadata": {
        "id": "oKUvwMOfLpVh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkIuk743Wgbx"
      },
      "outputs": [],
      "source": [
        "from stellargraph.mapper import Node2VecLinkGenerator, Node2VecNodeGenerator\n",
        "from stellargraph.layer import Node2Vec, link_classification\n",
        "\n",
        "def node2vec_embedding(G): \n",
        "  #   Create the biased random walker to generate random walks\n",
        "  walker = create_biased_random_walker(G, 0.5, 0.2)\n",
        "  #   Create the unsupervised sampler to sample (target, context) pairs from random walks\n",
        "  unsupervised_samples = UnsupervisedSampler(G, nodes=list(G.nodes()), walker=walker)\n",
        "\n",
        "  #   Define a Node2Vec training generator, which generates batches of training pairs\n",
        "  generator = Node2VecLinkGenerator(G, args.batch_size)\n",
        "\n",
        "  #   Create the Node2Vec model\n",
        "  node2vec = Node2Vec(args.dim, generator=generator)\n",
        "\n",
        "  #   Build the model and expose input and output sockets of Node2Vec, for node pair inputs\n",
        "  x_inp, x_out = node2vec.in_out_tensors()\n",
        "\n",
        "  #   Use the link_classification function to generate the output of the Node2Vec model\n",
        "  prediction = link_classification(output_dim=1, output_act=\"sigmoid\", edge_embedding_method=\"dot\")(x_out)\n",
        "\n",
        "  #   Stack the Node2Vec encoder and prediction layer into a Keras model, and specify the loss\n",
        "  model = keras.Model(inputs=x_inp, outputs=prediction)\n",
        "  \n",
        "  model.compile(\n",
        "      optimizer=keras.optimizers.Adam(learning_rate=args.lr),\n",
        "      loss=keras.losses.binary_crossentropy,\n",
        "      metrics=[keras.metrics.binary_accuracy]\n",
        "  )\n",
        "\n",
        "  es_callback = keras.callbacks.EarlyStopping(monitor=\"binary_accuracy\", patience=3, verbose=1, mode=\"max\")\n",
        "\n",
        "  #   Train the model\n",
        "  model.fit(\n",
        "      generator.flow(unsupervised_samples),\n",
        "      epochs=args.epoch,\n",
        "      verbose=2,\n",
        "      use_multiprocessing=False,\n",
        "      workers=4,\n",
        "      shuffle=True,\n",
        "      callbacks=[es_callback]\n",
        "  )\n",
        "\n",
        "  #   Build the model to predict node representations from node ids with the learned Node2Vec model parameters\n",
        "  x_inp_src = x_inp[0]\n",
        "  x_out_src = x_out[0]\n",
        "  embedding_model = keras.Model(inputs=x_inp_src, outputs=x_out_src)\n",
        "\n",
        "  # Get representations for all nodes in ``graph``\n",
        "  node_gen = Node2VecNodeGenerator(G, args.batch_size).flow(list(G.nodes()))\n",
        "  return embedding_model.predict(node_gen, workers=1, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **GraphSAGE**"
      ],
      "metadata": {
        "id": "nLbGEXGALdNd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5fP-j2fmOyo"
      },
      "outputs": [],
      "source": [
        "from stellargraph.mapper import GraphSAGELinkGenerator, GraphSAGENodeGenerator\n",
        "from stellargraph.layer import GraphSAGE\n",
        "\n",
        "def graphsage_embedding(G):\n",
        "  #   Defining a 2-layer GraphSAGE model\n",
        "  num_samples = [10, 5]  \n",
        "  layer_sizes = [args.dim, args.dim]\n",
        "  assert len(layer_sizes) == len(num_samples)\n",
        "\n",
        "  \n",
        "  #   Create the biased random walker to generate random walks\n",
        "  walker = create_biased_random_walker(G, 0.5, 0.2)\n",
        "  \n",
        "  #   Create the unsupervised sampler to sample (target, context) pairs from random walks\n",
        "  unsupervised_samples = UnsupervisedSampler(G, nodes=list(G.nodes()), walker=walker)\n",
        "\n",
        "  #   Define a GraphSAGE training generator, which generates batches of training pairs\n",
        "  generator = GraphSAGELinkGenerator(G, args.batch_size, num_samples=num_samples)\n",
        "\n",
        "  #   Create the GraphSAGE model\n",
        "  graphsage = GraphSAGE(\n",
        "        layer_sizes=layer_sizes,\n",
        "        generator=generator,\n",
        "        bias=True,\n",
        "        dropout=0.2,\n",
        "        normalize=\"l2\"\n",
        "  )\n",
        "\n",
        "  #   Build the model and expose input and output sockets of GraphSAGE, for node pair inputs\n",
        "  x_inp, x_out = graphsage.in_out_tensors()\n",
        "\n",
        "  #   Use the link_classification function to generate the output of the GraphSAGE model\n",
        "  prediction = link_classification(output_dim=1, output_act=\"relu\", edge_embedding_method=\"ip\")(x_out)\n",
        "\n",
        "  #   Stack the GraphSAGE encoder and prediction layer into a Keras model, and specify the loss\n",
        "  model = keras.Model(inputs=x_inp, outputs=prediction)\n",
        "  \n",
        "  model.compile(\n",
        "      optimizer=keras.optimizers.Adam(learning_rate=args.lr),\n",
        "      loss=keras.losses.binary_crossentropy,\n",
        "      metrics=[keras.metrics.binary_accuracy]\n",
        "  )\n",
        "\n",
        "  es_callback = keras.callbacks.EarlyStopping(monitor=\"binary_accuracy\", patience=3, verbose=1, mode=\"max\")\n",
        "\n",
        "  #   Train the model\n",
        "  model.fit(\n",
        "      generator.flow(unsupervised_samples),\n",
        "      epochs=args.epoch,\n",
        "      verbose=2,\n",
        "      use_multiprocessing=False,\n",
        "      workers=4,\n",
        "      shuffle=True,\n",
        "      callbacks=[es_callback]\n",
        "  )\n",
        "\n",
        "  #   Build the model to predict node representations from node features with the learned GraphSAGE model parameters\n",
        "  x_inp_src = x_inp[0::2]\n",
        "  x_out_src = x_out[0]\n",
        "  embedding_model = keras.Model(inputs=x_inp_src, outputs=x_out_src)\n",
        "\n",
        "  # Get representations for all nodes in ``graph``\n",
        "  node_gen = GraphSAGENodeGenerator(G, args.batch_size, num_samples).flow(list(G.nodes()))\n",
        "  return embedding_model.predict(node_gen, workers=1, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **GCN**"
      ],
      "metadata": {
        "id": "vkKl21XxLghB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qzrpa7IYNuEy"
      },
      "outputs": [],
      "source": [
        "from stellargraph.mapper import FullBatchLinkGenerator, FullBatchNodeGenerator\n",
        "from stellargraph.layer import GCN, LinkEmbedding\n",
        "\n",
        "def gcn_embedding(G):\n",
        "  #   Defining a 2-layer GCN model\n",
        "  layer_sizes = [args.dim, args.dim]\n",
        "  \n",
        "  #   Create the biased random walker to generate random walks\n",
        "  walker = create_biased_random_walker(G, 1.0, 1.0)\n",
        "  \n",
        "  #   Create the unsupervised sampler to sample (target, context) pairs from random walks\n",
        "  unsupervised_samples = UnsupervisedSampler(G, nodes=list(G.nodes()), walker=walker)\n",
        "\n",
        "  #   Define a GCN training generator, which generates the full batch of training pairs\n",
        "  generator = FullBatchLinkGenerator(G, method=\"gcn\")\n",
        "\n",
        "  #   Create the GCN model\n",
        "  gcn = GCN(\n",
        "      layer_sizes=layer_sizes,\n",
        "      activations=[\"relu\", \"relu\"],\n",
        "      generator=generator,\n",
        "      dropout=0.3\n",
        "  )\n",
        "\n",
        "  #   Build the model and expose input and output sockets of GCN, for node pair inputs\n",
        "  x_inp, x_out = gcn.in_out_tensors()\n",
        "\n",
        "  #   Use the dot product of node embeddings to make node pairs co-occurring in short random walks represented closely\n",
        "  prediction = LinkEmbedding(activation=\"sigmoid\", method=\"ip\")(x_out)\n",
        "  prediction = keras.layers.Reshape((-1,))(prediction)\n",
        "\n",
        "  #   Stack the GCN encoder and prediction layer into a Keras model, and specify the loss\n",
        "  model = keras.Model(inputs=x_inp, outputs=prediction)\n",
        "  \n",
        "  model.compile(\n",
        "      optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "      loss=keras.losses.binary_crossentropy,\n",
        "      metrics=[keras.metrics.binary_accuracy]\n",
        "  )\n",
        "\n",
        "  # Train the model\n",
        "  batches = unsupervised_samples.run(args.batch_size)\n",
        "  for epoch in range(args.epoch):\n",
        "    for batch in batches:\n",
        "      samples = generator.flow(batch[0], targets=batch[1], use_ilocs=True)[0]\n",
        "      [loss, accuracy] = model.train_on_batch(x=samples[0], y=samples[1])\n",
        "    print(\n",
        "      f\"Epoch: {epoch+1}/{args.epoch} - \"\n",
        "      + \" loss: {:6.4f}\".format(loss)\n",
        "      + \" - binary_accuracy: {:6.4f}\".format(accuracy)\n",
        "    )\n",
        "\n",
        "  # Get representations for all nodes in ``graph``\n",
        "  embedding_model = keras.Model(inputs=x_inp, outputs=x_out)\n",
        "  node_embeddings = embedding_model.predict(generator.flow(list(zip(list(G.nodes()), list(G.nodes())))))\n",
        "  return node_embeddings[0][:, 0, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training Embedding Graph Models**"
      ],
      "metadata": {
        "id": "THgu6SvpLRE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_embedding(method, G):\n",
        "  start_time = time.time()\n",
        "\n",
        "  if method == \"Word2Vec\":\n",
        "    node_embedding = word2vec_embedding(G)\n",
        "  elif method == \"Node2Vec\":\n",
        "    node_embedding = node2vec_embedding(G)\n",
        "  elif method == \"GraphSAGE\":\n",
        "    node_embedding = graphsage_embedding(G)\n",
        "  elif method == \"GCN\":\n",
        "    node_embedding = gcn_embedding(G)\n",
        "  else:\n",
        "    print(\"Pick appropriate embedding method\")\n",
        "    return\n",
        "  \n",
        "  pd.DataFrame(node_embedding).to_csv(os.path.join(results,\n",
        "    f\"{method}_{args.graph_method}\" + \n",
        "    f\"graph_{str(timedelta(seconds=time.time() - start_time))}\" +\n",
        "    f\"dim_{args.dim}\" +\n",
        "    f\"epochs_{args.epoch}\" +\n",
        "    f\"batchsize_{args.batch_size}\" +\n",
        "    f\"walknumber_{args.walk_number}\" +\n",
        "    f\"walklength_{args.walk_length}.csv\"))\n"
      ],
      "metadata": {
        "id": "p1Dy5rjYYW75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "methods = [\"Word2Vec\", \"Node2Vec\", \"GraphSAGE\", \"GCN\"]\n",
        "method = methods[1]\n",
        "print(f\"Selected embedding method {method}\")\n",
        "train_embedding(method, G_w_node_feature)"
      ],
      "metadata": {
        "id": "T2o8SeqtZYFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pick Embedding**"
      ],
      "metadata": {
        "id": "Ww63IIxnH7gL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paths = os.listdir(results)\n",
        "for i in range(len(paths)):\n",
        "  print(f\"{i}: {paths[i]}\")"
      ],
      "metadata": {
        "id": "fQemBxtPHPgD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e10b63e-4e56-45db-f68b-26de4e2fabd6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: Word2Vec_connectedgraph_0:12:08.268310dim_128epochs_10batchsize_64walknumber_10walklength_100.csv\n",
            "1: Node2Vec_connectedgraph_2:11:51.515414dim_128epochs_10batchsize_64walknumber_10walklength_100.csv\n",
            "2: Word2Vec_completegraph_0:20:48.676683dim_128epochs_10batchsize_64walknumber_10walklength_100.csv\n",
            "3: Node2Vec_completegraph_3:28:50.135091dim_128epochs_10batchsize_64walknumber_10walklength_100.csv\n",
            "4: GCN_connectedgraph_1:52:23.785886dim_64epochs_10batchsize_64walknumber_10walklength_20.csv\n",
            "5: GraphSAGE_connectedgraph_7:03:52.822946dim_128epochs_4batchsize_64walknumber_10walklength_30.csv\n",
            "6: GCN_completegraph_3:06:44.202400dim_128epochs_4batchsize_64walknumber_10walklength_30.csv\n",
            "7: test_classification_answer.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = paths[1]\n",
        "print(f\"Chosen embedding: {path}\")\n",
        "embeddings = pd.read_csv(os.path.join(results, path))\n",
        "embeddings = embeddings.drop(embeddings.columns[0], axis=1)"
      ],
      "metadata": {
        "id": "aR1YR-dfbVVq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "117476a4-157a-493b-f514-59c9135e49b4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chosen embedding: Node2Vec_connectedgraph_2:11:51.515414dim_128epochs_10batchsize_64walknumber_10walklength_100.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Classification**"
      ],
      "metadata": {
        "id": "iFdTk74nSlls"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dataset Constructor**"
      ],
      "metadata": {
        "id": "nmef-LWGEqhY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, recipes, targets):\n",
        "    self.recipes = torch.from_numpy(recipes).float()\n",
        "    self.targets = torch.from_numpy(targets).float()\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.targets)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    target = self.targets[idx]\n",
        "    recipe = self.recipes[idx]\n",
        "    sample = {\"recipe\": recipe, \"label\": target}\n",
        "    return sample"
      ],
      "metadata": {
        "id": "yY2Ky-9lVtxD"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Loader**"
      ],
      "metadata": {
        "id": "mWJPf8_vHmpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_classification(embedding, labels, stage):\n",
        "  if stage == \"train\":\n",
        "    with open (\"train.csv\", \"r\") as f:\n",
        "      data = f.readlines()\n",
        "      emb = np.zeros((len(data), args.dim))\n",
        "      target = np.zeros((len(data), len(labels)))\n",
        "      \n",
        "      for i in range(len(data)):\n",
        "        ingredients = data[i].strip().split(\",\")\n",
        "        origin = ingredients.pop()\n",
        "        ingredients = [int(x) for x in ingredients]\n",
        "        average = np.zeros((len(ingredients), args.dim))\n",
        "        for j in range(len(ingredients)):\n",
        "          average[j, :] = embedding.iloc[ingredients[j], :]\n",
        "        \n",
        "        emb[i, :] = np.mean(average, axis=0)\n",
        "        target[i, labels[origin]] = 1\n",
        "    \n",
        "  elif stage == \"val\":\n",
        "    with open (\"validation_classification_answer.csv\", \"r\") as f:\n",
        "      data = f.readlines()\n",
        "      target = np.zeros((len(data), len(labels)))\n",
        "      for i in range(len(data)):\n",
        "        origin = data[i].strip()\n",
        "        target[i, labels[origin]] = 1\n",
        "    \n",
        "    with open (\"validation_classification_question.csv\", \"r\") as f:\n",
        "      data = f.readlines()\n",
        "      emb = np.zeros((len(data), args.dim))\n",
        "      for i in range(len(data)):\n",
        "        ingredients = data[i].strip().split(\",\")\n",
        "        ingredients = [int(x) for x in ingredients]\n",
        "        average = np.zeros((len(ingredients), args.dim))\n",
        "        for j in range(len(ingredients)):\n",
        "          average[j, :] = embedding.iloc[ingredients[j], :]\n",
        "        \n",
        "        emb[i, :] = np.mean(average, axis=0)\n",
        "    \n",
        "  elif stage == \"test\":\n",
        "    with open (\"test_classification_question.csv\", \"r\") as f:\n",
        "      data = f.readlines()\n",
        "      emb = np.zeros((len(data), args.dim))\n",
        "      target = np.zeros((len(data), 1))\n",
        "      for i in range(len(data)):\n",
        "        ingredients = data[i].strip().split(\",\")\n",
        "        ingredients = [int(x) for x in ingredients]\n",
        "        average = np.zeros((len(ingredients), args.dim))\n",
        "        \n",
        "        for j in range(len(ingredients)):\n",
        "          average[j, :] = embedding.iloc[ingredients[j], :]\n",
        "        \n",
        "        emb[i, :] = np.mean(average, axis=0)\n",
        "\n",
        "  return emb, target"
      ],
      "metadata": {
        "id": "D__noB6kMOyU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model**"
      ],
      "metadata": {
        "id": "p_nCEIGX2Uzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier(nn.Module):\n",
        "  def __init__(self, num_feature, num_class):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.fc1 = nn.Linear(num_feature, 512)\n",
        "    self.bn1 = nn.BatchNorm1d(512)\n",
        "    \n",
        "    self.fc2 = nn.Linear(512, 64)\n",
        "    self.bn2 = nn.BatchNorm1d(64)\n",
        "\n",
        "    self.fc3 = nn.Linear(64, num_class)\n",
        "    self.bn3 = nn.BatchNorm1d(num_class)\n",
        "\n",
        "    self.dp = nn.Dropout(0.3)\n",
        "    self.act = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = self.dp(self.act(self.bn1(self.fc1(x))))\n",
        "    output = self.dp(self.act(self.bn2(self.fc2(output))))\n",
        "    output = self.bn3(self.fc3(output))\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "vc7VFTDSh0wd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **RF**"
      ],
      "metadata": {
        "id": "MOTvWOtMIZdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_classification_RF(embedding, labels, stage):\n",
        "  if stage == \"train\":\n",
        "    with open (\"train.csv\", \"r\") as f:\n",
        "      data = f.readlines()\n",
        "      emb = np.zeros((len(data), args.dim))\n",
        "      target = []\n",
        "      \n",
        "      for i in range(len(data)):\n",
        "        ingredients = data[i].strip().split(\",\")\n",
        "        origin = ingredients.pop()\n",
        "        ingredients = [int(x) for x in ingredients]\n",
        "        average = np.zeros((len(ingredients), args.dim))\n",
        "        for j in range(len(ingredients)):\n",
        "          average[j, :] = embedding.iloc[ingredients[j], :]\n",
        "        \n",
        "        emb[i, :] = np.mean(average, axis=0)\n",
        "        target.append(labels[origin])\n",
        "    \n",
        "  elif stage == \"val\":\n",
        "    with open (\"validation_classification_answer.csv\", \"r\") as f:\n",
        "      data = f.readlines()\n",
        "      target = []\n",
        "      for i in range(len(data)):\n",
        "        origin = data[i].strip()\n",
        "        target.append(labels[origin])\n",
        "    \n",
        "    with open (\"validation_classification_question.csv\", \"r\") as f:\n",
        "      data = f.readlines()\n",
        "      emb = np.zeros((len(data), args.dim))\n",
        "      for i in range(len(data)):\n",
        "        ingredients = data[i].strip().split(\",\")\n",
        "        ingredients = [int(x) for x in ingredients]\n",
        "        average = np.zeros((len(ingredients), args.dim))\n",
        "        for j in range(len(ingredients)):\n",
        "          average[j, :] = embedding.iloc[ingredients[j], :]\n",
        "        \n",
        "        emb[i, :] = np.mean(average, axis=0)\n",
        "  return emb, target"
      ],
      "metadata": {
        "id": "RMbMdIfgMLWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_clf_dataset_RF, y_train_clf_dataset_RF = load_data_classification_RF(embeddings, labels, \"train\")\n",
        "x_val_clf_dataset_RF, y_val_clf_dataset_RF = load_data_classification_RF(embeddings, labels, \"val\")"
      ],
      "metadata": {
        "id": "YyiLwnGdPyNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estimators = [15, 20, 30]\n",
        "for i in estimators:\n",
        "  clf = RandomForestClassifier( bootstrap=True, class_weight=None, criterion='gini',\n",
        "                                max_depth = 20, max_features = 'auto', max_leaf_nodes = None,\n",
        "                                min_impurity_decrease = 0.0,\n",
        "                                min_samples_leaf = 3, min_samples_split = 3,\n",
        "                                min_weight_fraction_leaf = 0.0, n_estimators = i, n_jobs =-1,\n",
        "                                random_state = 25,warm_start = False)\n",
        "\n",
        "  clf.fit(x_train_clf_dataset_RF, y_train_clf_dataset_RF) # fitting the classifier\n",
        "  \n",
        "  train_sc = accuracy_score(y_train_clf_dataset_RF, clf.predict(x_train_clf_dataset_RF))\n",
        "  val_sc = accuracy_score(y_val_clf_dataset_RF, clf.predict(x_val_clf_dataset_RF))\n",
        "  \n",
        "  print('Estimators = ',i,'Train Score',train_sc,'test Score',val_sc)"
      ],
      "metadata": {
        "id": "7v2m943rMfHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training**"
      ],
      "metadata": {
        "id": "AoMCjJG7sjti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_clf_dataset, y_train_clf_dataset = load_data_classification(df, labels, \"train\")\n",
        "x_val_clf_dataset, y_val_clf_dataset = load_data_classification(df, labels, \"val\")\n",
        "x_test_clf_dataset, y_test_clf_dataset = load_data_classification(df, labels, \"test\")\n",
        "\n",
        "train_clf_dataset = MyDataset(x_train_clf_dataset, y_train_clf_dataset)\n",
        "val_clf_dataset = MyDataset(x_val_clf_dataset, y_val_clf_dataset)\n",
        "test_clf_dataset = MyDataset(x_test_clf_dataset, y_test_clf_dataset)\n",
        "\n",
        "train_clf_dataloader = torch.utils.data.DataLoader(train_clf_dataset, batch_size=args.batch_size, shuffle=True, num_workers=2)\n",
        "val_clf_dataloader = torch.utils.data.DataLoader(val_clf_dataset, batch_size=args.batch_size, shuffle=False, num_workers=2)\n",
        "test_clf_dataloader = torch.utils.data.DataLoader(test_clf_dataset, batch_size=args.batch_size, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "eI6Sq_SySoKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_classifier(model, optimizer, scheduler):\n",
        "  best_accuracy = 0\n",
        "  t_loss, t_accuracy = [], []\n",
        "  v_loss, v_accuracy = [], []\n",
        "  for epoch in range(args.epoch_):\n",
        "    # Here starts the train loop.\n",
        "    train_loss = []\n",
        "    train_accuracy = []\n",
        "    model.train()\n",
        "    for batch_idx, data in enumerate(train_clf_dataloader):\n",
        "      x = data['recipe'].to(device)\n",
        "      y = data['label'].to(device)\n",
        "      y = y.type(torch.float)\n",
        "\n",
        "      #   Feed `x` into the network, get an output, and keep it in a variable called `logit`. \n",
        "      pred = model(x)\n",
        "      pred = pred.type(torch.float).to(device)\n",
        "                                 \n",
        "      #   Accuracy\n",
        "      accuracy = (torch.argmax(torch.log_softmax(pred, 1), 1) == torch.argmax(y, 1)).float().mean()\n",
        "\n",
        "      #   Compute loss using `logit` and `y`, and keep it in a variable called `loss`.\n",
        "      loss = nn.CrossEntropyLoss()(pred, y)\n",
        "\n",
        "      #   Flush out the previously computed gradient.\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      #   Backward the computed loss. \n",
        "      loss.backward()\n",
        "\n",
        "      #   Update the network weights. \n",
        "      optimizer.step()\n",
        "      \n",
        "      train_loss.append(loss.item())\n",
        "      train_accuracy.append(accuracy.item())\n",
        "      \n",
        "      if batch_idx % 50 == 0:\n",
        "        print(f'Epoch : {epoch} || {batch_idx}/{len(train_clf_dataloader)} || \\\n",
        "                loss : {loss.item():.3f}, acc : {accuracy:.3f}')\n",
        "\n",
        "    mean_train_loss = sum(train_loss) / len(train_loss)\n",
        "    mean_train_accuracy = sum(train_accuracy) / len(train_accuracy)\n",
        "\n",
        "    t_loss.append(mean_train_loss)          # t_loss += train_loss\n",
        "    t_accuracy.append(mean_train_accuracy)  # t_accuracy += train_accuracy\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      val_loss = []\n",
        "      val_accuracy = []\n",
        "      for batch_idx, data in enumerate(val_clf_dataloader):\n",
        "        x = data['recipe'].to(device=device)\n",
        "        y = data['label'].to(device=device)\n",
        "        y = y.type(torch.float)\n",
        "  \n",
        "        #   Feed `x` into the network, get an output, and keep it in a variable called `logit`. \n",
        "        pred = model(x)\n",
        "        pred = pred.type(torch.float).to(device)\n",
        "        \n",
        "        #   Accuracy\n",
        "        accuracy = (torch.argmax(torch.log_softmax(pred, 1), 1) == torch.argmax(y, 1)).float().mean()\n",
        "        \n",
        "        #   Compute loss using `logit` and `y`, and keep it in a variable called `loss`.\n",
        "        loss = nn.CrossEntropyLoss()(pred, y)\n",
        "\n",
        "        val_loss.append(loss.item())\n",
        "        val_accuracy.append(accuracy.item())\n",
        "\n",
        "      mean_val_loss = sum(val_loss) / len(val_loss)\n",
        "      mean_val_accuracy = sum(val_accuracy) / len(val_accuracy)\n",
        "      \n",
        "      v_loss.append(mean_val_loss)\n",
        "      v_accuracy.append(mean_val_accuracy)\n",
        "\n",
        "      print(f'Validation result of epoch {epoch}/{args.epoch_} || val_loss : {mean_val_loss:.3f} val_acc : {mean_val_accuracy:.3f} ')\n",
        "\n",
        "      #   Whenever `test_accuracy` is greater than `best_accuracy`, save network weights with the filename 'best.pt' in the directory specified by `ckpt_dir`.\n",
        "      if mean_val_accuracy > best_accuracy:\n",
        "          best_accuracy = mean_val_accuracy\n",
        "          best_val_model = copy.deepcopy(model.state_dict())\n",
        "    \n",
        "    scheduler.step()\n",
        "  return best_accuracy, t_loss, t_accuracy, v_loss, v_accuracy, best_val_model"
      ],
      "metadata": {
        "id": "2AhfsXSjJtvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Classifier(args.dim, len(labels))\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=0.0001)\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50,80], gamma=0.5)\n",
        "start_time = time.time()\n",
        "accuracy, train_loss_clf, train_accuracy_clf, val_loss_clf, val_accuracy_clf, best_val_model = train_classifier(model, optimizer, scheduler)\n",
        "duration = time.time() - start_time\n",
        "print(f'Best validation accuracy of classifier network : {accuracy:.3f} took {duration:.3f} secs')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vSDyOT45oI8",
        "outputId": "eff9614a-80b5-4012-a698-aeb19d8e1560"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 0 || 0/368 ||                 loss : 3.310, acc : 0.062\n",
            "Epoch : 0 || 50/368 ||                 loss : 2.168, acc : 0.422\n",
            "Epoch : 0 || 100/368 ||                 loss : 2.046, acc : 0.453\n",
            "Epoch : 0 || 150/368 ||                 loss : 1.906, acc : 0.500\n",
            "Epoch : 0 || 200/368 ||                 loss : 1.708, acc : 0.516\n",
            "Epoch : 0 || 250/368 ||                 loss : 1.527, acc : 0.625\n",
            "Epoch : 0 || 300/368 ||                 loss : 1.610, acc : 0.578\n",
            "Epoch : 0 || 350/368 ||                 loss : 1.640, acc : 0.594\n",
            "Validation result of epoch 0/100 || val_loss : 1.487 val_acc : 0.620 \n",
            "Epoch : 1 || 0/368 ||                 loss : 1.606, acc : 0.594\n",
            "Epoch : 1 || 50/368 ||                 loss : 1.558, acc : 0.578\n",
            "Epoch : 1 || 100/368 ||                 loss : 1.474, acc : 0.609\n",
            "Epoch : 1 || 150/368 ||                 loss : 1.340, acc : 0.688\n",
            "Epoch : 1 || 200/368 ||                 loss : 1.580, acc : 0.625\n",
            "Epoch : 1 || 250/368 ||                 loss : 1.635, acc : 0.594\n",
            "Epoch : 1 || 300/368 ||                 loss : 1.437, acc : 0.594\n",
            "Epoch : 1 || 350/368 ||                 loss : 1.179, acc : 0.688\n",
            "Validation result of epoch 1/100 || val_loss : 1.315 val_acc : 0.645 \n",
            "Epoch : 2 || 0/368 ||                 loss : 1.418, acc : 0.562\n",
            "Epoch : 2 || 50/368 ||                 loss : 1.539, acc : 0.531\n",
            "Epoch : 2 || 100/368 ||                 loss : 1.306, acc : 0.625\n",
            "Epoch : 2 || 150/368 ||                 loss : 1.788, acc : 0.500\n",
            "Epoch : 2 || 200/368 ||                 loss : 1.247, acc : 0.719\n",
            "Epoch : 2 || 250/368 ||                 loss : 1.346, acc : 0.641\n",
            "Epoch : 2 || 300/368 ||                 loss : 1.356, acc : 0.672\n",
            "Epoch : 2 || 350/368 ||                 loss : 1.143, acc : 0.703\n",
            "Validation result of epoch 2/100 || val_loss : 1.231 val_acc : 0.657 \n",
            "Epoch : 3 || 0/368 ||                 loss : 1.505, acc : 0.562\n",
            "Epoch : 3 || 50/368 ||                 loss : 1.489, acc : 0.578\n",
            "Epoch : 3 || 100/368 ||                 loss : 1.184, acc : 0.656\n",
            "Epoch : 3 || 150/368 ||                 loss : 1.316, acc : 0.656\n",
            "Epoch : 3 || 200/368 ||                 loss : 1.449, acc : 0.578\n",
            "Epoch : 3 || 250/368 ||                 loss : 1.763, acc : 0.438\n",
            "Epoch : 3 || 300/368 ||                 loss : 1.189, acc : 0.656\n",
            "Epoch : 3 || 350/368 ||                 loss : 1.560, acc : 0.562\n",
            "Validation result of epoch 3/100 || val_loss : 1.219 val_acc : 0.654 \n",
            "Epoch : 4 || 0/368 ||                 loss : 1.095, acc : 0.641\n",
            "Epoch : 4 || 50/368 ||                 loss : 1.322, acc : 0.641\n",
            "Epoch : 4 || 100/368 ||                 loss : 1.187, acc : 0.625\n",
            "Epoch : 4 || 150/368 ||                 loss : 1.294, acc : 0.641\n",
            "Epoch : 4 || 200/368 ||                 loss : 1.195, acc : 0.594\n",
            "Epoch : 4 || 250/368 ||                 loss : 1.318, acc : 0.609\n",
            "Epoch : 4 || 300/368 ||                 loss : 1.547, acc : 0.531\n",
            "Epoch : 4 || 350/368 ||                 loss : 1.479, acc : 0.531\n",
            "Validation result of epoch 4/100 || val_loss : 1.200 val_acc : 0.659 \n",
            "Epoch : 5 || 0/368 ||                 loss : 1.202, acc : 0.609\n",
            "Epoch : 5 || 50/368 ||                 loss : 1.134, acc : 0.672\n",
            "Epoch : 5 || 100/368 ||                 loss : 1.220, acc : 0.672\n",
            "Epoch : 5 || 150/368 ||                 loss : 1.385, acc : 0.625\n",
            "Epoch : 5 || 200/368 ||                 loss : 1.137, acc : 0.672\n",
            "Epoch : 5 || 250/368 ||                 loss : 1.152, acc : 0.672\n",
            "Epoch : 5 || 300/368 ||                 loss : 1.520, acc : 0.547\n",
            "Epoch : 5 || 350/368 ||                 loss : 1.171, acc : 0.625\n",
            "Validation result of epoch 5/100 || val_loss : 1.165 val_acc : 0.665 \n",
            "Epoch : 6 || 0/368 ||                 loss : 1.452, acc : 0.531\n",
            "Epoch : 6 || 50/368 ||                 loss : 1.241, acc : 0.594\n",
            "Epoch : 6 || 100/368 ||                 loss : 1.387, acc : 0.625\n",
            "Epoch : 6 || 150/368 ||                 loss : 1.265, acc : 0.641\n",
            "Epoch : 6 || 200/368 ||                 loss : 1.079, acc : 0.641\n",
            "Epoch : 6 || 250/368 ||                 loss : 1.359, acc : 0.625\n",
            "Epoch : 6 || 300/368 ||                 loss : 1.103, acc : 0.672\n",
            "Epoch : 6 || 350/368 ||                 loss : 1.409, acc : 0.625\n",
            "Validation result of epoch 6/100 || val_loss : 1.165 val_acc : 0.664 \n",
            "Epoch : 7 || 0/368 ||                 loss : 1.521, acc : 0.484\n",
            "Epoch : 7 || 50/368 ||                 loss : 1.253, acc : 0.641\n",
            "Epoch : 7 || 100/368 ||                 loss : 1.123, acc : 0.625\n",
            "Epoch : 7 || 150/368 ||                 loss : 1.432, acc : 0.547\n",
            "Epoch : 7 || 200/368 ||                 loss : 1.402, acc : 0.625\n",
            "Epoch : 7 || 250/368 ||                 loss : 1.085, acc : 0.656\n",
            "Epoch : 7 || 300/368 ||                 loss : 1.067, acc : 0.688\n",
            "Epoch : 7 || 350/368 ||                 loss : 1.334, acc : 0.625\n",
            "Validation result of epoch 7/100 || val_loss : 1.159 val_acc : 0.662 \n",
            "Epoch : 8 || 0/368 ||                 loss : 1.355, acc : 0.672\n",
            "Epoch : 8 || 50/368 ||                 loss : 1.245, acc : 0.594\n",
            "Epoch : 8 || 100/368 ||                 loss : 1.131, acc : 0.672\n",
            "Epoch : 8 || 150/368 ||                 loss : 1.139, acc : 0.703\n",
            "Epoch : 8 || 200/368 ||                 loss : 1.336, acc : 0.656\n",
            "Epoch : 8 || 250/368 ||                 loss : 1.282, acc : 0.641\n",
            "Epoch : 8 || 300/368 ||                 loss : 1.284, acc : 0.641\n",
            "Epoch : 8 || 350/368 ||                 loss : 1.224, acc : 0.656\n",
            "Validation result of epoch 8/100 || val_loss : 1.156 val_acc : 0.665 \n",
            "Epoch : 9 || 0/368 ||                 loss : 1.411, acc : 0.578\n",
            "Epoch : 9 || 50/368 ||                 loss : 1.189, acc : 0.578\n",
            "Epoch : 9 || 100/368 ||                 loss : 1.027, acc : 0.688\n",
            "Epoch : 9 || 150/368 ||                 loss : 1.333, acc : 0.641\n",
            "Epoch : 9 || 200/368 ||                 loss : 1.177, acc : 0.609\n",
            "Epoch : 9 || 250/368 ||                 loss : 1.041, acc : 0.672\n",
            "Epoch : 9 || 300/368 ||                 loss : 1.370, acc : 0.562\n",
            "Epoch : 9 || 350/368 ||                 loss : 1.611, acc : 0.484\n",
            "Validation result of epoch 9/100 || val_loss : 1.149 val_acc : 0.663 \n",
            "Epoch : 10 || 0/368 ||                 loss : 1.510, acc : 0.547\n",
            "Epoch : 10 || 50/368 ||                 loss : 1.291, acc : 0.641\n",
            "Epoch : 10 || 100/368 ||                 loss : 1.095, acc : 0.719\n",
            "Epoch : 10 || 150/368 ||                 loss : 1.177, acc : 0.656\n",
            "Epoch : 10 || 200/368 ||                 loss : 1.149, acc : 0.609\n",
            "Epoch : 10 || 250/368 ||                 loss : 1.208, acc : 0.656\n",
            "Epoch : 10 || 300/368 ||                 loss : 1.236, acc : 0.703\n",
            "Epoch : 10 || 350/368 ||                 loss : 1.200, acc : 0.641\n",
            "Validation result of epoch 10/100 || val_loss : 1.139 val_acc : 0.663 \n",
            "Epoch : 11 || 0/368 ||                 loss : 1.087, acc : 0.719\n",
            "Epoch : 11 || 50/368 ||                 loss : 1.386, acc : 0.547\n",
            "Epoch : 11 || 100/368 ||                 loss : 1.163, acc : 0.672\n",
            "Epoch : 11 || 150/368 ||                 loss : 1.311, acc : 0.609\n",
            "Epoch : 11 || 200/368 ||                 loss : 1.334, acc : 0.641\n",
            "Epoch : 11 || 250/368 ||                 loss : 1.314, acc : 0.594\n",
            "Epoch : 11 || 300/368 ||                 loss : 0.971, acc : 0.703\n",
            "Epoch : 11 || 350/368 ||                 loss : 1.167, acc : 0.625\n",
            "Validation result of epoch 11/100 || val_loss : 1.133 val_acc : 0.666 \n",
            "Epoch : 12 || 0/368 ||                 loss : 1.210, acc : 0.703\n",
            "Epoch : 12 || 50/368 ||                 loss : 0.910, acc : 0.750\n",
            "Epoch : 12 || 100/368 ||                 loss : 1.304, acc : 0.641\n",
            "Epoch : 12 || 150/368 ||                 loss : 1.037, acc : 0.750\n",
            "Epoch : 12 || 200/368 ||                 loss : 1.367, acc : 0.562\n",
            "Epoch : 12 || 250/368 ||                 loss : 1.329, acc : 0.562\n",
            "Epoch : 12 || 300/368 ||                 loss : 1.009, acc : 0.719\n",
            "Epoch : 12 || 350/368 ||                 loss : 1.212, acc : 0.641\n",
            "Validation result of epoch 12/100 || val_loss : 1.136 val_acc : 0.665 \n",
            "Epoch : 13 || 0/368 ||                 loss : 1.441, acc : 0.531\n",
            "Epoch : 13 || 50/368 ||                 loss : 1.113, acc : 0.719\n",
            "Epoch : 13 || 100/368 ||                 loss : 1.612, acc : 0.516\n",
            "Epoch : 13 || 150/368 ||                 loss : 1.298, acc : 0.672\n",
            "Epoch : 13 || 200/368 ||                 loss : 1.322, acc : 0.578\n",
            "Epoch : 13 || 250/368 ||                 loss : 1.131, acc : 0.594\n",
            "Epoch : 13 || 300/368 ||                 loss : 1.364, acc : 0.625\n",
            "Epoch : 13 || 350/368 ||                 loss : 1.502, acc : 0.562\n",
            "Validation result of epoch 13/100 || val_loss : 1.125 val_acc : 0.668 \n",
            "Epoch : 14 || 0/368 ||                 loss : 1.292, acc : 0.609\n",
            "Epoch : 14 || 50/368 ||                 loss : 1.073, acc : 0.703\n",
            "Epoch : 14 || 100/368 ||                 loss : 1.313, acc : 0.672\n",
            "Epoch : 14 || 150/368 ||                 loss : 0.985, acc : 0.688\n",
            "Epoch : 14 || 200/368 ||                 loss : 1.529, acc : 0.547\n",
            "Epoch : 14 || 250/368 ||                 loss : 1.200, acc : 0.625\n",
            "Epoch : 14 || 300/368 ||                 loss : 1.280, acc : 0.656\n",
            "Epoch : 14 || 350/368 ||                 loss : 1.141, acc : 0.703\n",
            "Validation result of epoch 14/100 || val_loss : 1.132 val_acc : 0.661 \n",
            "Epoch : 15 || 0/368 ||                 loss : 1.333, acc : 0.641\n",
            "Epoch : 15 || 50/368 ||                 loss : 1.196, acc : 0.641\n",
            "Epoch : 15 || 100/368 ||                 loss : 1.392, acc : 0.562\n",
            "Epoch : 15 || 150/368 ||                 loss : 1.488, acc : 0.594\n",
            "Epoch : 15 || 200/368 ||                 loss : 1.015, acc : 0.688\n",
            "Epoch : 15 || 250/368 ||                 loss : 1.382, acc : 0.688\n",
            "Epoch : 15 || 300/368 ||                 loss : 1.269, acc : 0.594\n",
            "Epoch : 15 || 350/368 ||                 loss : 1.059, acc : 0.688\n",
            "Validation result of epoch 15/100 || val_loss : 1.144 val_acc : 0.658 \n",
            "Epoch : 16 || 0/368 ||                 loss : 1.136, acc : 0.609\n",
            "Epoch : 16 || 50/368 ||                 loss : 1.213, acc : 0.688\n",
            "Epoch : 16 || 100/368 ||                 loss : 1.355, acc : 0.641\n",
            "Epoch : 16 || 150/368 ||                 loss : 1.319, acc : 0.531\n",
            "Epoch : 16 || 200/368 ||                 loss : 1.340, acc : 0.578\n",
            "Epoch : 16 || 250/368 ||                 loss : 1.334, acc : 0.578\n",
            "Epoch : 16 || 300/368 ||                 loss : 1.205, acc : 0.578\n",
            "Epoch : 16 || 350/368 ||                 loss : 1.097, acc : 0.641\n",
            "Validation result of epoch 16/100 || val_loss : 1.124 val_acc : 0.672 \n",
            "Epoch : 17 || 0/368 ||                 loss : 1.432, acc : 0.547\n",
            "Epoch : 17 || 50/368 ||                 loss : 1.292, acc : 0.609\n",
            "Epoch : 17 || 100/368 ||                 loss : 1.258, acc : 0.672\n",
            "Epoch : 17 || 150/368 ||                 loss : 1.105, acc : 0.719\n",
            "Epoch : 17 || 200/368 ||                 loss : 1.110, acc : 0.609\n",
            "Epoch : 17 || 250/368 ||                 loss : 1.182, acc : 0.625\n",
            "Epoch : 17 || 300/368 ||                 loss : 1.484, acc : 0.547\n",
            "Epoch : 17 || 350/368 ||                 loss : 1.077, acc : 0.672\n",
            "Validation result of epoch 17/100 || val_loss : 1.123 val_acc : 0.670 \n",
            "Epoch : 18 || 0/368 ||                 loss : 1.161, acc : 0.688\n",
            "Epoch : 18 || 50/368 ||                 loss : 1.376, acc : 0.656\n",
            "Epoch : 18 || 100/368 ||                 loss : 1.337, acc : 0.625\n",
            "Epoch : 18 || 150/368 ||                 loss : 1.529, acc : 0.484\n",
            "Epoch : 18 || 200/368 ||                 loss : 1.394, acc : 0.562\n",
            "Epoch : 18 || 250/368 ||                 loss : 1.209, acc : 0.625\n",
            "Epoch : 18 || 300/368 ||                 loss : 1.282, acc : 0.578\n",
            "Epoch : 18 || 350/368 ||                 loss : 1.068, acc : 0.703\n",
            "Validation result of epoch 18/100 || val_loss : 1.133 val_acc : 0.667 \n",
            "Epoch : 19 || 0/368 ||                 loss : 1.330, acc : 0.641\n",
            "Epoch : 19 || 50/368 ||                 loss : 1.073, acc : 0.672\n",
            "Epoch : 19 || 100/368 ||                 loss : 1.229, acc : 0.594\n",
            "Epoch : 19 || 150/368 ||                 loss : 1.100, acc : 0.672\n",
            "Epoch : 19 || 200/368 ||                 loss : 1.357, acc : 0.625\n",
            "Epoch : 19 || 250/368 ||                 loss : 1.259, acc : 0.594\n",
            "Epoch : 19 || 300/368 ||                 loss : 1.115, acc : 0.641\n",
            "Epoch : 19 || 350/368 ||                 loss : 1.241, acc : 0.641\n",
            "Validation result of epoch 19/100 || val_loss : 1.123 val_acc : 0.669 \n",
            "Epoch : 20 || 0/368 ||                 loss : 1.181, acc : 0.656\n",
            "Epoch : 20 || 50/368 ||                 loss : 1.326, acc : 0.594\n",
            "Epoch : 20 || 100/368 ||                 loss : 1.179, acc : 0.672\n",
            "Epoch : 20 || 150/368 ||                 loss : 1.451, acc : 0.625\n",
            "Epoch : 20 || 200/368 ||                 loss : 1.057, acc : 0.656\n",
            "Epoch : 20 || 250/368 ||                 loss : 1.126, acc : 0.641\n",
            "Epoch : 20 || 300/368 ||                 loss : 1.499, acc : 0.594\n",
            "Epoch : 20 || 350/368 ||                 loss : 1.229, acc : 0.688\n",
            "Validation result of epoch 20/100 || val_loss : 1.150 val_acc : 0.654 \n",
            "Epoch : 21 || 0/368 ||                 loss : 0.998, acc : 0.688\n",
            "Epoch : 21 || 50/368 ||                 loss : 0.951, acc : 0.750\n",
            "Epoch : 21 || 100/368 ||                 loss : 1.116, acc : 0.672\n",
            "Epoch : 21 || 150/368 ||                 loss : 0.954, acc : 0.734\n",
            "Epoch : 21 || 200/368 ||                 loss : 1.046, acc : 0.750\n",
            "Epoch : 21 || 250/368 ||                 loss : 1.235, acc : 0.672\n",
            "Epoch : 21 || 300/368 ||                 loss : 0.981, acc : 0.734\n",
            "Epoch : 21 || 350/368 ||                 loss : 1.241, acc : 0.734\n",
            "Validation result of epoch 21/100 || val_loss : 1.112 val_acc : 0.675 \n",
            "Epoch : 22 || 0/368 ||                 loss : 0.945, acc : 0.688\n",
            "Epoch : 22 || 50/368 ||                 loss : 1.096, acc : 0.719\n",
            "Epoch : 22 || 100/368 ||                 loss : 0.876, acc : 0.781\n",
            "Epoch : 22 || 150/368 ||                 loss : 1.224, acc : 0.641\n",
            "Epoch : 22 || 200/368 ||                 loss : 1.133, acc : 0.625\n",
            "Epoch : 22 || 250/368 ||                 loss : 1.010, acc : 0.719\n",
            "Epoch : 22 || 300/368 ||                 loss : 1.191, acc : 0.672\n",
            "Epoch : 22 || 350/368 ||                 loss : 1.349, acc : 0.625\n",
            "Validation result of epoch 22/100 || val_loss : 1.114 val_acc : 0.668 \n",
            "Epoch : 23 || 0/368 ||                 loss : 1.239, acc : 0.688\n",
            "Epoch : 23 || 50/368 ||                 loss : 1.153, acc : 0.625\n",
            "Epoch : 23 || 100/368 ||                 loss : 1.159, acc : 0.625\n",
            "Epoch : 23 || 150/368 ||                 loss : 1.408, acc : 0.562\n",
            "Epoch : 23 || 200/368 ||                 loss : 0.826, acc : 0.766\n",
            "Epoch : 23 || 250/368 ||                 loss : 1.163, acc : 0.656\n",
            "Epoch : 23 || 300/368 ||                 loss : 1.222, acc : 0.688\n",
            "Epoch : 23 || 350/368 ||                 loss : 1.453, acc : 0.547\n",
            "Validation result of epoch 23/100 || val_loss : 1.110 val_acc : 0.671 \n",
            "Epoch : 24 || 0/368 ||                 loss : 1.061, acc : 0.656\n",
            "Epoch : 24 || 50/368 ||                 loss : 1.047, acc : 0.703\n",
            "Epoch : 24 || 100/368 ||                 loss : 1.268, acc : 0.672\n",
            "Epoch : 24 || 150/368 ||                 loss : 1.261, acc : 0.578\n",
            "Epoch : 24 || 200/368 ||                 loss : 1.076, acc : 0.672\n",
            "Epoch : 24 || 250/368 ||                 loss : 1.002, acc : 0.750\n",
            "Epoch : 24 || 300/368 ||                 loss : 1.608, acc : 0.500\n",
            "Epoch : 24 || 350/368 ||                 loss : 1.133, acc : 0.656\n",
            "Validation result of epoch 24/100 || val_loss : 1.111 val_acc : 0.673 \n",
            "Epoch : 25 || 0/368 ||                 loss : 1.413, acc : 0.578\n",
            "Epoch : 25 || 50/368 ||                 loss : 1.021, acc : 0.656\n",
            "Epoch : 25 || 100/368 ||                 loss : 1.307, acc : 0.578\n",
            "Epoch : 25 || 150/368 ||                 loss : 1.363, acc : 0.562\n",
            "Epoch : 25 || 200/368 ||                 loss : 1.093, acc : 0.656\n",
            "Epoch : 25 || 250/368 ||                 loss : 1.235, acc : 0.656\n",
            "Epoch : 25 || 300/368 ||                 loss : 1.148, acc : 0.656\n",
            "Epoch : 25 || 350/368 ||                 loss : 1.110, acc : 0.641\n",
            "Validation result of epoch 25/100 || val_loss : 1.110 val_acc : 0.671 \n",
            "Epoch : 26 || 0/368 ||                 loss : 1.159, acc : 0.672\n",
            "Epoch : 26 || 50/368 ||                 loss : 1.032, acc : 0.641\n",
            "Epoch : 26 || 100/368 ||                 loss : 1.221, acc : 0.672\n",
            "Epoch : 26 || 150/368 ||                 loss : 1.136, acc : 0.672\n",
            "Epoch : 26 || 200/368 ||                 loss : 1.116, acc : 0.750\n",
            "Epoch : 26 || 250/368 ||                 loss : 1.430, acc : 0.531\n",
            "Epoch : 26 || 300/368 ||                 loss : 1.227, acc : 0.594\n",
            "Epoch : 26 || 350/368 ||                 loss : 1.374, acc : 0.500\n",
            "Validation result of epoch 26/100 || val_loss : 1.110 val_acc : 0.674 \n",
            "Epoch : 27 || 0/368 ||                 loss : 0.955, acc : 0.656\n",
            "Epoch : 27 || 50/368 ||                 loss : 0.931, acc : 0.734\n",
            "Epoch : 27 || 100/368 ||                 loss : 1.057, acc : 0.688\n",
            "Epoch : 27 || 150/368 ||                 loss : 1.605, acc : 0.516\n",
            "Epoch : 27 || 200/368 ||                 loss : 1.184, acc : 0.656\n",
            "Epoch : 27 || 250/368 ||                 loss : 1.103, acc : 0.656\n",
            "Epoch : 27 || 300/368 ||                 loss : 1.071, acc : 0.688\n",
            "Epoch : 27 || 350/368 ||                 loss : 1.102, acc : 0.688\n",
            "Validation result of epoch 27/100 || val_loss : 1.137 val_acc : 0.661 \n",
            "Epoch : 28 || 0/368 ||                 loss : 0.830, acc : 0.797\n",
            "Epoch : 28 || 50/368 ||                 loss : 1.125, acc : 0.641\n",
            "Epoch : 28 || 100/368 ||                 loss : 1.106, acc : 0.656\n",
            "Epoch : 28 || 150/368 ||                 loss : 1.032, acc : 0.656\n",
            "Epoch : 28 || 200/368 ||                 loss : 1.243, acc : 0.562\n",
            "Epoch : 28 || 250/368 ||                 loss : 1.283, acc : 0.641\n",
            "Epoch : 28 || 300/368 ||                 loss : 1.029, acc : 0.734\n",
            "Epoch : 28 || 350/368 ||                 loss : 1.101, acc : 0.688\n",
            "Validation result of epoch 28/100 || val_loss : 1.108 val_acc : 0.675 \n",
            "Epoch : 29 || 0/368 ||                 loss : 1.203, acc : 0.609\n",
            "Epoch : 29 || 50/368 ||                 loss : 1.069, acc : 0.766\n",
            "Epoch : 29 || 100/368 ||                 loss : 1.490, acc : 0.562\n",
            "Epoch : 29 || 150/368 ||                 loss : 1.060, acc : 0.656\n",
            "Epoch : 29 || 200/368 ||                 loss : 1.284, acc : 0.625\n",
            "Epoch : 29 || 250/368 ||                 loss : 1.002, acc : 0.703\n",
            "Epoch : 29 || 300/368 ||                 loss : 1.034, acc : 0.656\n",
            "Epoch : 29 || 350/368 ||                 loss : 1.245, acc : 0.688\n",
            "Validation result of epoch 29/100 || val_loss : 1.099 val_acc : 0.673 \n",
            "Epoch : 30 || 0/368 ||                 loss : 1.319, acc : 0.594\n",
            "Epoch : 30 || 50/368 ||                 loss : 1.381, acc : 0.594\n",
            "Epoch : 30 || 100/368 ||                 loss : 0.892, acc : 0.766\n",
            "Epoch : 30 || 150/368 ||                 loss : 1.307, acc : 0.562\n",
            "Epoch : 30 || 200/368 ||                 loss : 1.124, acc : 0.656\n",
            "Epoch : 30 || 250/368 ||                 loss : 1.330, acc : 0.609\n",
            "Epoch : 30 || 300/368 ||                 loss : 1.221, acc : 0.641\n",
            "Epoch : 30 || 350/368 ||                 loss : 0.924, acc : 0.719\n",
            "Validation result of epoch 30/100 || val_loss : 1.119 val_acc : 0.667 \n",
            "Epoch : 31 || 0/368 ||                 loss : 1.149, acc : 0.641\n",
            "Epoch : 31 || 50/368 ||                 loss : 1.163, acc : 0.625\n",
            "Epoch : 31 || 100/368 ||                 loss : 1.311, acc : 0.656\n",
            "Epoch : 31 || 150/368 ||                 loss : 0.846, acc : 0.719\n",
            "Epoch : 31 || 200/368 ||                 loss : 1.152, acc : 0.625\n",
            "Epoch : 31 || 250/368 ||                 loss : 1.275, acc : 0.609\n",
            "Epoch : 31 || 300/368 ||                 loss : 1.105, acc : 0.672\n",
            "Epoch : 31 || 350/368 ||                 loss : 1.096, acc : 0.688\n",
            "Validation result of epoch 31/100 || val_loss : 1.093 val_acc : 0.682 \n",
            "Epoch : 32 || 0/368 ||                 loss : 1.339, acc : 0.578\n",
            "Epoch : 32 || 50/368 ||                 loss : 0.953, acc : 0.734\n",
            "Epoch : 32 || 100/368 ||                 loss : 1.059, acc : 0.672\n",
            "Epoch : 32 || 150/368 ||                 loss : 1.189, acc : 0.672\n",
            "Epoch : 32 || 200/368 ||                 loss : 1.177, acc : 0.625\n",
            "Epoch : 32 || 250/368 ||                 loss : 1.030, acc : 0.656\n",
            "Epoch : 32 || 300/368 ||                 loss : 1.301, acc : 0.625\n",
            "Epoch : 32 || 350/368 ||                 loss : 0.948, acc : 0.688\n",
            "Validation result of epoch 32/100 || val_loss : 1.126 val_acc : 0.670 \n",
            "Epoch : 33 || 0/368 ||                 loss : 1.624, acc : 0.516\n",
            "Epoch : 33 || 50/368 ||                 loss : 1.164, acc : 0.641\n",
            "Epoch : 33 || 100/368 ||                 loss : 0.945, acc : 0.750\n",
            "Epoch : 33 || 150/368 ||                 loss : 1.092, acc : 0.656\n",
            "Epoch : 33 || 200/368 ||                 loss : 0.861, acc : 0.781\n",
            "Epoch : 33 || 250/368 ||                 loss : 1.009, acc : 0.688\n",
            "Epoch : 33 || 300/368 ||                 loss : 1.299, acc : 0.609\n",
            "Epoch : 33 || 350/368 ||                 loss : 1.113, acc : 0.641\n",
            "Validation result of epoch 33/100 || val_loss : 1.106 val_acc : 0.675 \n",
            "Epoch : 34 || 0/368 ||                 loss : 1.464, acc : 0.578\n",
            "Epoch : 34 || 50/368 ||                 loss : 0.995, acc : 0.703\n",
            "Epoch : 34 || 100/368 ||                 loss : 1.368, acc : 0.625\n",
            "Epoch : 34 || 150/368 ||                 loss : 1.074, acc : 0.672\n",
            "Epoch : 34 || 200/368 ||                 loss : 1.207, acc : 0.656\n",
            "Epoch : 34 || 250/368 ||                 loss : 0.928, acc : 0.734\n",
            "Epoch : 34 || 300/368 ||                 loss : 1.525, acc : 0.516\n",
            "Epoch : 34 || 350/368 ||                 loss : 1.160, acc : 0.656\n",
            "Validation result of epoch 34/100 || val_loss : 1.127 val_acc : 0.663 \n",
            "Epoch : 35 || 0/368 ||                 loss : 1.114, acc : 0.656\n",
            "Epoch : 35 || 50/368 ||                 loss : 1.456, acc : 0.594\n",
            "Epoch : 35 || 100/368 ||                 loss : 1.107, acc : 0.734\n",
            "Epoch : 35 || 150/368 ||                 loss : 1.041, acc : 0.703\n",
            "Epoch : 35 || 200/368 ||                 loss : 1.065, acc : 0.656\n",
            "Epoch : 35 || 250/368 ||                 loss : 1.189, acc : 0.625\n",
            "Epoch : 35 || 300/368 ||                 loss : 1.328, acc : 0.641\n",
            "Epoch : 35 || 350/368 ||                 loss : 1.015, acc : 0.719\n",
            "Validation result of epoch 35/100 || val_loss : 1.109 val_acc : 0.672 \n",
            "Epoch : 36 || 0/368 ||                 loss : 1.348, acc : 0.594\n",
            "Epoch : 36 || 50/368 ||                 loss : 1.092, acc : 0.672\n",
            "Epoch : 36 || 100/368 ||                 loss : 0.976, acc : 0.703\n",
            "Epoch : 36 || 150/368 ||                 loss : 1.192, acc : 0.703\n",
            "Epoch : 36 || 200/368 ||                 loss : 1.183, acc : 0.656\n",
            "Epoch : 36 || 250/368 ||                 loss : 1.045, acc : 0.688\n",
            "Epoch : 36 || 300/368 ||                 loss : 1.120, acc : 0.641\n",
            "Epoch : 36 || 350/368 ||                 loss : 1.160, acc : 0.594\n",
            "Validation result of epoch 36/100 || val_loss : 1.089 val_acc : 0.679 \n",
            "Epoch : 37 || 0/368 ||                 loss : 1.214, acc : 0.656\n",
            "Epoch : 37 || 50/368 ||                 loss : 1.043, acc : 0.641\n",
            "Epoch : 37 || 100/368 ||                 loss : 0.969, acc : 0.703\n",
            "Epoch : 37 || 150/368 ||                 loss : 0.937, acc : 0.688\n",
            "Epoch : 37 || 200/368 ||                 loss : 1.259, acc : 0.672\n",
            "Epoch : 37 || 250/368 ||                 loss : 1.087, acc : 0.719\n",
            "Epoch : 37 || 300/368 ||                 loss : 1.255, acc : 0.656\n",
            "Epoch : 37 || 350/368 ||                 loss : 1.159, acc : 0.672\n",
            "Validation result of epoch 37/100 || val_loss : 1.118 val_acc : 0.665 \n",
            "Epoch : 38 || 0/368 ||                 loss : 0.844, acc : 0.719\n",
            "Epoch : 38 || 50/368 ||                 loss : 0.840, acc : 0.797\n",
            "Epoch : 38 || 100/368 ||                 loss : 1.224, acc : 0.609\n",
            "Epoch : 38 || 150/368 ||                 loss : 1.579, acc : 0.516\n",
            "Epoch : 38 || 200/368 ||                 loss : 1.388, acc : 0.609\n",
            "Epoch : 38 || 250/368 ||                 loss : 0.927, acc : 0.734\n",
            "Epoch : 38 || 300/368 ||                 loss : 1.094, acc : 0.703\n",
            "Epoch : 38 || 350/368 ||                 loss : 0.826, acc : 0.719\n",
            "Validation result of epoch 38/100 || val_loss : 1.095 val_acc : 0.672 \n",
            "Epoch : 39 || 0/368 ||                 loss : 1.209, acc : 0.625\n",
            "Epoch : 39 || 50/368 ||                 loss : 1.449, acc : 0.594\n",
            "Epoch : 39 || 100/368 ||                 loss : 1.418, acc : 0.594\n",
            "Epoch : 39 || 150/368 ||                 loss : 1.054, acc : 0.641\n",
            "Epoch : 39 || 200/368 ||                 loss : 0.929, acc : 0.750\n",
            "Epoch : 39 || 250/368 ||                 loss : 1.559, acc : 0.531\n",
            "Epoch : 39 || 300/368 ||                 loss : 1.185, acc : 0.625\n",
            "Epoch : 39 || 350/368 ||                 loss : 1.633, acc : 0.531\n",
            "Validation result of epoch 39/100 || val_loss : 1.101 val_acc : 0.669 \n",
            "Epoch : 40 || 0/368 ||                 loss : 1.170, acc : 0.672\n",
            "Epoch : 40 || 50/368 ||                 loss : 0.934, acc : 0.641\n",
            "Epoch : 40 || 100/368 ||                 loss : 1.319, acc : 0.594\n",
            "Epoch : 40 || 150/368 ||                 loss : 1.262, acc : 0.562\n",
            "Epoch : 40 || 200/368 ||                 loss : 1.053, acc : 0.719\n",
            "Epoch : 40 || 250/368 ||                 loss : 1.248, acc : 0.734\n",
            "Epoch : 40 || 300/368 ||                 loss : 1.350, acc : 0.562\n",
            "Epoch : 40 || 350/368 ||                 loss : 1.025, acc : 0.641\n",
            "Validation result of epoch 40/100 || val_loss : 1.090 val_acc : 0.674 \n",
            "Epoch : 41 || 0/368 ||                 loss : 1.232, acc : 0.625\n",
            "Epoch : 41 || 50/368 ||                 loss : 0.843, acc : 0.734\n",
            "Epoch : 41 || 100/368 ||                 loss : 0.990, acc : 0.734\n",
            "Epoch : 41 || 150/368 ||                 loss : 1.072, acc : 0.656\n",
            "Epoch : 41 || 200/368 ||                 loss : 1.174, acc : 0.641\n",
            "Epoch : 41 || 250/368 ||                 loss : 0.909, acc : 0.703\n",
            "Epoch : 41 || 300/368 ||                 loss : 1.095, acc : 0.656\n",
            "Epoch : 41 || 350/368 ||                 loss : 1.087, acc : 0.688\n",
            "Validation result of epoch 41/100 || val_loss : 1.096 val_acc : 0.676 \n",
            "Epoch : 42 || 0/368 ||                 loss : 1.202, acc : 0.594\n",
            "Epoch : 42 || 50/368 ||                 loss : 1.525, acc : 0.656\n",
            "Epoch : 42 || 100/368 ||                 loss : 1.207, acc : 0.656\n",
            "Epoch : 42 || 150/368 ||                 loss : 1.453, acc : 0.594\n",
            "Epoch : 42 || 200/368 ||                 loss : 1.016, acc : 0.703\n",
            "Epoch : 42 || 250/368 ||                 loss : 0.868, acc : 0.781\n",
            "Epoch : 42 || 300/368 ||                 loss : 1.340, acc : 0.641\n",
            "Epoch : 42 || 350/368 ||                 loss : 1.309, acc : 0.594\n",
            "Validation result of epoch 42/100 || val_loss : 1.093 val_acc : 0.681 \n",
            "Epoch : 43 || 0/368 ||                 loss : 0.985, acc : 0.688\n",
            "Epoch : 43 || 50/368 ||                 loss : 1.066, acc : 0.656\n",
            "Epoch : 43 || 100/368 ||                 loss : 1.153, acc : 0.609\n",
            "Epoch : 43 || 150/368 ||                 loss : 1.389, acc : 0.641\n",
            "Epoch : 43 || 200/368 ||                 loss : 1.331, acc : 0.609\n",
            "Epoch : 43 || 250/368 ||                 loss : 1.088, acc : 0.672\n",
            "Epoch : 43 || 300/368 ||                 loss : 1.266, acc : 0.594\n",
            "Epoch : 43 || 350/368 ||                 loss : 1.192, acc : 0.625\n",
            "Validation result of epoch 43/100 || val_loss : 1.079 val_acc : 0.682 \n",
            "Epoch : 44 || 0/368 ||                 loss : 1.378, acc : 0.578\n",
            "Epoch : 44 || 50/368 ||                 loss : 1.098, acc : 0.656\n",
            "Epoch : 44 || 100/368 ||                 loss : 1.453, acc : 0.594\n",
            "Epoch : 44 || 150/368 ||                 loss : 1.204, acc : 0.688\n",
            "Epoch : 44 || 200/368 ||                 loss : 1.236, acc : 0.625\n",
            "Epoch : 44 || 250/368 ||                 loss : 1.147, acc : 0.703\n",
            "Epoch : 44 || 300/368 ||                 loss : 1.088, acc : 0.672\n",
            "Epoch : 44 || 350/368 ||                 loss : 1.191, acc : 0.703\n",
            "Validation result of epoch 44/100 || val_loss : 1.098 val_acc : 0.676 \n",
            "Epoch : 45 || 0/368 ||                 loss : 1.115, acc : 0.641\n",
            "Epoch : 45 || 50/368 ||                 loss : 1.482, acc : 0.562\n",
            "Epoch : 45 || 100/368 ||                 loss : 1.227, acc : 0.641\n",
            "Epoch : 45 || 150/368 ||                 loss : 1.169, acc : 0.656\n",
            "Epoch : 45 || 200/368 ||                 loss : 0.935, acc : 0.781\n",
            "Epoch : 45 || 250/368 ||                 loss : 0.941, acc : 0.703\n",
            "Epoch : 45 || 300/368 ||                 loss : 1.274, acc : 0.656\n",
            "Epoch : 45 || 350/368 ||                 loss : 0.976, acc : 0.766\n",
            "Validation result of epoch 45/100 || val_loss : 1.097 val_acc : 0.675 \n",
            "Epoch : 46 || 0/368 ||                 loss : 1.076, acc : 0.688\n",
            "Epoch : 46 || 50/368 ||                 loss : 1.114, acc : 0.609\n",
            "Epoch : 46 || 100/368 ||                 loss : 1.660, acc : 0.500\n",
            "Epoch : 46 || 150/368 ||                 loss : 1.237, acc : 0.656\n",
            "Epoch : 46 || 200/368 ||                 loss : 1.193, acc : 0.672\n",
            "Epoch : 46 || 250/368 ||                 loss : 1.302, acc : 0.609\n",
            "Epoch : 46 || 300/368 ||                 loss : 1.254, acc : 0.609\n",
            "Epoch : 46 || 350/368 ||                 loss : 1.106, acc : 0.609\n",
            "Validation result of epoch 46/100 || val_loss : 1.088 val_acc : 0.679 \n",
            "Epoch : 47 || 0/368 ||                 loss : 1.262, acc : 0.672\n",
            "Epoch : 47 || 50/368 ||                 loss : 1.451, acc : 0.547\n",
            "Epoch : 47 || 100/368 ||                 loss : 1.415, acc : 0.609\n",
            "Epoch : 47 || 150/368 ||                 loss : 1.259, acc : 0.562\n",
            "Epoch : 47 || 200/368 ||                 loss : 1.171, acc : 0.625\n",
            "Epoch : 47 || 250/368 ||                 loss : 1.243, acc : 0.656\n",
            "Epoch : 47 || 300/368 ||                 loss : 1.168, acc : 0.641\n",
            "Epoch : 47 || 350/368 ||                 loss : 1.409, acc : 0.594\n",
            "Validation result of epoch 47/100 || val_loss : 1.092 val_acc : 0.676 \n",
            "Epoch : 48 || 0/368 ||                 loss : 1.413, acc : 0.578\n",
            "Epoch : 48 || 50/368 ||                 loss : 1.502, acc : 0.516\n",
            "Epoch : 48 || 100/368 ||                 loss : 1.108, acc : 0.672\n",
            "Epoch : 48 || 150/368 ||                 loss : 1.047, acc : 0.703\n",
            "Epoch : 48 || 200/368 ||                 loss : 1.229, acc : 0.656\n",
            "Epoch : 48 || 250/368 ||                 loss : 1.078, acc : 0.641\n",
            "Epoch : 48 || 300/368 ||                 loss : 1.061, acc : 0.625\n",
            "Epoch : 48 || 350/368 ||                 loss : 1.403, acc : 0.578\n",
            "Validation result of epoch 48/100 || val_loss : 1.089 val_acc : 0.677 \n",
            "Epoch : 49 || 0/368 ||                 loss : 1.296, acc : 0.656\n",
            "Epoch : 49 || 50/368 ||                 loss : 1.157, acc : 0.672\n",
            "Epoch : 49 || 100/368 ||                 loss : 0.947, acc : 0.688\n",
            "Epoch : 49 || 150/368 ||                 loss : 1.105, acc : 0.672\n",
            "Epoch : 49 || 200/368 ||                 loss : 1.501, acc : 0.547\n",
            "Epoch : 49 || 250/368 ||                 loss : 1.048, acc : 0.672\n",
            "Epoch : 49 || 300/368 ||                 loss : 1.181, acc : 0.641\n",
            "Epoch : 49 || 350/368 ||                 loss : 1.133, acc : 0.688\n",
            "Validation result of epoch 49/100 || val_loss : 1.095 val_acc : 0.676 \n",
            "Epoch : 50 || 0/368 ||                 loss : 0.950, acc : 0.703\n",
            "Epoch : 50 || 50/368 ||                 loss : 1.278, acc : 0.578\n",
            "Epoch : 50 || 100/368 ||                 loss : 1.089, acc : 0.656\n",
            "Epoch : 50 || 150/368 ||                 loss : 0.803, acc : 0.766\n",
            "Epoch : 50 || 200/368 ||                 loss : 0.861, acc : 0.797\n",
            "Epoch : 50 || 250/368 ||                 loss : 0.906, acc : 0.766\n",
            "Epoch : 50 || 300/368 ||                 loss : 0.982, acc : 0.703\n",
            "Epoch : 50 || 350/368 ||                 loss : 1.021, acc : 0.719\n",
            "Validation result of epoch 50/100 || val_loss : 1.063 val_acc : 0.688 \n",
            "Epoch : 51 || 0/368 ||                 loss : 1.044, acc : 0.609\n",
            "Epoch : 51 || 50/368 ||                 loss : 1.107, acc : 0.672\n",
            "Epoch : 51 || 100/368 ||                 loss : 1.123, acc : 0.578\n",
            "Epoch : 51 || 150/368 ||                 loss : 1.271, acc : 0.594\n",
            "Epoch : 51 || 200/368 ||                 loss : 1.013, acc : 0.688\n",
            "Epoch : 51 || 250/368 ||                 loss : 1.016, acc : 0.719\n",
            "Epoch : 51 || 300/368 ||                 loss : 1.154, acc : 0.625\n",
            "Epoch : 51 || 350/368 ||                 loss : 1.621, acc : 0.453\n",
            "Validation result of epoch 51/100 || val_loss : 1.061 val_acc : 0.689 \n",
            "Epoch : 52 || 0/368 ||                 loss : 1.307, acc : 0.578\n",
            "Epoch : 52 || 50/368 ||                 loss : 1.138, acc : 0.625\n",
            "Epoch : 52 || 100/368 ||                 loss : 1.311, acc : 0.594\n",
            "Epoch : 52 || 150/368 ||                 loss : 1.329, acc : 0.672\n",
            "Epoch : 52 || 200/368 ||                 loss : 1.076, acc : 0.719\n",
            "Epoch : 52 || 250/368 ||                 loss : 1.003, acc : 0.672\n",
            "Epoch : 52 || 300/368 ||                 loss : 1.020, acc : 0.688\n",
            "Epoch : 52 || 350/368 ||                 loss : 1.164, acc : 0.656\n",
            "Validation result of epoch 52/100 || val_loss : 1.061 val_acc : 0.688 \n",
            "Epoch : 53 || 0/368 ||                 loss : 1.009, acc : 0.703\n",
            "Epoch : 53 || 50/368 ||                 loss : 1.031, acc : 0.703\n",
            "Epoch : 53 || 100/368 ||                 loss : 1.065, acc : 0.703\n",
            "Epoch : 53 || 150/368 ||                 loss : 1.322, acc : 0.641\n",
            "Epoch : 53 || 200/368 ||                 loss : 1.032, acc : 0.688\n",
            "Epoch : 53 || 250/368 ||                 loss : 0.988, acc : 0.734\n",
            "Epoch : 53 || 300/368 ||                 loss : 1.240, acc : 0.594\n",
            "Epoch : 53 || 350/368 ||                 loss : 1.083, acc : 0.719\n",
            "Validation result of epoch 53/100 || val_loss : 1.064 val_acc : 0.685 \n",
            "Epoch : 54 || 0/368 ||                 loss : 1.200, acc : 0.609\n",
            "Epoch : 54 || 50/368 ||                 loss : 0.938, acc : 0.719\n",
            "Epoch : 54 || 100/368 ||                 loss : 1.063, acc : 0.656\n",
            "Epoch : 54 || 150/368 ||                 loss : 1.252, acc : 0.578\n",
            "Epoch : 54 || 200/368 ||                 loss : 1.004, acc : 0.688\n",
            "Epoch : 54 || 250/368 ||                 loss : 1.185, acc : 0.578\n",
            "Epoch : 54 || 300/368 ||                 loss : 0.877, acc : 0.781\n",
            "Epoch : 54 || 350/368 ||                 loss : 1.155, acc : 0.562\n",
            "Validation result of epoch 54/100 || val_loss : 1.063 val_acc : 0.683 \n",
            "Epoch : 55 || 0/368 ||                 loss : 0.942, acc : 0.719\n",
            "Epoch : 55 || 50/368 ||                 loss : 1.387, acc : 0.562\n",
            "Epoch : 55 || 100/368 ||                 loss : 1.201, acc : 0.672\n",
            "Epoch : 55 || 150/368 ||                 loss : 1.135, acc : 0.641\n",
            "Epoch : 55 || 200/368 ||                 loss : 1.198, acc : 0.625\n",
            "Epoch : 55 || 250/368 ||                 loss : 1.109, acc : 0.656\n",
            "Epoch : 55 || 300/368 ||                 loss : 1.359, acc : 0.641\n",
            "Epoch : 55 || 350/368 ||                 loss : 1.143, acc : 0.656\n",
            "Validation result of epoch 55/100 || val_loss : 1.063 val_acc : 0.685 \n",
            "Epoch : 56 || 0/368 ||                 loss : 1.131, acc : 0.719\n",
            "Epoch : 56 || 50/368 ||                 loss : 0.912, acc : 0.656\n",
            "Epoch : 56 || 100/368 ||                 loss : 0.900, acc : 0.766\n",
            "Epoch : 56 || 150/368 ||                 loss : 1.079, acc : 0.625\n",
            "Epoch : 56 || 200/368 ||                 loss : 1.021, acc : 0.734\n",
            "Epoch : 56 || 250/368 ||                 loss : 1.010, acc : 0.688\n",
            "Epoch : 56 || 300/368 ||                 loss : 1.143, acc : 0.688\n",
            "Epoch : 56 || 350/368 ||                 loss : 1.111, acc : 0.656\n",
            "Validation result of epoch 56/100 || val_loss : 1.061 val_acc : 0.685 \n",
            "Epoch : 57 || 0/368 ||                 loss : 1.236, acc : 0.688\n",
            "Epoch : 57 || 50/368 ||                 loss : 0.877, acc : 0.719\n",
            "Epoch : 57 || 100/368 ||                 loss : 1.139, acc : 0.625\n",
            "Epoch : 57 || 150/368 ||                 loss : 1.207, acc : 0.672\n",
            "Epoch : 57 || 200/368 ||                 loss : 0.956, acc : 0.750\n",
            "Epoch : 57 || 250/368 ||                 loss : 0.963, acc : 0.719\n",
            "Epoch : 57 || 300/368 ||                 loss : 1.073, acc : 0.688\n",
            "Epoch : 57 || 350/368 ||                 loss : 1.099, acc : 0.641\n",
            "Validation result of epoch 57/100 || val_loss : 1.072 val_acc : 0.684 \n",
            "Epoch : 58 || 0/368 ||                 loss : 1.523, acc : 0.547\n",
            "Epoch : 58 || 50/368 ||                 loss : 1.054, acc : 0.656\n",
            "Epoch : 58 || 100/368 ||                 loss : 1.028, acc : 0.703\n",
            "Epoch : 58 || 150/368 ||                 loss : 1.258, acc : 0.703\n",
            "Epoch : 58 || 200/368 ||                 loss : 1.072, acc : 0.609\n",
            "Epoch : 58 || 250/368 ||                 loss : 1.078, acc : 0.688\n",
            "Epoch : 58 || 300/368 ||                 loss : 1.297, acc : 0.609\n",
            "Epoch : 58 || 350/368 ||                 loss : 1.344, acc : 0.625\n",
            "Validation result of epoch 58/100 || val_loss : 1.056 val_acc : 0.689 \n",
            "Epoch : 59 || 0/368 ||                 loss : 1.229, acc : 0.562\n",
            "Epoch : 59 || 50/368 ||                 loss : 1.373, acc : 0.500\n",
            "Epoch : 59 || 100/368 ||                 loss : 1.241, acc : 0.625\n",
            "Epoch : 59 || 150/368 ||                 loss : 1.314, acc : 0.594\n",
            "Epoch : 59 || 200/368 ||                 loss : 0.972, acc : 0.672\n",
            "Epoch : 59 || 250/368 ||                 loss : 1.455, acc : 0.578\n",
            "Epoch : 59 || 300/368 ||                 loss : 0.924, acc : 0.734\n",
            "Epoch : 59 || 350/368 ||                 loss : 0.959, acc : 0.688\n",
            "Validation result of epoch 59/100 || val_loss : 1.067 val_acc : 0.682 \n",
            "Epoch : 60 || 0/368 ||                 loss : 0.977, acc : 0.688\n",
            "Epoch : 60 || 50/368 ||                 loss : 0.983, acc : 0.641\n",
            "Epoch : 60 || 100/368 ||                 loss : 0.904, acc : 0.703\n",
            "Epoch : 60 || 150/368 ||                 loss : 1.058, acc : 0.656\n",
            "Epoch : 60 || 200/368 ||                 loss : 0.884, acc : 0.703\n",
            "Epoch : 60 || 250/368 ||                 loss : 1.120, acc : 0.703\n",
            "Epoch : 60 || 300/368 ||                 loss : 0.873, acc : 0.781\n",
            "Epoch : 60 || 350/368 ||                 loss : 1.152, acc : 0.656\n",
            "Validation result of epoch 60/100 || val_loss : 1.055 val_acc : 0.686 \n",
            "Epoch : 61 || 0/368 ||                 loss : 1.085, acc : 0.656\n",
            "Epoch : 61 || 50/368 ||                 loss : 0.960, acc : 0.750\n",
            "Epoch : 61 || 100/368 ||                 loss : 1.301, acc : 0.594\n",
            "Epoch : 61 || 150/368 ||                 loss : 0.836, acc : 0.734\n",
            "Epoch : 61 || 200/368 ||                 loss : 0.940, acc : 0.719\n",
            "Epoch : 61 || 250/368 ||                 loss : 1.127, acc : 0.641\n",
            "Epoch : 61 || 300/368 ||                 loss : 1.094, acc : 0.625\n",
            "Epoch : 61 || 350/368 ||                 loss : 1.173, acc : 0.641\n",
            "Validation result of epoch 61/100 || val_loss : 1.052 val_acc : 0.690 \n",
            "Epoch : 62 || 0/368 ||                 loss : 1.208, acc : 0.656\n",
            "Epoch : 62 || 50/368 ||                 loss : 1.175, acc : 0.609\n",
            "Epoch : 62 || 100/368 ||                 loss : 1.015, acc : 0.734\n",
            "Epoch : 62 || 150/368 ||                 loss : 1.042, acc : 0.688\n",
            "Epoch : 62 || 200/368 ||                 loss : 1.425, acc : 0.578\n",
            "Epoch : 62 || 250/368 ||                 loss : 1.168, acc : 0.656\n",
            "Epoch : 62 || 300/368 ||                 loss : 1.034, acc : 0.766\n",
            "Epoch : 62 || 350/368 ||                 loss : 1.031, acc : 0.609\n",
            "Validation result of epoch 62/100 || val_loss : 1.057 val_acc : 0.689 \n",
            "Epoch : 63 || 0/368 ||                 loss : 1.136, acc : 0.719\n",
            "Epoch : 63 || 50/368 ||                 loss : 0.862, acc : 0.703\n",
            "Epoch : 63 || 100/368 ||                 loss : 1.124, acc : 0.672\n",
            "Epoch : 63 || 150/368 ||                 loss : 1.185, acc : 0.641\n",
            "Epoch : 63 || 200/368 ||                 loss : 0.880, acc : 0.766\n",
            "Epoch : 63 || 250/368 ||                 loss : 0.810, acc : 0.750\n",
            "Epoch : 63 || 300/368 ||                 loss : 1.398, acc : 0.547\n",
            "Epoch : 63 || 350/368 ||                 loss : 0.856, acc : 0.781\n",
            "Validation result of epoch 63/100 || val_loss : 1.056 val_acc : 0.686 \n",
            "Epoch : 64 || 0/368 ||                 loss : 1.228, acc : 0.609\n",
            "Epoch : 64 || 50/368 ||                 loss : 1.351, acc : 0.594\n",
            "Epoch : 64 || 100/368 ||                 loss : 1.057, acc : 0.641\n",
            "Epoch : 64 || 150/368 ||                 loss : 1.239, acc : 0.594\n",
            "Epoch : 64 || 200/368 ||                 loss : 1.080, acc : 0.734\n",
            "Epoch : 64 || 250/368 ||                 loss : 1.060, acc : 0.750\n",
            "Epoch : 64 || 300/368 ||                 loss : 1.342, acc : 0.625\n",
            "Epoch : 64 || 350/368 ||                 loss : 1.208, acc : 0.625\n",
            "Validation result of epoch 64/100 || val_loss : 1.055 val_acc : 0.686 \n",
            "Epoch : 65 || 0/368 ||                 loss : 1.076, acc : 0.672\n",
            "Epoch : 65 || 50/368 ||                 loss : 0.948, acc : 0.734\n",
            "Epoch : 65 || 100/368 ||                 loss : 1.014, acc : 0.734\n",
            "Epoch : 65 || 150/368 ||                 loss : 1.209, acc : 0.641\n",
            "Epoch : 65 || 200/368 ||                 loss : 1.131, acc : 0.641\n",
            "Epoch : 65 || 250/368 ||                 loss : 1.216, acc : 0.703\n",
            "Epoch : 65 || 300/368 ||                 loss : 1.173, acc : 0.641\n",
            "Epoch : 65 || 350/368 ||                 loss : 0.939, acc : 0.688\n",
            "Validation result of epoch 65/100 || val_loss : 1.054 val_acc : 0.689 \n",
            "Epoch : 66 || 0/368 ||                 loss : 0.992, acc : 0.656\n",
            "Epoch : 66 || 50/368 ||                 loss : 0.952, acc : 0.734\n",
            "Epoch : 66 || 100/368 ||                 loss : 0.992, acc : 0.641\n",
            "Epoch : 66 || 150/368 ||                 loss : 0.870, acc : 0.781\n",
            "Epoch : 66 || 200/368 ||                 loss : 1.030, acc : 0.656\n",
            "Epoch : 66 || 250/368 ||                 loss : 1.099, acc : 0.656\n",
            "Epoch : 66 || 300/368 ||                 loss : 0.901, acc : 0.672\n",
            "Epoch : 66 || 350/368 ||                 loss : 0.879, acc : 0.703\n",
            "Validation result of epoch 66/100 || val_loss : 1.061 val_acc : 0.686 \n",
            "Epoch : 67 || 0/368 ||                 loss : 0.937, acc : 0.703\n",
            "Epoch : 67 || 50/368 ||                 loss : 0.837, acc : 0.703\n",
            "Epoch : 67 || 100/368 ||                 loss : 1.049, acc : 0.656\n",
            "Epoch : 67 || 150/368 ||                 loss : 1.165, acc : 0.703\n",
            "Epoch : 67 || 200/368 ||                 loss : 1.172, acc : 0.594\n",
            "Epoch : 67 || 250/368 ||                 loss : 1.193, acc : 0.625\n",
            "Epoch : 67 || 300/368 ||                 loss : 0.887, acc : 0.703\n",
            "Epoch : 67 || 350/368 ||                 loss : 1.144, acc : 0.656\n",
            "Validation result of epoch 67/100 || val_loss : 1.049 val_acc : 0.687 \n",
            "Epoch : 68 || 0/368 ||                 loss : 1.115, acc : 0.625\n",
            "Epoch : 68 || 50/368 ||                 loss : 0.953, acc : 0.719\n",
            "Epoch : 68 || 100/368 ||                 loss : 1.484, acc : 0.547\n",
            "Epoch : 68 || 150/368 ||                 loss : 1.058, acc : 0.719\n",
            "Epoch : 68 || 200/368 ||                 loss : 0.983, acc : 0.750\n",
            "Epoch : 68 || 250/368 ||                 loss : 1.229, acc : 0.656\n",
            "Epoch : 68 || 300/368 ||                 loss : 1.006, acc : 0.734\n",
            "Epoch : 68 || 350/368 ||                 loss : 1.109, acc : 0.688\n",
            "Validation result of epoch 68/100 || val_loss : 1.059 val_acc : 0.685 \n",
            "Epoch : 69 || 0/368 ||                 loss : 0.851, acc : 0.734\n",
            "Epoch : 69 || 50/368 ||                 loss : 1.202, acc : 0.641\n",
            "Epoch : 69 || 100/368 ||                 loss : 0.998, acc : 0.703\n",
            "Epoch : 69 || 150/368 ||                 loss : 1.513, acc : 0.578\n",
            "Epoch : 69 || 200/368 ||                 loss : 0.903, acc : 0.719\n",
            "Epoch : 69 || 250/368 ||                 loss : 1.304, acc : 0.672\n",
            "Epoch : 69 || 300/368 ||                 loss : 1.213, acc : 0.609\n",
            "Epoch : 69 || 350/368 ||                 loss : 1.268, acc : 0.625\n",
            "Validation result of epoch 69/100 || val_loss : 1.046 val_acc : 0.691 \n",
            "Epoch : 70 || 0/368 ||                 loss : 0.853, acc : 0.750\n",
            "Epoch : 70 || 50/368 ||                 loss : 0.960, acc : 0.672\n",
            "Epoch : 70 || 100/368 ||                 loss : 1.258, acc : 0.594\n",
            "Epoch : 70 || 150/368 ||                 loss : 1.073, acc : 0.641\n",
            "Epoch : 70 || 200/368 ||                 loss : 0.945, acc : 0.703\n",
            "Epoch : 70 || 250/368 ||                 loss : 0.900, acc : 0.719\n",
            "Epoch : 70 || 300/368 ||                 loss : 1.195, acc : 0.625\n",
            "Epoch : 70 || 350/368 ||                 loss : 1.110, acc : 0.594\n",
            "Validation result of epoch 70/100 || val_loss : 1.050 val_acc : 0.690 \n",
            "Epoch : 71 || 0/368 ||                 loss : 1.303, acc : 0.672\n",
            "Epoch : 71 || 50/368 ||                 loss : 0.875, acc : 0.734\n",
            "Epoch : 71 || 100/368 ||                 loss : 1.301, acc : 0.562\n",
            "Epoch : 71 || 150/368 ||                 loss : 0.992, acc : 0.688\n",
            "Epoch : 71 || 200/368 ||                 loss : 0.867, acc : 0.766\n",
            "Epoch : 71 || 250/368 ||                 loss : 1.175, acc : 0.594\n",
            "Epoch : 71 || 300/368 ||                 loss : 1.183, acc : 0.641\n",
            "Epoch : 71 || 350/368 ||                 loss : 1.273, acc : 0.578\n",
            "Validation result of epoch 71/100 || val_loss : 1.065 val_acc : 0.683 \n",
            "Epoch : 72 || 0/368 ||                 loss : 1.303, acc : 0.672\n",
            "Epoch : 72 || 50/368 ||                 loss : 1.225, acc : 0.641\n",
            "Epoch : 72 || 100/368 ||                 loss : 0.830, acc : 0.766\n",
            "Epoch : 72 || 150/368 ||                 loss : 1.082, acc : 0.672\n",
            "Epoch : 72 || 200/368 ||                 loss : 1.029, acc : 0.750\n",
            "Epoch : 72 || 250/368 ||                 loss : 0.814, acc : 0.719\n",
            "Epoch : 72 || 300/368 ||                 loss : 1.163, acc : 0.609\n",
            "Epoch : 72 || 350/368 ||                 loss : 1.285, acc : 0.641\n",
            "Validation result of epoch 72/100 || val_loss : 1.058 val_acc : 0.686 \n",
            "Epoch : 73 || 0/368 ||                 loss : 1.245, acc : 0.562\n",
            "Epoch : 73 || 50/368 ||                 loss : 1.256, acc : 0.578\n",
            "Epoch : 73 || 100/368 ||                 loss : 1.042, acc : 0.688\n",
            "Epoch : 73 || 150/368 ||                 loss : 1.129, acc : 0.672\n",
            "Epoch : 73 || 200/368 ||                 loss : 0.869, acc : 0.750\n",
            "Epoch : 73 || 250/368 ||                 loss : 1.095, acc : 0.641\n",
            "Epoch : 73 || 300/368 ||                 loss : 0.953, acc : 0.719\n",
            "Epoch : 73 || 350/368 ||                 loss : 1.064, acc : 0.703\n",
            "Validation result of epoch 73/100 || val_loss : 1.058 val_acc : 0.688 \n",
            "Epoch : 74 || 0/368 ||                 loss : 1.230, acc : 0.609\n",
            "Epoch : 74 || 50/368 ||                 loss : 1.314, acc : 0.656\n",
            "Epoch : 74 || 100/368 ||                 loss : 0.770, acc : 0.734\n",
            "Epoch : 74 || 150/368 ||                 loss : 1.205, acc : 0.641\n",
            "Epoch : 74 || 200/368 ||                 loss : 1.046, acc : 0.641\n",
            "Epoch : 74 || 250/368 ||                 loss : 0.865, acc : 0.750\n",
            "Epoch : 74 || 300/368 ||                 loss : 1.193, acc : 0.641\n",
            "Epoch : 74 || 350/368 ||                 loss : 0.876, acc : 0.734\n",
            "Validation result of epoch 74/100 || val_loss : 1.064 val_acc : 0.684 \n",
            "Epoch : 75 || 0/368 ||                 loss : 1.053, acc : 0.672\n",
            "Epoch : 75 || 50/368 ||                 loss : 1.078, acc : 0.656\n",
            "Epoch : 75 || 100/368 ||                 loss : 0.794, acc : 0.797\n",
            "Epoch : 75 || 150/368 ||                 loss : 1.078, acc : 0.672\n",
            "Epoch : 75 || 200/368 ||                 loss : 0.887, acc : 0.734\n",
            "Epoch : 75 || 250/368 ||                 loss : 1.040, acc : 0.672\n",
            "Epoch : 75 || 300/368 ||                 loss : 1.088, acc : 0.641\n",
            "Epoch : 75 || 350/368 ||                 loss : 1.154, acc : 0.625\n",
            "Validation result of epoch 75/100 || val_loss : 1.054 val_acc : 0.690 \n",
            "Epoch : 76 || 0/368 ||                 loss : 0.917, acc : 0.719\n",
            "Epoch : 76 || 50/368 ||                 loss : 1.147, acc : 0.672\n",
            "Epoch : 76 || 100/368 ||                 loss : 1.178, acc : 0.703\n",
            "Epoch : 76 || 150/368 ||                 loss : 1.162, acc : 0.641\n",
            "Epoch : 76 || 200/368 ||                 loss : 0.837, acc : 0.719\n",
            "Epoch : 76 || 250/368 ||                 loss : 0.797, acc : 0.719\n",
            "Epoch : 76 || 300/368 ||                 loss : 1.148, acc : 0.625\n",
            "Epoch : 76 || 350/368 ||                 loss : 1.106, acc : 0.656\n",
            "Validation result of epoch 76/100 || val_loss : 1.056 val_acc : 0.689 \n",
            "Epoch : 77 || 0/368 ||                 loss : 1.001, acc : 0.703\n",
            "Epoch : 77 || 50/368 ||                 loss : 0.901, acc : 0.688\n",
            "Epoch : 77 || 100/368 ||                 loss : 1.070, acc : 0.625\n",
            "Epoch : 77 || 150/368 ||                 loss : 1.112, acc : 0.656\n",
            "Epoch : 77 || 200/368 ||                 loss : 1.173, acc : 0.656\n",
            "Epoch : 77 || 250/368 ||                 loss : 1.316, acc : 0.625\n",
            "Epoch : 77 || 300/368 ||                 loss : 1.143, acc : 0.641\n",
            "Epoch : 77 || 350/368 ||                 loss : 1.095, acc : 0.641\n",
            "Validation result of epoch 77/100 || val_loss : 1.058 val_acc : 0.686 \n",
            "Epoch : 78 || 0/368 ||                 loss : 1.125, acc : 0.703\n",
            "Epoch : 78 || 50/368 ||                 loss : 1.312, acc : 0.562\n",
            "Epoch : 78 || 100/368 ||                 loss : 0.905, acc : 0.703\n",
            "Epoch : 78 || 150/368 ||                 loss : 1.409, acc : 0.562\n",
            "Epoch : 78 || 200/368 ||                 loss : 1.262, acc : 0.641\n",
            "Epoch : 78 || 250/368 ||                 loss : 1.165, acc : 0.609\n",
            "Epoch : 78 || 300/368 ||                 loss : 0.879, acc : 0.688\n",
            "Epoch : 78 || 350/368 ||                 loss : 1.151, acc : 0.578\n",
            "Validation result of epoch 78/100 || val_loss : 1.050 val_acc : 0.689 \n",
            "Epoch : 79 || 0/368 ||                 loss : 1.096, acc : 0.641\n",
            "Epoch : 79 || 50/368 ||                 loss : 1.034, acc : 0.641\n",
            "Epoch : 79 || 100/368 ||                 loss : 1.044, acc : 0.641\n",
            "Epoch : 79 || 150/368 ||                 loss : 1.268, acc : 0.594\n",
            "Epoch : 79 || 200/368 ||                 loss : 0.809, acc : 0.797\n",
            "Epoch : 79 || 250/368 ||                 loss : 0.968, acc : 0.688\n",
            "Epoch : 79 || 300/368 ||                 loss : 1.171, acc : 0.656\n",
            "Epoch : 79 || 350/368 ||                 loss : 0.979, acc : 0.734\n",
            "Validation result of epoch 79/100 || val_loss : 1.049 val_acc : 0.689 \n",
            "Epoch : 80 || 0/368 ||                 loss : 1.462, acc : 0.562\n",
            "Epoch : 80 || 50/368 ||                 loss : 1.102, acc : 0.594\n",
            "Epoch : 80 || 100/368 ||                 loss : 1.293, acc : 0.656\n",
            "Epoch : 80 || 150/368 ||                 loss : 1.303, acc : 0.641\n",
            "Epoch : 80 || 200/368 ||                 loss : 1.011, acc : 0.688\n",
            "Epoch : 80 || 250/368 ||                 loss : 0.960, acc : 0.734\n",
            "Epoch : 80 || 300/368 ||                 loss : 1.158, acc : 0.625\n",
            "Epoch : 80 || 350/368 ||                 loss : 1.098, acc : 0.734\n",
            "Validation result of epoch 80/100 || val_loss : 1.044 val_acc : 0.693 \n",
            "Epoch : 81 || 0/368 ||                 loss : 1.409, acc : 0.625\n",
            "Epoch : 81 || 50/368 ||                 loss : 1.028, acc : 0.672\n",
            "Epoch : 81 || 100/368 ||                 loss : 1.345, acc : 0.547\n",
            "Epoch : 81 || 150/368 ||                 loss : 0.908, acc : 0.750\n",
            "Epoch : 81 || 200/368 ||                 loss : 1.035, acc : 0.641\n",
            "Epoch : 81 || 250/368 ||                 loss : 0.708, acc : 0.797\n",
            "Epoch : 81 || 300/368 ||                 loss : 1.198, acc : 0.672\n",
            "Epoch : 81 || 350/368 ||                 loss : 1.232, acc : 0.625\n",
            "Validation result of epoch 81/100 || val_loss : 1.042 val_acc : 0.690 \n",
            "Epoch : 82 || 0/368 ||                 loss : 0.972, acc : 0.641\n",
            "Epoch : 82 || 50/368 ||                 loss : 0.935, acc : 0.703\n",
            "Epoch : 82 || 100/368 ||                 loss : 1.223, acc : 0.609\n",
            "Epoch : 82 || 150/368 ||                 loss : 1.235, acc : 0.594\n",
            "Epoch : 82 || 200/368 ||                 loss : 0.791, acc : 0.766\n",
            "Epoch : 82 || 250/368 ||                 loss : 1.162, acc : 0.641\n",
            "Epoch : 82 || 300/368 ||                 loss : 0.833, acc : 0.734\n",
            "Epoch : 82 || 350/368 ||                 loss : 0.951, acc : 0.703\n",
            "Validation result of epoch 82/100 || val_loss : 1.039 val_acc : 0.695 \n",
            "Epoch : 83 || 0/368 ||                 loss : 1.131, acc : 0.625\n",
            "Epoch : 83 || 50/368 ||                 loss : 1.037, acc : 0.719\n",
            "Epoch : 83 || 100/368 ||                 loss : 0.933, acc : 0.750\n",
            "Epoch : 83 || 150/368 ||                 loss : 1.014, acc : 0.750\n",
            "Epoch : 83 || 200/368 ||                 loss : 1.193, acc : 0.641\n",
            "Epoch : 83 || 250/368 ||                 loss : 0.995, acc : 0.703\n",
            "Epoch : 83 || 300/368 ||                 loss : 0.898, acc : 0.781\n",
            "Epoch : 83 || 350/368 ||                 loss : 1.295, acc : 0.547\n",
            "Validation result of epoch 83/100 || val_loss : 1.044 val_acc : 0.690 \n",
            "Epoch : 84 || 0/368 ||                 loss : 1.029, acc : 0.703\n",
            "Epoch : 84 || 50/368 ||                 loss : 1.043, acc : 0.672\n",
            "Epoch : 84 || 100/368 ||                 loss : 1.105, acc : 0.625\n",
            "Epoch : 84 || 150/368 ||                 loss : 1.075, acc : 0.641\n",
            "Epoch : 84 || 200/368 ||                 loss : 1.145, acc : 0.641\n",
            "Epoch : 84 || 250/368 ||                 loss : 1.103, acc : 0.656\n",
            "Epoch : 84 || 300/368 ||                 loss : 1.202, acc : 0.656\n",
            "Epoch : 84 || 350/368 ||                 loss : 1.077, acc : 0.641\n",
            "Validation result of epoch 84/100 || val_loss : 1.044 val_acc : 0.692 \n",
            "Epoch : 85 || 0/368 ||                 loss : 1.015, acc : 0.688\n",
            "Epoch : 85 || 50/368 ||                 loss : 0.924, acc : 0.719\n",
            "Epoch : 85 || 100/368 ||                 loss : 1.028, acc : 0.734\n",
            "Epoch : 85 || 150/368 ||                 loss : 1.062, acc : 0.672\n",
            "Epoch : 85 || 200/368 ||                 loss : 1.175, acc : 0.609\n",
            "Epoch : 85 || 250/368 ||                 loss : 1.156, acc : 0.688\n",
            "Epoch : 85 || 300/368 ||                 loss : 1.184, acc : 0.656\n",
            "Epoch : 85 || 350/368 ||                 loss : 1.037, acc : 0.656\n",
            "Validation result of epoch 85/100 || val_loss : 1.042 val_acc : 0.691 \n",
            "Epoch : 86 || 0/368 ||                 loss : 0.863, acc : 0.766\n",
            "Epoch : 86 || 50/368 ||                 loss : 1.071, acc : 0.688\n",
            "Epoch : 86 || 100/368 ||                 loss : 1.290, acc : 0.609\n",
            "Epoch : 86 || 150/368 ||                 loss : 1.063, acc : 0.672\n",
            "Epoch : 86 || 200/368 ||                 loss : 1.187, acc : 0.688\n",
            "Epoch : 86 || 250/368 ||                 loss : 1.116, acc : 0.734\n",
            "Epoch : 86 || 300/368 ||                 loss : 1.031, acc : 0.719\n",
            "Epoch : 86 || 350/368 ||                 loss : 1.112, acc : 0.672\n",
            "Validation result of epoch 86/100 || val_loss : 1.039 val_acc : 0.693 \n",
            "Epoch : 87 || 0/368 ||                 loss : 1.283, acc : 0.625\n",
            "Epoch : 87 || 50/368 ||                 loss : 0.989, acc : 0.734\n",
            "Epoch : 87 || 100/368 ||                 loss : 1.217, acc : 0.641\n",
            "Epoch : 87 || 150/368 ||                 loss : 1.159, acc : 0.594\n",
            "Epoch : 87 || 200/368 ||                 loss : 1.176, acc : 0.609\n",
            "Epoch : 87 || 250/368 ||                 loss : 1.161, acc : 0.656\n",
            "Epoch : 87 || 300/368 ||                 loss : 1.505, acc : 0.609\n",
            "Epoch : 87 || 350/368 ||                 loss : 0.856, acc : 0.734\n",
            "Validation result of epoch 87/100 || val_loss : 1.042 val_acc : 0.690 \n",
            "Epoch : 88 || 0/368 ||                 loss : 0.615, acc : 0.797\n",
            "Epoch : 88 || 50/368 ||                 loss : 0.977, acc : 0.688\n",
            "Epoch : 88 || 100/368 ||                 loss : 1.585, acc : 0.594\n",
            "Epoch : 88 || 150/368 ||                 loss : 1.146, acc : 0.641\n",
            "Epoch : 88 || 200/368 ||                 loss : 1.209, acc : 0.625\n",
            "Epoch : 88 || 250/368 ||                 loss : 1.017, acc : 0.750\n",
            "Epoch : 88 || 300/368 ||                 loss : 0.967, acc : 0.703\n",
            "Epoch : 88 || 350/368 ||                 loss : 1.177, acc : 0.672\n",
            "Validation result of epoch 88/100 || val_loss : 1.040 val_acc : 0.688 \n",
            "Epoch : 89 || 0/368 ||                 loss : 1.264, acc : 0.672\n",
            "Epoch : 89 || 50/368 ||                 loss : 1.205, acc : 0.656\n",
            "Epoch : 89 || 100/368 ||                 loss : 1.113, acc : 0.609\n",
            "Epoch : 89 || 150/368 ||                 loss : 1.019, acc : 0.688\n",
            "Epoch : 89 || 200/368 ||                 loss : 1.390, acc : 0.625\n",
            "Epoch : 89 || 250/368 ||                 loss : 0.951, acc : 0.750\n",
            "Epoch : 89 || 300/368 ||                 loss : 1.485, acc : 0.578\n",
            "Epoch : 89 || 350/368 ||                 loss : 1.133, acc : 0.641\n",
            "Validation result of epoch 89/100 || val_loss : 1.041 val_acc : 0.694 \n",
            "Epoch : 90 || 0/368 ||                 loss : 1.012, acc : 0.734\n",
            "Epoch : 90 || 50/368 ||                 loss : 0.880, acc : 0.750\n",
            "Epoch : 90 || 100/368 ||                 loss : 1.039, acc : 0.734\n",
            "Epoch : 90 || 150/368 ||                 loss : 1.082, acc : 0.672\n",
            "Epoch : 90 || 200/368 ||                 loss : 1.040, acc : 0.641\n",
            "Epoch : 90 || 250/368 ||                 loss : 1.140, acc : 0.641\n",
            "Epoch : 90 || 300/368 ||                 loss : 1.217, acc : 0.656\n",
            "Epoch : 90 || 350/368 ||                 loss : 0.878, acc : 0.828\n",
            "Validation result of epoch 90/100 || val_loss : 1.041 val_acc : 0.690 \n",
            "Epoch : 91 || 0/368 ||                 loss : 1.120, acc : 0.703\n",
            "Epoch : 91 || 50/368 ||                 loss : 1.123, acc : 0.719\n",
            "Epoch : 91 || 100/368 ||                 loss : 1.188, acc : 0.656\n",
            "Epoch : 91 || 150/368 ||                 loss : 0.820, acc : 0.781\n",
            "Epoch : 91 || 200/368 ||                 loss : 0.797, acc : 0.781\n",
            "Epoch : 91 || 250/368 ||                 loss : 1.047, acc : 0.609\n",
            "Epoch : 91 || 300/368 ||                 loss : 0.958, acc : 0.703\n",
            "Epoch : 91 || 350/368 ||                 loss : 0.867, acc : 0.734\n",
            "Validation result of epoch 91/100 || val_loss : 1.045 val_acc : 0.691 \n",
            "Epoch : 92 || 0/368 ||                 loss : 0.970, acc : 0.703\n",
            "Epoch : 92 || 50/368 ||                 loss : 0.907, acc : 0.750\n",
            "Epoch : 92 || 100/368 ||                 loss : 1.064, acc : 0.641\n",
            "Epoch : 92 || 150/368 ||                 loss : 0.995, acc : 0.703\n",
            "Epoch : 92 || 200/368 ||                 loss : 0.856, acc : 0.734\n",
            "Epoch : 92 || 250/368 ||                 loss : 1.190, acc : 0.594\n",
            "Epoch : 92 || 300/368 ||                 loss : 0.879, acc : 0.750\n",
            "Epoch : 92 || 350/368 ||                 loss : 1.293, acc : 0.672\n",
            "Validation result of epoch 92/100 || val_loss : 1.035 val_acc : 0.694 \n",
            "Epoch : 93 || 0/368 ||                 loss : 0.842, acc : 0.688\n",
            "Epoch : 93 || 50/368 ||                 loss : 1.402, acc : 0.609\n",
            "Epoch : 93 || 100/368 ||                 loss : 0.919, acc : 0.766\n",
            "Epoch : 93 || 150/368 ||                 loss : 0.815, acc : 0.812\n",
            "Epoch : 93 || 200/368 ||                 loss : 1.233, acc : 0.609\n",
            "Epoch : 93 || 250/368 ||                 loss : 0.949, acc : 0.672\n",
            "Epoch : 93 || 300/368 ||                 loss : 1.016, acc : 0.656\n",
            "Epoch : 93 || 350/368 ||                 loss : 1.078, acc : 0.672\n",
            "Validation result of epoch 93/100 || val_loss : 1.040 val_acc : 0.692 \n",
            "Epoch : 94 || 0/368 ||                 loss : 1.127, acc : 0.688\n",
            "Epoch : 94 || 50/368 ||                 loss : 1.091, acc : 0.719\n",
            "Epoch : 94 || 100/368 ||                 loss : 0.885, acc : 0.703\n",
            "Epoch : 94 || 150/368 ||                 loss : 0.998, acc : 0.703\n",
            "Epoch : 94 || 200/368 ||                 loss : 1.166, acc : 0.672\n",
            "Epoch : 94 || 250/368 ||                 loss : 1.182, acc : 0.672\n",
            "Epoch : 94 || 300/368 ||                 loss : 1.365, acc : 0.594\n",
            "Epoch : 94 || 350/368 ||                 loss : 1.018, acc : 0.688\n",
            "Validation result of epoch 94/100 || val_loss : 1.043 val_acc : 0.693 \n",
            "Epoch : 95 || 0/368 ||                 loss : 1.098, acc : 0.703\n",
            "Epoch : 95 || 50/368 ||                 loss : 1.351, acc : 0.688\n",
            "Epoch : 95 || 100/368 ||                 loss : 1.058, acc : 0.719\n",
            "Epoch : 95 || 150/368 ||                 loss : 1.140, acc : 0.625\n",
            "Epoch : 95 || 200/368 ||                 loss : 1.208, acc : 0.641\n",
            "Epoch : 95 || 250/368 ||                 loss : 0.831, acc : 0.750\n",
            "Epoch : 95 || 300/368 ||                 loss : 1.060, acc : 0.672\n",
            "Epoch : 95 || 350/368 ||                 loss : 1.294, acc : 0.594\n",
            "Validation result of epoch 95/100 || val_loss : 1.044 val_acc : 0.693 \n",
            "Epoch : 96 || 0/368 ||                 loss : 1.329, acc : 0.672\n",
            "Epoch : 96 || 50/368 ||                 loss : 1.095, acc : 0.672\n",
            "Epoch : 96 || 100/368 ||                 loss : 1.095, acc : 0.703\n",
            "Epoch : 96 || 150/368 ||                 loss : 1.063, acc : 0.719\n",
            "Epoch : 96 || 200/368 ||                 loss : 1.027, acc : 0.609\n",
            "Epoch : 96 || 250/368 ||                 loss : 1.220, acc : 0.625\n",
            "Epoch : 96 || 300/368 ||                 loss : 0.811, acc : 0.703\n",
            "Epoch : 96 || 350/368 ||                 loss : 1.015, acc : 0.609\n",
            "Validation result of epoch 96/100 || val_loss : 1.036 val_acc : 0.695 \n",
            "Epoch : 97 || 0/368 ||                 loss : 0.879, acc : 0.797\n",
            "Epoch : 97 || 50/368 ||                 loss : 1.070, acc : 0.609\n",
            "Epoch : 97 || 100/368 ||                 loss : 1.001, acc : 0.672\n",
            "Epoch : 97 || 150/368 ||                 loss : 1.178, acc : 0.594\n",
            "Epoch : 97 || 200/368 ||                 loss : 1.040, acc : 0.688\n",
            "Epoch : 97 || 250/368 ||                 loss : 1.009, acc : 0.703\n",
            "Epoch : 97 || 300/368 ||                 loss : 1.038, acc : 0.703\n",
            "Epoch : 97 || 350/368 ||                 loss : 1.365, acc : 0.531\n",
            "Validation result of epoch 97/100 || val_loss : 1.043 val_acc : 0.689 \n",
            "Epoch : 98 || 0/368 ||                 loss : 0.829, acc : 0.766\n",
            "Epoch : 98 || 50/368 ||                 loss : 1.120, acc : 0.703\n",
            "Epoch : 98 || 100/368 ||                 loss : 0.930, acc : 0.672\n",
            "Epoch : 98 || 150/368 ||                 loss : 0.829, acc : 0.781\n",
            "Epoch : 98 || 200/368 ||                 loss : 1.158, acc : 0.656\n",
            "Epoch : 98 || 250/368 ||                 loss : 1.088, acc : 0.703\n",
            "Epoch : 98 || 300/368 ||                 loss : 1.003, acc : 0.688\n",
            "Epoch : 98 || 350/368 ||                 loss : 1.081, acc : 0.688\n",
            "Validation result of epoch 98/100 || val_loss : 1.042 val_acc : 0.693 \n",
            "Epoch : 99 || 0/368 ||                 loss : 1.036, acc : 0.656\n",
            "Epoch : 99 || 50/368 ||                 loss : 1.239, acc : 0.641\n",
            "Epoch : 99 || 100/368 ||                 loss : 0.885, acc : 0.766\n",
            "Epoch : 99 || 150/368 ||                 loss : 1.093, acc : 0.641\n",
            "Epoch : 99 || 200/368 ||                 loss : 1.036, acc : 0.719\n",
            "Epoch : 99 || 250/368 ||                 loss : 0.992, acc : 0.750\n",
            "Epoch : 99 || 300/368 ||                 loss : 1.114, acc : 0.688\n",
            "Epoch : 99 || 350/368 ||                 loss : 0.674, acc : 0.781\n",
            "Validation result of epoch 99/100 || val_loss : 1.036 val_acc : 0.692 \n",
            "Best validation accuracy of classifier network : 0.695 took 232.396 secs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Visualize**"
      ],
      "metadata": {
        "id": "2QCMX1MKmnYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Classification Training and Validation Loss\")\n",
        "plt.plot(train_loss_clf, label=\"train_loss\", color='red', linewidth=1.0)\n",
        "plt.plot(val_loss_clf, label=\"val_loss\", color='blue', linewidth=1.0)\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Classification Training and Validation Accuracy\")\n",
        "plt.plot(train_accuracy_clf, label=\"train_acc\", color='green', linewidth=1.0)\n",
        "plt.plot(val_accuracy_clf, label=\"val_acc\", color='orange', linewidth=1.0)\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout(4)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "p20GF8UBmXeV",
        "outputId": "f446f3c2-0a32-48f2-860a-fcd7b27cad9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Test**"
      ],
      "metadata": {
        "id": "XX-ug_PRmsYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Classifier(args.dim, len(labels))\n",
        "model.load_state_dict(best_val_model)\n",
        "model = model.to(device)\n",
        "pred_origins = [0]*len(labels)\n",
        "origins = list(labels.keys())\n",
        "test_origins = []\n",
        "model.eval()\n",
        "\n",
        "for batch_idx, data in enumerate(test_clf_dataloader):\n",
        "  x = data['recipe'].to(device=device)\n",
        "  pred = model(x)\n",
        "  pred = pred.type(torch.float).to(device)\n",
        "  pred = torch.argmax(torch.log_softmax(pred, 1), 1).tolist()\n",
        "  for idx in pred:\n",
        "    test_origins.append(origins[idx])\n",
        "    pred_origins[idx] += 1"
      ],
      "metadata": {
        "id": "6fB6c4uCmmtE"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(test_origins, columns = [\"origin\"]).to_csv(os.path.join(results, \"test_classification_answer.csv\"))"
      ],
      "metadata": {
        "id": "j9xzdTt0a6L2"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig1 = px.bar(x = list(labels.keys()), y = pred_origins, text_auto='.2s')\n",
        "fig1.update_layout(\n",
        "    xaxis={'categoryorder':'total descending'},\n",
        "    xaxis_title=\"Origin\",\n",
        "    yaxis_title = \"Frequency\",\n",
        "    title=\"Predicted Origins and their frequency\",\n",
        "    template=\"plotly_dark\")\n",
        "fig1.update_traces(textfont_size=12, textangle=0, textposition=\"outside\", cliponaxis=False)\n",
        "fig1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "s-3MWnzgkeYY",
        "outputId": "73e0ad3f-367d-473e-cd19-dccfee28b2d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"50dd6296-5e85-4304-83c1-06fbd357a822\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"50dd6296-5e85-4304-83c1-06fbd357a822\")) {                    Plotly.newPlot(                        \"50dd6296-5e85-4304-83c1-06fbd357a822\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"x=%{x}<br>y=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"outside\",\"texttemplate\":\"%{y:.2s}\",\"x\":[\"brazilian\",\"british\",\"cajun_creole\",\"chinese\",\"filipino\",\"french\",\"greek\",\"indian\",\"irish\",\"italian\",\"jamaican\",\"japanese\",\"korean\",\"mexican\",\"moroccan\",\"russian\",\"southern_us\",\"spanish\",\"thai\",\"vietnamese\"],\"xaxis\":\"x\",\"y\":[27,36,129,262,58,274,86,307,35,946,38,96,70,695,88,27,494,48,144,64],\"yaxis\":\"y\",\"type\":\"bar\",\"textfont\":{\"size\":12},\"cliponaxis\":false,\"textangle\":0}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#f2f5fa\"},\"error_y\":{\"color\":\"#f2f5fa\"},\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"baxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#506784\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"header\":{\"fill\":{\"color\":\"#2a3f5f\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#f2f5fa\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#f2f5fa\"},\"geo\":{\"bgcolor\":\"rgb(17,17,17)\",\"lakecolor\":\"rgb(17,17,17)\",\"landcolor\":\"rgb(17,17,17)\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#506784\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"dark\"},\"paper_bgcolor\":\"rgb(17,17,17)\",\"plot_bgcolor\":\"rgb(17,17,17)\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"bgcolor\":\"rgb(17,17,17)\",\"radialaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"gridwidth\":2,\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\"},\"yaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"gridwidth\":2,\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\"},\"zaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"gridwidth\":2,\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\"}},\"shapedefaults\":{\"line\":{\"color\":\"#f2f5fa\"}},\"sliderdefaults\":{\"bgcolor\":\"#C8D4E3\",\"bordercolor\":\"rgb(17,17,17)\",\"borderwidth\":1,\"tickwidth\":0},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"bgcolor\":\"rgb(17,17,17)\",\"caxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"updatemenudefaults\":{\"bgcolor\":\"#506784\",\"borderwidth\":0},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Origin\"},\"categoryorder\":\"total descending\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Frequency\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"title\":{\"text\":\"Predicted Origins and their frequency\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('50dd6296-5e85-4304-83c1-06fbd357a822');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig2 = px.bar(x = list(labels.keys()), y = list(np.sum(node_features, axis = 0)), text_auto='.2s')\n",
        "fig2.update_layout(\n",
        "    xaxis={'categoryorder':'total descending'},\n",
        "    title=\"Each countries distribution\",\n",
        "    template=\"plotly_dark\")\n",
        "fig2.update_traces(textfont_size=12, textangle=0, textposition=\"outside\", cliponaxis=False)\n",
        "\n",
        "fig2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "E2CtUn7yicrq",
        "outputId": "64c61574-185f-466e-aeb5-5926f4c4582d"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"31c49557-b62a-4f44-8c76-3e91915ecb32\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"31c49557-b62a-4f44-8c76-3e91915ecb32\")) {                    Plotly.newPlot(                        \"31c49557-b62a-4f44-8c76-3e91915ecb32\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"x=%{x}<br>y=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"outside\",\"texttemplate\":\"%{y:.2s}\",\"x\":[\"brazilian\",\"british\",\"cajun_creole\",\"chinese\",\"filipino\",\"french\",\"greek\",\"indian\",\"irish\",\"italian\",\"jamaican\",\"japanese\",\"korean\",\"mexican\",\"moroccan\",\"russian\",\"southern_us\",\"spanish\",\"thai\",\"vietnamese\"],\"xaxis\":\"x\",\"y\":[3556.0,6328.0,15349.0,25379.0,5889.0,20381.0,9532.0,30216.0,4876.0,61791.0,4750.0,11071.0,7240.0,55410.0,8518.0,3989.0,32383.0,8275.0,15036.0,8275.0],\"yaxis\":\"y\",\"type\":\"bar\",\"textfont\":{\"size\":12},\"cliponaxis\":false,\"textangle\":0}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#f2f5fa\"},\"error_y\":{\"color\":\"#f2f5fa\"},\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"baxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#506784\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"header\":{\"fill\":{\"color\":\"#2a3f5f\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#f2f5fa\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#f2f5fa\"},\"geo\":{\"bgcolor\":\"rgb(17,17,17)\",\"lakecolor\":\"rgb(17,17,17)\",\"landcolor\":\"rgb(17,17,17)\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#506784\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"dark\"},\"paper_bgcolor\":\"rgb(17,17,17)\",\"plot_bgcolor\":\"rgb(17,17,17)\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"bgcolor\":\"rgb(17,17,17)\",\"radialaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"gridwidth\":2,\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\"},\"yaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"gridwidth\":2,\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\"},\"zaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"gridwidth\":2,\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\"}},\"shapedefaults\":{\"line\":{\"color\":\"#f2f5fa\"}},\"sliderdefaults\":{\"bgcolor\":\"#C8D4E3\",\"bordercolor\":\"rgb(17,17,17)\",\"borderwidth\":1,\"tickwidth\":0},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"bgcolor\":\"rgb(17,17,17)\",\"caxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"updatemenudefaults\":{\"bgcolor\":\"#506784\",\"borderwidth\":0},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"},\"categoryorder\":\"total descending\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"title\":{\"text\":\"Each countries distribution\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('31c49557-b62a-4f44-8c76-3e91915ecb32');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Completion**"
      ],
      "metadata": {
        "id": "Jz-ErCwmnkZJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Loader**"
      ],
      "metadata": {
        "id": "ygc3cWZlFoOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_completion(embedding, dim, stage):\n",
        "  emb = []\n",
        "  target = []\n",
        "  if stage == \"train\":\n",
        "    with open (\"train.csv\", \"r\") as f:\n",
        "      data = f.readlines()      \n",
        "      for i in range(len(data)):\n",
        "        ingredients = data[i].strip().split(\",\")[:-1]\n",
        "        ingredients = [int(x) for x in ingredients]\n",
        "        \n",
        "        # Randomly pop one ingredient and make it target\n",
        "        random.shuffle(ingredients)\n",
        "\n",
        "        missing = ingredients.pop()\n",
        "        merge = np.zeros((len(ingredients), dim))        \n",
        "        for j in range(len(ingredients)):\n",
        "          merge[j, :] = embedding.iloc[ingredients[j], :]\n",
        "        merge = np.sum(merge, axis=0)\n",
        "        emb.append(merge)\n",
        "        target.append(embedding.iloc[missing, :])\n",
        "    \n",
        "  elif stage == \"val\":\n",
        "    with open (\"validation_completion_answer.csv\", \"r\") as f:\n",
        "      data = f.readlines()\n",
        "      for i in range(len(data)):\n",
        "        target.append(embedding.iloc[int(data[i]), :])\n",
        "    \n",
        "    with open (\"validation_completion_question.csv\", \"r\") as f:\n",
        "      data = f.readlines()\n",
        "      \n",
        "      for i in range(len(data)):\n",
        "        ingredients = data[i].strip().split(\",\")\n",
        "        ingredients = [int(x) for x in ingredients]\n",
        "        merge = np.zeros((len(ingredients), dim))\n",
        "        for j in range(len(ingredients)):\n",
        "          merge[j, :] = embedding.iloc[ingredients[j], :]\n",
        "        merge = np.sum(merge, axis=0)\n",
        "        emb.append(merge)\n",
        "    \n",
        "  elif stage == \"test\":\n",
        "    with open (\"test_completion_question.csv\", \"r\") as f:\n",
        "      data = f.readlines()\n",
        "      for i in range(len(data)):\n",
        "        ingredients = data[i].strip().split(\",\")\n",
        "        ingredients = [int(x) for x in ingredients]\n",
        "        merge = np.zeros((len(ingredients), dim))\n",
        "        \n",
        "        for j in range(len(ingredients)):\n",
        "          merge[j, :] = embedding.iloc[ingredients[j], :]\n",
        "        merge = np.sum(merge, axis=0) \n",
        "        emb.append(merge)\n",
        "        target.append(np.zeros(dim))\n",
        "\n",
        "  return np.vstack(emb), np.vstack(target)"
      ],
      "metadata": {
        "id": "blIjCSTpv1Aa"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model**"
      ],
      "metadata": {
        "id": "Z1DKwXbEE1Ep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, num_feature, latent_dim):\n",
        "    super(Generator, self).__init__()    \n",
        "    self.fc1 = nn.Linear(num_feature + latent_dim, 64)\n",
        "    self.bn1 = nn.BatchNorm1d(64)\n",
        "    \n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.bn2 = nn.BatchNorm1d(32)\n",
        "\n",
        "    self.fc3 = nn.Linear(32, 2*num_feature)\n",
        "    self.bn3 = nn.BatchNorm1d(2*num_feature)\n",
        "\n",
        "    self.dp = nn.Dropout(0.5)\n",
        "    self.act = nn.LeakyReLU(0.2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = self.dp(self.act(self.bn1(self.fc1(x))))\n",
        "    output = self.dp(self.act(self.bn2(self.fc2(output))))\n",
        "    output = self.bn3(self.fc3(output))\n",
        "    return torch.tanh(output)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, num_feature):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.fc1 = nn.Linear(2*num_feature, 512)\n",
        "    self.bn1 = nn.BatchNorm1d(512)\n",
        "    \n",
        "    self.fc2 = nn.Linear(512, 64)\n",
        "    self.bn2 = nn.BatchNorm1d(64)\n",
        "\n",
        "    self.fc3 = nn.Linear(64, 1)\n",
        "\n",
        "    self.dp = nn.Dropout(0.5)\n",
        "    self.act = nn.LeakyReLU(0.2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = self.dp(self.act(self.bn1(self.fc1(x))))\n",
        "    output = self.dp(self.act(self.bn2(self.fc2(output))))\n",
        "    output = self.fc3(output)\n",
        "\n",
        "    return torch.sigmoid(output)\n",
        "\n",
        "\n",
        "class GANclassifier(nn.Module):\n",
        "  def __init__(self, num_feature):\n",
        "    super(GANclassifier, self).__init__()\n",
        "    self.fc1 = nn.Linear(2*num_feature, 512)\n",
        "    self.bn1 = nn.BatchNorm1d(512)\n",
        "    \n",
        "    self.fc2 = nn.Linear(512, 256)\n",
        "    self.bn2 = nn.BatchNorm1d(256)\n",
        "\n",
        "    self.fc3 = nn.Linear(256, num_feature)\n",
        "    self.bn3 = nn.BatchNorm1d(num_feature)\n",
        "\n",
        "    self.dp = nn.Dropout(0.5)\n",
        "    self.act = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = self.dp(self.act(self.bn1(self.fc1(x))))\n",
        "    output = self.dp(self.act(self.bn2(self.fc2(output))))\n",
        "    output = self.act(self.bn3(self.fc3(output)))\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "QP8syoprwLhu"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training**"
      ],
      "metadata": {
        "id": "zPY0WexcFykq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_com_dataset, y_train_com_dataset = load_data_completion(embeddings, args.pred_dim, \"train\")\n",
        "x_val_com_dataset, y_val_com_dataset = load_data_completion(embeddings, args.pred_dim, \"val\")\n",
        "x_test_com_dataset, y_test_com_dataset = load_data_completion(embeddings, args.pred_dim, \"test\")\n",
        "\n",
        "train_com_dataset = MyDataset(x_train_com_dataset, y_train_com_dataset)\n",
        "val_com_dataset = MyDataset(x_val_com_dataset, y_val_com_dataset)\n",
        "test_com_dataset = MyDataset(x_test_com_dataset, y_test_com_dataset)\n",
        "\n",
        "\n",
        "train_com_dataloader = torch.utils.data.DataLoader(train_com_dataset, batch_size=args.batch_size, shuffle=True, num_workers=2)\n",
        "val_com_dataloader = torch.utils.data.DataLoader(val_com_dataset, batch_size=args.batch_size, shuffle=False, num_workers=2)\n",
        "test_com_dataloader = torch.utils.data.DataLoader(test_com_dataset, batch_size=args.batch_size, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "xA4Qo1OgnmDE"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_loss = torch.nn.MSELoss()\n",
        "adversarial_loss = torch.nn.BCELoss()\n",
        "generator = Generator(args.pred_dim, args.latent_dim).to(device)\n",
        "discriminator = Discriminator(args.pred_dim).to(device)\n",
        "classifier = GANclassifier(args.pred_dim).to(device)"
      ],
      "metadata": {
        "id": "zlWU4iuMwEUN"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=args.pred_lr, betas=(args.b1, args.b2))\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=args.pred_lr, betas=(args.b1, args.b2))\n",
        "optimizer_C = torch.optim.Adam(classifier.parameters(), lr=args.pred_lr, weight_decay=0.0001)\n",
        "scheduler_pred = torch.optim.lr_scheduler.MultiStepLR(optimizer_C, milestones=[50,80], gamma=0.5)"
      ],
      "metadata": {
        "id": "oQZUp1KSv4Ju"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G_losses = []\n",
        "D_losses = []\n",
        "C_losses = []\n",
        "V_losses = []\n",
        "for epoch in range(args.pred_epochs):\n",
        "  for batch_idx, data in enumerate(train_com_dataloader):\n",
        "    recipe_emb = data['recipe'].to(device)\n",
        "    mis_recipe = data['label'].to(device)\n",
        "\n",
        "    valid_label = Variable(torch.FloatTensor(recipe_emb.shape[0], 1).fill_(1.0), requires_grad=False).to(device)\n",
        "    fake_label = Variable(torch.FloatTensor(recipe_emb.shape[0], 1).fill_(0.0), requires_grad=False).to(device)\n",
        "\n",
        "    noise = Variable(torch.FloatTensor(np.random.normal(0, 1, (recipe_emb.shape[0], args.latent_dim)))).to(device)\n",
        "    # noise = Variable(torch.FloatTensor(np.full((recipe_emb.shape[0], args.latent_dim), 0.001))).to(device)\n",
        "    fake = generator(torch.cat((noise, recipe_emb), dim=1))\n",
        "\n",
        "\n",
        "    optimizer_D.zero_grad()\n",
        "    optimizer_C.zero_grad()\n",
        "\n",
        "    real_score_out = discriminator(torch.cat((mis_recipe, recipe_emb), dim=1))\n",
        "    fake_score_out = discriminator(fake.detach())\n",
        "    real_embedding = classifier(torch.cat((mis_recipe, recipe_emb), dim=1))\n",
        "\n",
        "    D_real_loss = adversarial_loss(real_score_out, valid_label)\n",
        "    D_fake_loss = adversarial_loss(fake_score_out, fake_label)\n",
        "    C_real_loss = classifier_loss(real_embedding, mis_recipe)\n",
        "  \n",
        "    d_loss = (D_real_loss + D_fake_loss + C_real_loss) / 3\n",
        "    d_loss.backward()\n",
        "\n",
        "    optimizer_D.step()\n",
        "    optimizer_C.step()\n",
        "\n",
        "    # -----------------\n",
        "    #  Train Generator\n",
        "    # -----------------\n",
        "\n",
        "    optimizer_G.zero_grad()\n",
        "    \n",
        "    fake_score_out = discriminator(fake)\n",
        "    fake_embedding = classifier(fake)\n",
        "    \n",
        "    GD_fake_loss = adversarial_loss(fake_score_out, valid_label)\n",
        "    GC_fake_loss = classifier_loss(fake_embedding, fake[:, :args.pred_dim])\n",
        "    \n",
        "    g_loss = (GD_fake_loss + GC_fake_loss) / 2\n",
        "    g_loss.backward()\n",
        "    \n",
        "    optimizer_G.step()\n",
        "\n",
        "    if batch_idx % 50 == 0:\n",
        "      print(\n",
        "      \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f] [C loss: %f]\"\n",
        "      % (epoch, args.pred_epochs, batch_idx, len(train_com_dataloader), d_loss.item(), g_loss.item(), C_real_loss.item() )\n",
        "      )\n",
        "\n",
        "  # Save Losses for plotting later\n",
        "  G_losses.append(g_loss.item())\n",
        "  D_losses.append(d_loss.item())\n",
        "  C_losses.append(C_real_loss.item())\n",
        "\n",
        "  generator.eval()\n",
        "  with torch.no_grad():\n",
        "    val_loss = []\n",
        "    for batch_idx, data in enumerate(val_com_dataloader):\n",
        "      recipe_emb = data['recipe'].to(device=device)\n",
        "      mis_recipe = data['label'].to(device=device)\n",
        "\n",
        "      #   Feed `x` into the network, get an output, and keep it in a variable called `logit`. \n",
        "      noise = Variable(torch.FloatTensor(np.random.normal(0, 1, (recipe_emb.shape[0], args.latent_dim)))).to(device)\n",
        "      generated = generator(torch.cat((noise, recipe_emb), dim=1))\n",
        "      generated = generated.type(torch.float).to(device)\n",
        "      partition = classifier(generated)\n",
        "\n",
        "      loss = classifier_loss(partition, mis_recipe) # generated[:, :args.pred_dim]\n",
        "      val_loss.append(loss)\n",
        "    \n",
        "    mean_val_loss = sum(val_loss) / len(val_loss)\n",
        "    V_losses.append(mean_val_loss.item())"
      ],
      "metadata": {
        "id": "d-n8IkrLLr03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5455bec3-2b2a-4124-8d20-6258675288e2"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 0/50] [Batch 0/368] [D loss: 0.671400] [G loss: 0.805886] [C loss: 0.585326]\n",
            "[Epoch 0/50] [Batch 50/368] [D loss: 0.708497] [G loss: 0.802702] [C loss: 0.587287]\n",
            "[Epoch 0/50] [Batch 100/368] [D loss: 0.710865] [G loss: 0.798243] [C loss: 0.599361]\n",
            "[Epoch 0/50] [Batch 150/368] [D loss: 0.663439] [G loss: 0.794011] [C loss: 0.573668]\n",
            "[Epoch 0/50] [Batch 200/368] [D loss: 0.701150] [G loss: 0.817974] [C loss: 0.573722]\n",
            "[Epoch 0/50] [Batch 250/368] [D loss: 0.690020] [G loss: 0.827995] [C loss: 0.566031]\n",
            "[Epoch 0/50] [Batch 300/368] [D loss: 0.704597] [G loss: 0.800223] [C loss: 0.560431]\n",
            "[Epoch 0/50] [Batch 350/368] [D loss: 0.675003] [G loss: 0.815930] [C loss: 0.563729]\n",
            "[Epoch 1/50] [Batch 0/368] [D loss: 0.695024] [G loss: 0.669772] [C loss: 0.550497]\n",
            "[Epoch 1/50] [Batch 50/368] [D loss: 0.678777] [G loss: 0.660935] [C loss: 0.558782]\n",
            "[Epoch 1/50] [Batch 100/368] [D loss: 0.698557] [G loss: 0.674058] [C loss: 0.565829]\n",
            "[Epoch 1/50] [Batch 150/368] [D loss: 0.663105] [G loss: 0.646819] [C loss: 0.556287]\n",
            "[Epoch 1/50] [Batch 200/368] [D loss: 0.639791] [G loss: 0.621516] [C loss: 0.539645]\n",
            "[Epoch 1/50] [Batch 250/368] [D loss: 0.652192] [G loss: 0.656237] [C loss: 0.552755]\n",
            "[Epoch 1/50] [Batch 300/368] [D loss: 0.633377] [G loss: 0.649935] [C loss: 0.539053]\n",
            "[Epoch 1/50] [Batch 350/368] [D loss: 0.641545] [G loss: 0.672139] [C loss: 0.537838]\n",
            "[Epoch 2/50] [Batch 0/368] [D loss: 0.649394] [G loss: 0.644626] [C loss: 0.545498]\n",
            "[Epoch 2/50] [Batch 50/368] [D loss: 0.659365] [G loss: 0.639875] [C loss: 0.522479]\n",
            "[Epoch 2/50] [Batch 100/368] [D loss: 0.628109] [G loss: 0.619913] [C loss: 0.505402]\n",
            "[Epoch 2/50] [Batch 150/368] [D loss: 0.664291] [G loss: 0.626679] [C loss: 0.496136]\n",
            "[Epoch 2/50] [Batch 200/368] [D loss: 0.642763] [G loss: 0.651240] [C loss: 0.498731]\n",
            "[Epoch 2/50] [Batch 250/368] [D loss: 0.641216] [G loss: 0.622630] [C loss: 0.497941]\n",
            "[Epoch 2/50] [Batch 300/368] [D loss: 0.672222] [G loss: 0.657145] [C loss: 0.480240]\n",
            "[Epoch 2/50] [Batch 350/368] [D loss: 0.638476] [G loss: 0.630238] [C loss: 0.462803]\n",
            "[Epoch 3/50] [Batch 0/368] [D loss: 0.648332] [G loss: 0.611379] [C loss: 0.494768]\n",
            "[Epoch 3/50] [Batch 50/368] [D loss: 0.644216] [G loss: 0.608344] [C loss: 0.464664]\n",
            "[Epoch 3/50] [Batch 100/368] [D loss: 0.639843] [G loss: 0.622446] [C loss: 0.447924]\n",
            "[Epoch 3/50] [Batch 150/368] [D loss: 0.612649] [G loss: 0.587428] [C loss: 0.447290]\n",
            "[Epoch 3/50] [Batch 200/368] [D loss: 0.625100] [G loss: 0.596801] [C loss: 0.433051]\n",
            "[Epoch 3/50] [Batch 250/368] [D loss: 0.617278] [G loss: 0.602758] [C loss: 0.407224]\n",
            "[Epoch 3/50] [Batch 300/368] [D loss: 0.602472] [G loss: 0.582853] [C loss: 0.393681]\n",
            "[Epoch 3/50] [Batch 350/368] [D loss: 0.632890] [G loss: 0.588188] [C loss: 0.384003]\n",
            "[Epoch 4/50] [Batch 0/368] [D loss: 0.625850] [G loss: 0.586078] [C loss: 0.432818]\n",
            "[Epoch 4/50] [Batch 50/368] [D loss: 0.609124] [G loss: 0.567963] [C loss: 0.400270]\n",
            "[Epoch 4/50] [Batch 100/368] [D loss: 0.609007] [G loss: 0.549005] [C loss: 0.404185]\n",
            "[Epoch 4/50] [Batch 150/368] [D loss: 0.618165] [G loss: 0.553472] [C loss: 0.360139]\n",
            "[Epoch 4/50] [Batch 200/368] [D loss: 0.600888] [G loss: 0.573966] [C loss: 0.340674]\n",
            "[Epoch 4/50] [Batch 250/368] [D loss: 0.578691] [G loss: 0.539469] [C loss: 0.314208]\n",
            "[Epoch 4/50] [Batch 300/368] [D loss: 0.601670] [G loss: 0.572873] [C loss: 0.376111]\n",
            "[Epoch 4/50] [Batch 350/368] [D loss: 0.609891] [G loss: 0.536636] [C loss: 0.355835]\n",
            "[Epoch 5/50] [Batch 0/368] [D loss: 0.591456] [G loss: 0.544500] [C loss: 0.329557]\n",
            "[Epoch 5/50] [Batch 50/368] [D loss: 0.560037] [G loss: 0.547081] [C loss: 0.285329]\n",
            "[Epoch 5/50] [Batch 100/368] [D loss: 0.580978] [G loss: 0.541206] [C loss: 0.318937]\n",
            "[Epoch 5/50] [Batch 150/368] [D loss: 0.581956] [G loss: 0.529120] [C loss: 0.279661]\n",
            "[Epoch 5/50] [Batch 200/368] [D loss: 0.585982] [G loss: 0.531818] [C loss: 0.304022]\n",
            "[Epoch 5/50] [Batch 250/368] [D loss: 0.573402] [G loss: 0.535913] [C loss: 0.294001]\n",
            "[Epoch 5/50] [Batch 300/368] [D loss: 0.576272] [G loss: 0.547345] [C loss: 0.258224]\n",
            "[Epoch 5/50] [Batch 350/368] [D loss: 0.564791] [G loss: 0.532081] [C loss: 0.322794]\n",
            "[Epoch 6/50] [Batch 0/368] [D loss: 0.593430] [G loss: 0.490597] [C loss: 0.317570]\n",
            "[Epoch 6/50] [Batch 50/368] [D loss: 0.609807] [G loss: 0.510941] [C loss: 0.341845]\n",
            "[Epoch 6/50] [Batch 100/368] [D loss: 0.567658] [G loss: 0.515652] [C loss: 0.258447]\n",
            "[Epoch 6/50] [Batch 150/368] [D loss: 0.614041] [G loss: 0.503407] [C loss: 0.312083]\n",
            "[Epoch 6/50] [Batch 200/368] [D loss: 0.557637] [G loss: 0.501465] [C loss: 0.281601]\n",
            "[Epoch 6/50] [Batch 250/368] [D loss: 0.585260] [G loss: 0.499733] [C loss: 0.272414]\n",
            "[Epoch 6/50] [Batch 300/368] [D loss: 0.571821] [G loss: 0.498894] [C loss: 0.263141]\n",
            "[Epoch 6/50] [Batch 350/368] [D loss: 0.547221] [G loss: 0.487016] [C loss: 0.247538]\n",
            "[Epoch 7/50] [Batch 0/368] [D loss: 0.571977] [G loss: 0.513748] [C loss: 0.245078]\n",
            "[Epoch 7/50] [Batch 50/368] [D loss: 0.543225] [G loss: 0.479367] [C loss: 0.235166]\n",
            "[Epoch 7/50] [Batch 100/368] [D loss: 0.542758] [G loss: 0.490606] [C loss: 0.254663]\n",
            "[Epoch 7/50] [Batch 150/368] [D loss: 0.584588] [G loss: 0.491567] [C loss: 0.291283]\n",
            "[Epoch 7/50] [Batch 200/368] [D loss: 0.593621] [G loss: 0.482923] [C loss: 0.262260]\n",
            "[Epoch 7/50] [Batch 250/368] [D loss: 0.546857] [G loss: 0.492484] [C loss: 0.226520]\n",
            "[Epoch 7/50] [Batch 300/368] [D loss: 0.548179] [G loss: 0.483545] [C loss: 0.246911]\n",
            "[Epoch 7/50] [Batch 350/368] [D loss: 0.566377] [G loss: 0.459638] [C loss: 0.265663]\n",
            "[Epoch 8/50] [Batch 0/368] [D loss: 0.595906] [G loss: 0.477010] [C loss: 0.305620]\n",
            "[Epoch 8/50] [Batch 50/368] [D loss: 0.546523] [G loss: 0.462203] [C loss: 0.219384]\n",
            "[Epoch 8/50] [Batch 100/368] [D loss: 0.558011] [G loss: 0.446210] [C loss: 0.253803]\n",
            "[Epoch 8/50] [Batch 150/368] [D loss: 0.537660] [G loss: 0.466744] [C loss: 0.162069]\n",
            "[Epoch 8/50] [Batch 200/368] [D loss: 0.549358] [G loss: 0.451182] [C loss: 0.225652]\n",
            "[Epoch 8/50] [Batch 250/368] [D loss: 0.566236] [G loss: 0.443761] [C loss: 0.248453]\n",
            "[Epoch 8/50] [Batch 300/368] [D loss: 0.562523] [G loss: 0.445278] [C loss: 0.247522]\n",
            "[Epoch 8/50] [Batch 350/368] [D loss: 0.573277] [G loss: 0.436088] [C loss: 0.250591]\n",
            "[Epoch 9/50] [Batch 0/368] [D loss: 0.558925] [G loss: 0.444889] [C loss: 0.261697]\n",
            "[Epoch 9/50] [Batch 50/368] [D loss: 0.587498] [G loss: 0.431243] [C loss: 0.243919]\n",
            "[Epoch 9/50] [Batch 100/368] [D loss: 0.527096] [G loss: 0.444514] [C loss: 0.164050]\n",
            "[Epoch 9/50] [Batch 150/368] [D loss: 0.564459] [G loss: 0.456201] [C loss: 0.239835]\n",
            "[Epoch 9/50] [Batch 200/368] [D loss: 0.544476] [G loss: 0.437547] [C loss: 0.241752]\n",
            "[Epoch 9/50] [Batch 250/368] [D loss: 0.573756] [G loss: 0.429773] [C loss: 0.226742]\n",
            "[Epoch 9/50] [Batch 300/368] [D loss: 0.549019] [G loss: 0.436206] [C loss: 0.268684]\n",
            "[Epoch 9/50] [Batch 350/368] [D loss: 0.529337] [G loss: 0.437669] [C loss: 0.229649]\n",
            "[Epoch 10/50] [Batch 0/368] [D loss: 0.533397] [G loss: 0.455478] [C loss: 0.225946]\n",
            "[Epoch 10/50] [Batch 50/368] [D loss: 0.539098] [G loss: 0.453926] [C loss: 0.173098]\n",
            "[Epoch 10/50] [Batch 100/368] [D loss: 0.572884] [G loss: 0.424921] [C loss: 0.246549]\n",
            "[Epoch 10/50] [Batch 150/368] [D loss: 0.566281] [G loss: 0.437626] [C loss: 0.255437]\n",
            "[Epoch 10/50] [Batch 200/368] [D loss: 0.554391] [G loss: 0.446266] [C loss: 0.198568]\n",
            "[Epoch 10/50] [Batch 250/368] [D loss: 0.539729] [G loss: 0.409255] [C loss: 0.213280]\n",
            "[Epoch 10/50] [Batch 300/368] [D loss: 0.551739] [G loss: 0.447162] [C loss: 0.231508]\n",
            "[Epoch 10/50] [Batch 350/368] [D loss: 0.558315] [G loss: 0.451407] [C loss: 0.221193]\n",
            "[Epoch 11/50] [Batch 0/368] [D loss: 0.552069] [G loss: 0.431671] [C loss: 0.218371]\n",
            "[Epoch 11/50] [Batch 50/368] [D loss: 0.529247] [G loss: 0.468272] [C loss: 0.176734]\n",
            "[Epoch 11/50] [Batch 100/368] [D loss: 0.557699] [G loss: 0.427467] [C loss: 0.249045]\n",
            "[Epoch 11/50] [Batch 150/368] [D loss: 0.537814] [G loss: 0.441028] [C loss: 0.224535]\n",
            "[Epoch 11/50] [Batch 200/368] [D loss: 0.554437] [G loss: 0.402318] [C loss: 0.236537]\n",
            "[Epoch 11/50] [Batch 250/368] [D loss: 0.539896] [G loss: 0.410816] [C loss: 0.231067]\n",
            "[Epoch 11/50] [Batch 300/368] [D loss: 0.542740] [G loss: 0.425804] [C loss: 0.211378]\n",
            "[Epoch 11/50] [Batch 350/368] [D loss: 0.548616] [G loss: 0.408335] [C loss: 0.212199]\n",
            "[Epoch 12/50] [Batch 0/368] [D loss: 0.553611] [G loss: 0.434081] [C loss: 0.224073]\n",
            "[Epoch 12/50] [Batch 50/368] [D loss: 0.556194] [G loss: 0.412131] [C loss: 0.251430]\n",
            "[Epoch 12/50] [Batch 100/368] [D loss: 0.532192] [G loss: 0.418217] [C loss: 0.182358]\n",
            "[Epoch 12/50] [Batch 150/368] [D loss: 0.559566] [G loss: 0.400925] [C loss: 0.221069]\n",
            "[Epoch 12/50] [Batch 200/368] [D loss: 0.548136] [G loss: 0.431337] [C loss: 0.191277]\n",
            "[Epoch 12/50] [Batch 250/368] [D loss: 0.520009] [G loss: 0.425951] [C loss: 0.178092]\n",
            "[Epoch 12/50] [Batch 300/368] [D loss: 0.520397] [G loss: 0.427178] [C loss: 0.174394]\n",
            "[Epoch 12/50] [Batch 350/368] [D loss: 0.558645] [G loss: 0.407540] [C loss: 0.251509]\n",
            "[Epoch 13/50] [Batch 0/368] [D loss: 0.541440] [G loss: 0.413595] [C loss: 0.216848]\n",
            "[Epoch 13/50] [Batch 50/368] [D loss: 0.534003] [G loss: 0.430612] [C loss: 0.216965]\n",
            "[Epoch 13/50] [Batch 100/368] [D loss: 0.564422] [G loss: 0.394873] [C loss: 0.224093]\n",
            "[Epoch 13/50] [Batch 150/368] [D loss: 0.539341] [G loss: 0.394218] [C loss: 0.186887]\n",
            "[Epoch 13/50] [Batch 200/368] [D loss: 0.525679] [G loss: 0.423881] [C loss: 0.175515]\n",
            "[Epoch 13/50] [Batch 250/368] [D loss: 0.518127] [G loss: 0.412379] [C loss: 0.179643]\n",
            "[Epoch 13/50] [Batch 300/368] [D loss: 0.531409] [G loss: 0.434857] [C loss: 0.202296]\n",
            "[Epoch 13/50] [Batch 350/368] [D loss: 0.537283] [G loss: 0.392381] [C loss: 0.172068]\n",
            "[Epoch 14/50] [Batch 0/368] [D loss: 0.548663] [G loss: 0.420337] [C loss: 0.248284]\n",
            "[Epoch 14/50] [Batch 50/368] [D loss: 0.512930] [G loss: 0.409912] [C loss: 0.188277]\n",
            "[Epoch 14/50] [Batch 100/368] [D loss: 0.524281] [G loss: 0.402143] [C loss: 0.177375]\n",
            "[Epoch 14/50] [Batch 150/368] [D loss: 0.532179] [G loss: 0.420891] [C loss: 0.226700]\n",
            "[Epoch 14/50] [Batch 200/368] [D loss: 0.523410] [G loss: 0.415457] [C loss: 0.177767]\n",
            "[Epoch 14/50] [Batch 250/368] [D loss: 0.525035] [G loss: 0.385347] [C loss: 0.155629]\n",
            "[Epoch 14/50] [Batch 300/368] [D loss: 0.536490] [G loss: 0.384935] [C loss: 0.151570]\n",
            "[Epoch 14/50] [Batch 350/368] [D loss: 0.533357] [G loss: 0.390101] [C loss: 0.189882]\n",
            "[Epoch 15/50] [Batch 0/368] [D loss: 0.558881] [G loss: 0.387632] [C loss: 0.230925]\n",
            "[Epoch 15/50] [Batch 50/368] [D loss: 0.529099] [G loss: 0.404837] [C loss: 0.175647]\n",
            "[Epoch 15/50] [Batch 100/368] [D loss: 0.545086] [G loss: 0.396410] [C loss: 0.177017]\n",
            "[Epoch 15/50] [Batch 150/368] [D loss: 0.532168] [G loss: 0.389315] [C loss: 0.184627]\n",
            "[Epoch 15/50] [Batch 200/368] [D loss: 0.532445] [G loss: 0.412998] [C loss: 0.158715]\n",
            "[Epoch 15/50] [Batch 250/368] [D loss: 0.522585] [G loss: 0.431595] [C loss: 0.147839]\n",
            "[Epoch 15/50] [Batch 300/368] [D loss: 0.527994] [G loss: 0.410865] [C loss: 0.172335]\n",
            "[Epoch 15/50] [Batch 350/368] [D loss: 0.519706] [G loss: 0.409872] [C loss: 0.135111]\n",
            "[Epoch 16/50] [Batch 0/368] [D loss: 0.522560] [G loss: 0.403048] [C loss: 0.183335]\n",
            "[Epoch 16/50] [Batch 50/368] [D loss: 0.534370] [G loss: 0.391231] [C loss: 0.197101]\n",
            "[Epoch 16/50] [Batch 100/368] [D loss: 0.528326] [G loss: 0.420679] [C loss: 0.173274]\n",
            "[Epoch 16/50] [Batch 150/368] [D loss: 0.521097] [G loss: 0.394396] [C loss: 0.185656]\n",
            "[Epoch 16/50] [Batch 200/368] [D loss: 0.525141] [G loss: 0.390128] [C loss: 0.177727]\n",
            "[Epoch 16/50] [Batch 250/368] [D loss: 0.533264] [G loss: 0.395413] [C loss: 0.188909]\n",
            "[Epoch 16/50] [Batch 300/368] [D loss: 0.516981] [G loss: 0.406902] [C loss: 0.144897]\n",
            "[Epoch 16/50] [Batch 350/368] [D loss: 0.529554] [G loss: 0.409945] [C loss: 0.174962]\n",
            "[Epoch 17/50] [Batch 0/368] [D loss: 0.524591] [G loss: 0.377236] [C loss: 0.192556]\n",
            "[Epoch 17/50] [Batch 50/368] [D loss: 0.530755] [G loss: 0.404157] [C loss: 0.164727]\n",
            "[Epoch 17/50] [Batch 100/368] [D loss: 0.511318] [G loss: 0.417444] [C loss: 0.160495]\n",
            "[Epoch 17/50] [Batch 150/368] [D loss: 0.503226] [G loss: 0.397864] [C loss: 0.161156]\n",
            "[Epoch 17/50] [Batch 200/368] [D loss: 0.511906] [G loss: 0.375590] [C loss: 0.145852]\n",
            "[Epoch 17/50] [Batch 250/368] [D loss: 0.534553] [G loss: 0.393363] [C loss: 0.198239]\n",
            "[Epoch 17/50] [Batch 300/368] [D loss: 0.522648] [G loss: 0.375544] [C loss: 0.181278]\n",
            "[Epoch 17/50] [Batch 350/368] [D loss: 0.547154] [G loss: 0.426738] [C loss: 0.172845]\n",
            "[Epoch 18/50] [Batch 0/368] [D loss: 0.526605] [G loss: 0.413015] [C loss: 0.165843]\n",
            "[Epoch 18/50] [Batch 50/368] [D loss: 0.489985] [G loss: 0.409811] [C loss: 0.135271]\n",
            "[Epoch 18/50] [Batch 100/368] [D loss: 0.551541] [G loss: 0.403660] [C loss: 0.208815]\n",
            "[Epoch 18/50] [Batch 150/368] [D loss: 0.537786] [G loss: 0.392539] [C loss: 0.185023]\n",
            "[Epoch 18/50] [Batch 200/368] [D loss: 0.503049] [G loss: 0.388062] [C loss: 0.153028]\n",
            "[Epoch 18/50] [Batch 250/368] [D loss: 0.527749] [G loss: 0.391331] [C loss: 0.169085]\n",
            "[Epoch 18/50] [Batch 300/368] [D loss: 0.520979] [G loss: 0.396545] [C loss: 0.157762]\n",
            "[Epoch 18/50] [Batch 350/368] [D loss: 0.509711] [G loss: 0.364790] [C loss: 0.150397]\n",
            "[Epoch 19/50] [Batch 0/368] [D loss: 0.505484] [G loss: 0.394316] [C loss: 0.168417]\n",
            "[Epoch 19/50] [Batch 50/368] [D loss: 0.528359] [G loss: 0.413254] [C loss: 0.165217]\n",
            "[Epoch 19/50] [Batch 100/368] [D loss: 0.519049] [G loss: 0.413057] [C loss: 0.155687]\n",
            "[Epoch 19/50] [Batch 150/368] [D loss: 0.521428] [G loss: 0.400187] [C loss: 0.158828]\n",
            "[Epoch 19/50] [Batch 200/368] [D loss: 0.518457] [G loss: 0.385337] [C loss: 0.141651]\n",
            "[Epoch 19/50] [Batch 250/368] [D loss: 0.527919] [G loss: 0.392470] [C loss: 0.163809]\n",
            "[Epoch 19/50] [Batch 300/368] [D loss: 0.504171] [G loss: 0.385184] [C loss: 0.156147]\n",
            "[Epoch 19/50] [Batch 350/368] [D loss: 0.511696] [G loss: 0.376361] [C loss: 0.154450]\n",
            "[Epoch 20/50] [Batch 0/368] [D loss: 0.545507] [G loss: 0.398491] [C loss: 0.167060]\n",
            "[Epoch 20/50] [Batch 50/368] [D loss: 0.518172] [G loss: 0.392210] [C loss: 0.177723]\n",
            "[Epoch 20/50] [Batch 100/368] [D loss: 0.518878] [G loss: 0.382120] [C loss: 0.181201]\n",
            "[Epoch 20/50] [Batch 150/368] [D loss: 0.513584] [G loss: 0.394256] [C loss: 0.190801]\n",
            "[Epoch 20/50] [Batch 200/368] [D loss: 0.519178] [G loss: 0.400393] [C loss: 0.166737]\n",
            "[Epoch 20/50] [Batch 250/368] [D loss: 0.514935] [G loss: 0.373010] [C loss: 0.151432]\n",
            "[Epoch 20/50] [Batch 300/368] [D loss: 0.512476] [G loss: 0.389639] [C loss: 0.139844]\n",
            "[Epoch 20/50] [Batch 350/368] [D loss: 0.509682] [G loss: 0.375373] [C loss: 0.112896]\n",
            "[Epoch 21/50] [Batch 0/368] [D loss: 0.524083] [G loss: 0.402428] [C loss: 0.162655]\n",
            "[Epoch 21/50] [Batch 50/368] [D loss: 0.525616] [G loss: 0.389580] [C loss: 0.147372]\n",
            "[Epoch 21/50] [Batch 100/368] [D loss: 0.523919] [G loss: 0.385330] [C loss: 0.144887]\n",
            "[Epoch 21/50] [Batch 150/368] [D loss: 0.511115] [G loss: 0.374327] [C loss: 0.174450]\n",
            "[Epoch 21/50] [Batch 200/368] [D loss: 0.519757] [G loss: 0.385301] [C loss: 0.174857]\n",
            "[Epoch 21/50] [Batch 250/368] [D loss: 0.507764] [G loss: 0.400242] [C loss: 0.137812]\n",
            "[Epoch 21/50] [Batch 300/368] [D loss: 0.514833] [G loss: 0.382078] [C loss: 0.147145]\n",
            "[Epoch 21/50] [Batch 350/368] [D loss: 0.514650] [G loss: 0.387221] [C loss: 0.147510]\n",
            "[Epoch 22/50] [Batch 0/368] [D loss: 0.542291] [G loss: 0.379231] [C loss: 0.175737]\n",
            "[Epoch 22/50] [Batch 50/368] [D loss: 0.541139] [G loss: 0.397201] [C loss: 0.186153]\n",
            "[Epoch 22/50] [Batch 100/368] [D loss: 0.527781] [G loss: 0.381672] [C loss: 0.152250]\n",
            "[Epoch 22/50] [Batch 150/368] [D loss: 0.529580] [G loss: 0.397662] [C loss: 0.138316]\n",
            "[Epoch 22/50] [Batch 200/368] [D loss: 0.519957] [G loss: 0.380696] [C loss: 0.153657]\n",
            "[Epoch 22/50] [Batch 250/368] [D loss: 0.518736] [G loss: 0.362345] [C loss: 0.142089]\n",
            "[Epoch 22/50] [Batch 300/368] [D loss: 0.517800] [G loss: 0.370818] [C loss: 0.129552]\n",
            "[Epoch 22/50] [Batch 350/368] [D loss: 0.526676] [G loss: 0.371490] [C loss: 0.155677]\n",
            "[Epoch 23/50] [Batch 0/368] [D loss: 0.525128] [G loss: 0.378825] [C loss: 0.163726]\n",
            "[Epoch 23/50] [Batch 50/368] [D loss: 0.511479] [G loss: 0.365262] [C loss: 0.158882]\n",
            "[Epoch 23/50] [Batch 100/368] [D loss: 0.518330] [G loss: 0.381260] [C loss: 0.143440]\n",
            "[Epoch 23/50] [Batch 150/368] [D loss: 0.503435] [G loss: 0.378990] [C loss: 0.155351]\n",
            "[Epoch 23/50] [Batch 200/368] [D loss: 0.525463] [G loss: 0.380779] [C loss: 0.166301]\n",
            "[Epoch 23/50] [Batch 250/368] [D loss: 0.505511] [G loss: 0.377513] [C loss: 0.163323]\n",
            "[Epoch 23/50] [Batch 300/368] [D loss: 0.510222] [G loss: 0.410871] [C loss: 0.149418]\n",
            "[Epoch 23/50] [Batch 350/368] [D loss: 0.514823] [G loss: 0.386620] [C loss: 0.141697]\n",
            "[Epoch 24/50] [Batch 0/368] [D loss: 0.505970] [G loss: 0.380741] [C loss: 0.162056]\n",
            "[Epoch 24/50] [Batch 50/368] [D loss: 0.508700] [G loss: 0.394190] [C loss: 0.158446]\n",
            "[Epoch 24/50] [Batch 100/368] [D loss: 0.506523] [G loss: 0.401693] [C loss: 0.140350]\n",
            "[Epoch 24/50] [Batch 150/368] [D loss: 0.505530] [G loss: 0.371461] [C loss: 0.137917]\n",
            "[Epoch 24/50] [Batch 200/368] [D loss: 0.518195] [G loss: 0.391434] [C loss: 0.146501]\n",
            "[Epoch 24/50] [Batch 250/368] [D loss: 0.519058] [G loss: 0.378994] [C loss: 0.129836]\n",
            "[Epoch 24/50] [Batch 300/368] [D loss: 0.506830] [G loss: 0.367508] [C loss: 0.126400]\n",
            "[Epoch 24/50] [Batch 350/368] [D loss: 0.504026] [G loss: 0.400052] [C loss: 0.143464]\n",
            "[Epoch 25/50] [Batch 0/368] [D loss: 0.517385] [G loss: 0.372581] [C loss: 0.149617]\n",
            "[Epoch 25/50] [Batch 50/368] [D loss: 0.520373] [G loss: 0.374606] [C loss: 0.136465]\n",
            "[Epoch 25/50] [Batch 100/368] [D loss: 0.499999] [G loss: 0.378816] [C loss: 0.129564]\n",
            "[Epoch 25/50] [Batch 150/368] [D loss: 0.513810] [G loss: 0.362492] [C loss: 0.150223]\n",
            "[Epoch 25/50] [Batch 200/368] [D loss: 0.531173] [G loss: 0.382001] [C loss: 0.167704]\n",
            "[Epoch 25/50] [Batch 250/368] [D loss: 0.498988] [G loss: 0.378146] [C loss: 0.131919]\n",
            "[Epoch 25/50] [Batch 300/368] [D loss: 0.502419] [G loss: 0.381207] [C loss: 0.132782]\n",
            "[Epoch 25/50] [Batch 350/368] [D loss: 0.498551] [G loss: 0.373121] [C loss: 0.140447]\n",
            "[Epoch 26/50] [Batch 0/368] [D loss: 0.508607] [G loss: 0.386593] [C loss: 0.135844]\n",
            "[Epoch 26/50] [Batch 50/368] [D loss: 0.500183] [G loss: 0.378734] [C loss: 0.135201]\n",
            "[Epoch 26/50] [Batch 100/368] [D loss: 0.509708] [G loss: 0.376038] [C loss: 0.136578]\n",
            "[Epoch 26/50] [Batch 150/368] [D loss: 0.516958] [G loss: 0.375053] [C loss: 0.138911]\n",
            "[Epoch 26/50] [Batch 200/368] [D loss: 0.514577] [G loss: 0.366192] [C loss: 0.130508]\n",
            "[Epoch 26/50] [Batch 250/368] [D loss: 0.514339] [G loss: 0.402917] [C loss: 0.135841]\n",
            "[Epoch 26/50] [Batch 300/368] [D loss: 0.504973] [G loss: 0.367236] [C loss: 0.154532]\n",
            "[Epoch 26/50] [Batch 350/368] [D loss: 0.515334] [G loss: 0.369825] [C loss: 0.155187]\n",
            "[Epoch 27/50] [Batch 0/368] [D loss: 0.521772] [G loss: 0.367851] [C loss: 0.139242]\n",
            "[Epoch 27/50] [Batch 50/368] [D loss: 0.506150] [G loss: 0.379256] [C loss: 0.113659]\n",
            "[Epoch 27/50] [Batch 100/368] [D loss: 0.512525] [G loss: 0.373495] [C loss: 0.141516]\n",
            "[Epoch 27/50] [Batch 150/368] [D loss: 0.509951] [G loss: 0.393647] [C loss: 0.133302]\n",
            "[Epoch 27/50] [Batch 200/368] [D loss: 0.505954] [G loss: 0.385228] [C loss: 0.110296]\n",
            "[Epoch 27/50] [Batch 250/368] [D loss: 0.497847] [G loss: 0.390089] [C loss: 0.112339]\n",
            "[Epoch 27/50] [Batch 300/368] [D loss: 0.495023] [G loss: 0.364729] [C loss: 0.119508]\n",
            "[Epoch 27/50] [Batch 350/368] [D loss: 0.500514] [G loss: 0.376338] [C loss: 0.121552]\n",
            "[Epoch 28/50] [Batch 0/368] [D loss: 0.519269] [G loss: 0.375568] [C loss: 0.128249]\n",
            "[Epoch 28/50] [Batch 50/368] [D loss: 0.517223] [G loss: 0.358085] [C loss: 0.117153]\n",
            "[Epoch 28/50] [Batch 100/368] [D loss: 0.516740] [G loss: 0.366506] [C loss: 0.134712]\n",
            "[Epoch 28/50] [Batch 150/368] [D loss: 0.504543] [G loss: 0.382124] [C loss: 0.124906]\n",
            "[Epoch 28/50] [Batch 200/368] [D loss: 0.516139] [G loss: 0.376339] [C loss: 0.135503]\n",
            "[Epoch 28/50] [Batch 250/368] [D loss: 0.507793] [G loss: 0.383476] [C loss: 0.125564]\n",
            "[Epoch 28/50] [Batch 300/368] [D loss: 0.523553] [G loss: 0.384911] [C loss: 0.149242]\n",
            "[Epoch 28/50] [Batch 350/368] [D loss: 0.517711] [G loss: 0.373578] [C loss: 0.147281]\n",
            "[Epoch 29/50] [Batch 0/368] [D loss: 0.495678] [G loss: 0.364240] [C loss: 0.130362]\n",
            "[Epoch 29/50] [Batch 50/368] [D loss: 0.516473] [G loss: 0.405994] [C loss: 0.148194]\n",
            "[Epoch 29/50] [Batch 100/368] [D loss: 0.495278] [G loss: 0.377993] [C loss: 0.109929]\n",
            "[Epoch 29/50] [Batch 150/368] [D loss: 0.496714] [G loss: 0.376824] [C loss: 0.114347]\n",
            "[Epoch 29/50] [Batch 200/368] [D loss: 0.519622] [G loss: 0.369158] [C loss: 0.136753]\n",
            "[Epoch 29/50] [Batch 250/368] [D loss: 0.517294] [G loss: 0.378098] [C loss: 0.119545]\n",
            "[Epoch 29/50] [Batch 300/368] [D loss: 0.501757] [G loss: 0.377104] [C loss: 0.125660]\n",
            "[Epoch 29/50] [Batch 350/368] [D loss: 0.484690] [G loss: 0.371032] [C loss: 0.115444]\n",
            "[Epoch 30/50] [Batch 0/368] [D loss: 0.511043] [G loss: 0.364542] [C loss: 0.138458]\n",
            "[Epoch 30/50] [Batch 50/368] [D loss: 0.495044] [G loss: 0.389428] [C loss: 0.106353]\n",
            "[Epoch 30/50] [Batch 100/368] [D loss: 0.514417] [G loss: 0.371063] [C loss: 0.129460]\n",
            "[Epoch 30/50] [Batch 150/368] [D loss: 0.512203] [G loss: 0.379136] [C loss: 0.132970]\n",
            "[Epoch 30/50] [Batch 200/368] [D loss: 0.496669] [G loss: 0.379008] [C loss: 0.134054]\n",
            "[Epoch 30/50] [Batch 250/368] [D loss: 0.499557] [G loss: 0.370963] [C loss: 0.111357]\n",
            "[Epoch 30/50] [Batch 300/368] [D loss: 0.504565] [G loss: 0.371226] [C loss: 0.122476]\n",
            "[Epoch 30/50] [Batch 350/368] [D loss: 0.490518] [G loss: 0.378110] [C loss: 0.112015]\n",
            "[Epoch 31/50] [Batch 0/368] [D loss: 0.501740] [G loss: 0.372059] [C loss: 0.122698]\n",
            "[Epoch 31/50] [Batch 50/368] [D loss: 0.487455] [G loss: 0.370648] [C loss: 0.108801]\n",
            "[Epoch 31/50] [Batch 100/368] [D loss: 0.501877] [G loss: 0.386109] [C loss: 0.116139]\n",
            "[Epoch 31/50] [Batch 150/368] [D loss: 0.506721] [G loss: 0.377882] [C loss: 0.110815]\n",
            "[Epoch 31/50] [Batch 200/368] [D loss: 0.509213] [G loss: 0.377738] [C loss: 0.126905]\n",
            "[Epoch 31/50] [Batch 250/368] [D loss: 0.480366] [G loss: 0.374697] [C loss: 0.119163]\n",
            "[Epoch 31/50] [Batch 300/368] [D loss: 0.509185] [G loss: 0.374782] [C loss: 0.116606]\n",
            "[Epoch 31/50] [Batch 350/368] [D loss: 0.493741] [G loss: 0.370594] [C loss: 0.099087]\n",
            "[Epoch 32/50] [Batch 0/368] [D loss: 0.518561] [G loss: 0.382694] [C loss: 0.147634]\n",
            "[Epoch 32/50] [Batch 50/368] [D loss: 0.513255] [G loss: 0.382951] [C loss: 0.105855]\n",
            "[Epoch 32/50] [Batch 100/368] [D loss: 0.516119] [G loss: 0.373655] [C loss: 0.136365]\n",
            "[Epoch 32/50] [Batch 150/368] [D loss: 0.499467] [G loss: 0.370247] [C loss: 0.129294]\n",
            "[Epoch 32/50] [Batch 200/368] [D loss: 0.505955] [G loss: 0.355839] [C loss: 0.126813]\n",
            "[Epoch 32/50] [Batch 250/368] [D loss: 0.498873] [G loss: 0.378860] [C loss: 0.126395]\n",
            "[Epoch 32/50] [Batch 300/368] [D loss: 0.501014] [G loss: 0.376667] [C loss: 0.117887]\n",
            "[Epoch 32/50] [Batch 350/368] [D loss: 0.509549] [G loss: 0.387251] [C loss: 0.122800]\n",
            "[Epoch 33/50] [Batch 0/368] [D loss: 0.493513] [G loss: 0.372551] [C loss: 0.125903]\n",
            "[Epoch 33/50] [Batch 50/368] [D loss: 0.511867] [G loss: 0.375811] [C loss: 0.118689]\n",
            "[Epoch 33/50] [Batch 100/368] [D loss: 0.513166] [G loss: 0.367645] [C loss: 0.117927]\n",
            "[Epoch 33/50] [Batch 150/368] [D loss: 0.503739] [G loss: 0.368845] [C loss: 0.121350]\n",
            "[Epoch 33/50] [Batch 200/368] [D loss: 0.506126] [G loss: 0.376439] [C loss: 0.102674]\n",
            "[Epoch 33/50] [Batch 250/368] [D loss: 0.510463] [G loss: 0.377403] [C loss: 0.130456]\n",
            "[Epoch 33/50] [Batch 300/368] [D loss: 0.503699] [G loss: 0.379913] [C loss: 0.107054]\n",
            "[Epoch 33/50] [Batch 350/368] [D loss: 0.495621] [G loss: 0.374852] [C loss: 0.121243]\n",
            "[Epoch 34/50] [Batch 0/368] [D loss: 0.483027] [G loss: 0.367032] [C loss: 0.096441]\n",
            "[Epoch 34/50] [Batch 50/368] [D loss: 0.498528] [G loss: 0.373338] [C loss: 0.118537]\n",
            "[Epoch 34/50] [Batch 100/368] [D loss: 0.507636] [G loss: 0.365724] [C loss: 0.135573]\n",
            "[Epoch 34/50] [Batch 150/368] [D loss: 0.506039] [G loss: 0.377977] [C loss: 0.101605]\n",
            "[Epoch 34/50] [Batch 200/368] [D loss: 0.493867] [G loss: 0.353352] [C loss: 0.105675]\n",
            "[Epoch 34/50] [Batch 250/368] [D loss: 0.502912] [G loss: 0.384406] [C loss: 0.106839]\n",
            "[Epoch 34/50] [Batch 300/368] [D loss: 0.515496] [G loss: 0.378779] [C loss: 0.129739]\n",
            "[Epoch 34/50] [Batch 350/368] [D loss: 0.506900] [G loss: 0.359030] [C loss: 0.115989]\n",
            "[Epoch 35/50] [Batch 0/368] [D loss: 0.508089] [G loss: 0.355928] [C loss: 0.110058]\n",
            "[Epoch 35/50] [Batch 50/368] [D loss: 0.508341] [G loss: 0.372527] [C loss: 0.128989]\n",
            "[Epoch 35/50] [Batch 100/368] [D loss: 0.519533] [G loss: 0.368588] [C loss: 0.122423]\n",
            "[Epoch 35/50] [Batch 150/368] [D loss: 0.495352] [G loss: 0.365848] [C loss: 0.101748]\n",
            "[Epoch 35/50] [Batch 200/368] [D loss: 0.488536] [G loss: 0.368746] [C loss: 0.106494]\n",
            "[Epoch 35/50] [Batch 250/368] [D loss: 0.505662] [G loss: 0.372919] [C loss: 0.110714]\n",
            "[Epoch 35/50] [Batch 300/368] [D loss: 0.512564] [G loss: 0.379728] [C loss: 0.104963]\n",
            "[Epoch 35/50] [Batch 350/368] [D loss: 0.500940] [G loss: 0.362849] [C loss: 0.103690]\n",
            "[Epoch 36/50] [Batch 0/368] [D loss: 0.508037] [G loss: 0.375069] [C loss: 0.121394]\n",
            "[Epoch 36/50] [Batch 50/368] [D loss: 0.508009] [G loss: 0.357722] [C loss: 0.092280]\n",
            "[Epoch 36/50] [Batch 100/368] [D loss: 0.499537] [G loss: 0.370485] [C loss: 0.108960]\n",
            "[Epoch 36/50] [Batch 150/368] [D loss: 0.510677] [G loss: 0.358845] [C loss: 0.116516]\n",
            "[Epoch 36/50] [Batch 200/368] [D loss: 0.501566] [G loss: 0.366565] [C loss: 0.121030]\n",
            "[Epoch 36/50] [Batch 250/368] [D loss: 0.486452] [G loss: 0.374287] [C loss: 0.115281]\n",
            "[Epoch 36/50] [Batch 300/368] [D loss: 0.493663] [G loss: 0.352445] [C loss: 0.118118]\n",
            "[Epoch 36/50] [Batch 350/368] [D loss: 0.488764] [G loss: 0.367465] [C loss: 0.099751]\n",
            "[Epoch 37/50] [Batch 0/368] [D loss: 0.505489] [G loss: 0.366385] [C loss: 0.111217]\n",
            "[Epoch 37/50] [Batch 50/368] [D loss: 0.508627] [G loss: 0.361327] [C loss: 0.120155]\n",
            "[Epoch 37/50] [Batch 100/368] [D loss: 0.485810] [G loss: 0.375016] [C loss: 0.107376]\n",
            "[Epoch 37/50] [Batch 150/368] [D loss: 0.499979] [G loss: 0.359134] [C loss: 0.123715]\n",
            "[Epoch 37/50] [Batch 200/368] [D loss: 0.501887] [G loss: 0.386808] [C loss: 0.097170]\n",
            "[Epoch 37/50] [Batch 250/368] [D loss: 0.496884] [G loss: 0.362170] [C loss: 0.121251]\n",
            "[Epoch 37/50] [Batch 300/368] [D loss: 0.508290] [G loss: 0.367049] [C loss: 0.105034]\n",
            "[Epoch 37/50] [Batch 350/368] [D loss: 0.522165] [G loss: 0.361288] [C loss: 0.127345]\n",
            "[Epoch 38/50] [Batch 0/368] [D loss: 0.495346] [G loss: 0.370094] [C loss: 0.110817]\n",
            "[Epoch 38/50] [Batch 50/368] [D loss: 0.498544] [G loss: 0.375197] [C loss: 0.097772]\n",
            "[Epoch 38/50] [Batch 100/368] [D loss: 0.483314] [G loss: 0.366067] [C loss: 0.088595]\n",
            "[Epoch 38/50] [Batch 150/368] [D loss: 0.509832] [G loss: 0.358477] [C loss: 0.098598]\n",
            "[Epoch 38/50] [Batch 200/368] [D loss: 0.515718] [G loss: 0.369814] [C loss: 0.103110]\n",
            "[Epoch 38/50] [Batch 250/368] [D loss: 0.481346] [G loss: 0.363285] [C loss: 0.091825]\n",
            "[Epoch 38/50] [Batch 300/368] [D loss: 0.490793] [G loss: 0.376439] [C loss: 0.102884]\n",
            "[Epoch 38/50] [Batch 350/368] [D loss: 0.490668] [G loss: 0.357409] [C loss: 0.108938]\n",
            "[Epoch 39/50] [Batch 0/368] [D loss: 0.503093] [G loss: 0.361678] [C loss: 0.100509]\n",
            "[Epoch 39/50] [Batch 50/368] [D loss: 0.496829] [G loss: 0.362493] [C loss: 0.108456]\n",
            "[Epoch 39/50] [Batch 100/368] [D loss: 0.492860] [G loss: 0.369703] [C loss: 0.081940]\n",
            "[Epoch 39/50] [Batch 150/368] [D loss: 0.496302] [G loss: 0.381387] [C loss: 0.096973]\n",
            "[Epoch 39/50] [Batch 200/368] [D loss: 0.505809] [G loss: 0.365987] [C loss: 0.112521]\n",
            "[Epoch 39/50] [Batch 250/368] [D loss: 0.506935] [G loss: 0.377227] [C loss: 0.123216]\n",
            "[Epoch 39/50] [Batch 300/368] [D loss: 0.490119] [G loss: 0.374977] [C loss: 0.107554]\n",
            "[Epoch 39/50] [Batch 350/368] [D loss: 0.500409] [G loss: 0.373718] [C loss: 0.093010]\n",
            "[Epoch 40/50] [Batch 0/368] [D loss: 0.504284] [G loss: 0.361479] [C loss: 0.116954]\n",
            "[Epoch 40/50] [Batch 50/368] [D loss: 0.515581] [G loss: 0.368292] [C loss: 0.105991]\n",
            "[Epoch 40/50] [Batch 100/368] [D loss: 0.485899] [G loss: 0.364234] [C loss: 0.095934]\n",
            "[Epoch 40/50] [Batch 150/368] [D loss: 0.514541] [G loss: 0.362891] [C loss: 0.086319]\n",
            "[Epoch 40/50] [Batch 200/368] [D loss: 0.496175] [G loss: 0.375203] [C loss: 0.103818]\n",
            "[Epoch 40/50] [Batch 250/368] [D loss: 0.490843] [G loss: 0.361246] [C loss: 0.096620]\n",
            "[Epoch 40/50] [Batch 300/368] [D loss: 0.494216] [G loss: 0.366077] [C loss: 0.087259]\n",
            "[Epoch 40/50] [Batch 350/368] [D loss: 0.497914] [G loss: 0.357347] [C loss: 0.105477]\n",
            "[Epoch 41/50] [Batch 0/368] [D loss: 0.493091] [G loss: 0.369222] [C loss: 0.097444]\n",
            "[Epoch 41/50] [Batch 50/368] [D loss: 0.496883] [G loss: 0.369561] [C loss: 0.095981]\n",
            "[Epoch 41/50] [Batch 100/368] [D loss: 0.494008] [G loss: 0.381504] [C loss: 0.104890]\n",
            "[Epoch 41/50] [Batch 150/368] [D loss: 0.488262] [G loss: 0.364582] [C loss: 0.096780]\n",
            "[Epoch 41/50] [Batch 200/368] [D loss: 0.498537] [G loss: 0.371517] [C loss: 0.115302]\n",
            "[Epoch 41/50] [Batch 250/368] [D loss: 0.495669] [G loss: 0.362641] [C loss: 0.111696]\n",
            "[Epoch 41/50] [Batch 300/368] [D loss: 0.485974] [G loss: 0.369484] [C loss: 0.097194]\n",
            "[Epoch 41/50] [Batch 350/368] [D loss: 0.493429] [G loss: 0.371259] [C loss: 0.093779]\n",
            "[Epoch 42/50] [Batch 0/368] [D loss: 0.497750] [G loss: 0.358868] [C loss: 0.086519]\n",
            "[Epoch 42/50] [Batch 50/368] [D loss: 0.491842] [G loss: 0.369192] [C loss: 0.088069]\n",
            "[Epoch 42/50] [Batch 100/368] [D loss: 0.497831] [G loss: 0.373596] [C loss: 0.098791]\n",
            "[Epoch 42/50] [Batch 150/368] [D loss: 0.500771] [G loss: 0.363920] [C loss: 0.100078]\n",
            "[Epoch 42/50] [Batch 200/368] [D loss: 0.488810] [G loss: 0.380379] [C loss: 0.096895]\n",
            "[Epoch 42/50] [Batch 250/368] [D loss: 0.494940] [G loss: 0.364168] [C loss: 0.087341]\n",
            "[Epoch 42/50] [Batch 300/368] [D loss: 0.502993] [G loss: 0.352475] [C loss: 0.106334]\n",
            "[Epoch 42/50] [Batch 350/368] [D loss: 0.496308] [G loss: 0.362881] [C loss: 0.087507]\n",
            "[Epoch 43/50] [Batch 0/368] [D loss: 0.503492] [G loss: 0.371556] [C loss: 0.094515]\n",
            "[Epoch 43/50] [Batch 50/368] [D loss: 0.492914] [G loss: 0.365951] [C loss: 0.109091]\n",
            "[Epoch 43/50] [Batch 100/368] [D loss: 0.501543] [G loss: 0.363321] [C loss: 0.106743]\n",
            "[Epoch 43/50] [Batch 150/368] [D loss: 0.511772] [G loss: 0.365846] [C loss: 0.099144]\n",
            "[Epoch 43/50] [Batch 200/368] [D loss: 0.493883] [G loss: 0.371302] [C loss: 0.092628]\n",
            "[Epoch 43/50] [Batch 250/368] [D loss: 0.493327] [G loss: 0.372759] [C loss: 0.098823]\n",
            "[Epoch 43/50] [Batch 300/368] [D loss: 0.504178] [G loss: 0.370757] [C loss: 0.126439]\n",
            "[Epoch 43/50] [Batch 350/368] [D loss: 0.490342] [G loss: 0.366057] [C loss: 0.101650]\n",
            "[Epoch 44/50] [Batch 0/368] [D loss: 0.486793] [G loss: 0.359939] [C loss: 0.093271]\n",
            "[Epoch 44/50] [Batch 50/368] [D loss: 0.498844] [G loss: 0.361736] [C loss: 0.096973]\n",
            "[Epoch 44/50] [Batch 100/368] [D loss: 0.498752] [G loss: 0.359346] [C loss: 0.094162]\n",
            "[Epoch 44/50] [Batch 150/368] [D loss: 0.487730] [G loss: 0.363474] [C loss: 0.087663]\n",
            "[Epoch 44/50] [Batch 200/368] [D loss: 0.494700] [G loss: 0.356209] [C loss: 0.085643]\n",
            "[Epoch 44/50] [Batch 250/368] [D loss: 0.501350] [G loss: 0.371831] [C loss: 0.101660]\n",
            "[Epoch 44/50] [Batch 300/368] [D loss: 0.482811] [G loss: 0.385866] [C loss: 0.096900]\n",
            "[Epoch 44/50] [Batch 350/368] [D loss: 0.489018] [G loss: 0.379876] [C loss: 0.088884]\n",
            "[Epoch 45/50] [Batch 0/368] [D loss: 0.491902] [G loss: 0.366643] [C loss: 0.105272]\n",
            "[Epoch 45/50] [Batch 50/368] [D loss: 0.491172] [G loss: 0.374108] [C loss: 0.098145]\n",
            "[Epoch 45/50] [Batch 100/368] [D loss: 0.495771] [G loss: 0.365611] [C loss: 0.101452]\n",
            "[Epoch 45/50] [Batch 150/368] [D loss: 0.505064] [G loss: 0.354146] [C loss: 0.111116]\n",
            "[Epoch 45/50] [Batch 200/368] [D loss: 0.501949] [G loss: 0.353381] [C loss: 0.099139]\n",
            "[Epoch 45/50] [Batch 250/368] [D loss: 0.493123] [G loss: 0.358555] [C loss: 0.085643]\n",
            "[Epoch 45/50] [Batch 300/368] [D loss: 0.510378] [G loss: 0.373407] [C loss: 0.111535]\n",
            "[Epoch 45/50] [Batch 350/368] [D loss: 0.498821] [G loss: 0.368072] [C loss: 0.097167]\n",
            "[Epoch 46/50] [Batch 0/368] [D loss: 0.494102] [G loss: 0.354519] [C loss: 0.097225]\n",
            "[Epoch 46/50] [Batch 50/368] [D loss: 0.494293] [G loss: 0.356981] [C loss: 0.085145]\n",
            "[Epoch 46/50] [Batch 100/368] [D loss: 0.488304] [G loss: 0.365865] [C loss: 0.089487]\n",
            "[Epoch 46/50] [Batch 150/368] [D loss: 0.502342] [G loss: 0.368879] [C loss: 0.096407]\n",
            "[Epoch 46/50] [Batch 200/368] [D loss: 0.484223] [G loss: 0.367537] [C loss: 0.078869]\n",
            "[Epoch 46/50] [Batch 250/368] [D loss: 0.490448] [G loss: 0.372988] [C loss: 0.096832]\n",
            "[Epoch 46/50] [Batch 300/368] [D loss: 0.499283] [G loss: 0.356297] [C loss: 0.094114]\n",
            "[Epoch 46/50] [Batch 350/368] [D loss: 0.487608] [G loss: 0.377885] [C loss: 0.076247]\n",
            "[Epoch 47/50] [Batch 0/368] [D loss: 0.496622] [G loss: 0.370442] [C loss: 0.089568]\n",
            "[Epoch 47/50] [Batch 50/368] [D loss: 0.484214] [G loss: 0.354855] [C loss: 0.080206]\n",
            "[Epoch 47/50] [Batch 100/368] [D loss: 0.495733] [G loss: 0.357821] [C loss: 0.104450]\n",
            "[Epoch 47/50] [Batch 150/368] [D loss: 0.484756] [G loss: 0.373300] [C loss: 0.090421]\n",
            "[Epoch 47/50] [Batch 200/368] [D loss: 0.486912] [G loss: 0.371615] [C loss: 0.086848]\n",
            "[Epoch 47/50] [Batch 250/368] [D loss: 0.491147] [G loss: 0.360327] [C loss: 0.097592]\n",
            "[Epoch 47/50] [Batch 300/368] [D loss: 0.497662] [G loss: 0.370244] [C loss: 0.101522]\n",
            "[Epoch 47/50] [Batch 350/368] [D loss: 0.482279] [G loss: 0.365460] [C loss: 0.086467]\n",
            "[Epoch 48/50] [Batch 0/368] [D loss: 0.491892] [G loss: 0.365210] [C loss: 0.099961]\n",
            "[Epoch 48/50] [Batch 50/368] [D loss: 0.501330] [G loss: 0.359568] [C loss: 0.100569]\n",
            "[Epoch 48/50] [Batch 100/368] [D loss: 0.506031] [G loss: 0.364092] [C loss: 0.119664]\n",
            "[Epoch 48/50] [Batch 150/368] [D loss: 0.491055] [G loss: 0.361033] [C loss: 0.089831]\n",
            "[Epoch 48/50] [Batch 200/368] [D loss: 0.492680] [G loss: 0.369775] [C loss: 0.107650]\n",
            "[Epoch 48/50] [Batch 250/368] [D loss: 0.500189] [G loss: 0.363759] [C loss: 0.090483]\n",
            "[Epoch 48/50] [Batch 300/368] [D loss: 0.499696] [G loss: 0.378492] [C loss: 0.086965]\n",
            "[Epoch 48/50] [Batch 350/368] [D loss: 0.489817] [G loss: 0.360303] [C loss: 0.095666]\n",
            "[Epoch 49/50] [Batch 0/368] [D loss: 0.476086] [G loss: 0.367497] [C loss: 0.083855]\n",
            "[Epoch 49/50] [Batch 50/368] [D loss: 0.486030] [G loss: 0.370915] [C loss: 0.090079]\n",
            "[Epoch 49/50] [Batch 100/368] [D loss: 0.486696] [G loss: 0.376628] [C loss: 0.095621]\n",
            "[Epoch 49/50] [Batch 150/368] [D loss: 0.496664] [G loss: 0.354801] [C loss: 0.089863]\n",
            "[Epoch 49/50] [Batch 200/368] [D loss: 0.497535] [G loss: 0.352558] [C loss: 0.097814]\n",
            "[Epoch 49/50] [Batch 250/368] [D loss: 0.498660] [G loss: 0.373198] [C loss: 0.093808]\n",
            "[Epoch 49/50] [Batch 300/368] [D loss: 0.494293] [G loss: 0.373812] [C loss: 0.080285]\n",
            "[Epoch 49/50] [Batch 350/368] [D loss: 0.478928] [G loss: 0.361884] [C loss: 0.088207]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"GAN Generator, Discriminator, Embedding Loss During Training\")\n",
        "plt.plot(G_losses,label=\"Generator\")\n",
        "plt.plot(D_losses,label=\"Discriminator\")\n",
        "plt.plot(C_losses, label=\"Embedding\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "12b8A9Rcmf0H",
        "outputId": "44a284e4-86cf-4cbf-c41a-6761dc9318fa"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"MSE between missing and predicted node\")\n",
        "plt.plot(V_losses, label=\"Validation\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "F1gxeinDp8jo",
        "outputId": "b60d5d58-2ece-4ba4-cc6b-ec18ce1916be"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Test**"
      ],
      "metadata": {
        "id": "9WBf3cjshuDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "missing_nodes_embeddings = []\n",
        "generator.eval()\n",
        "classifier.eval()\n",
        "\n",
        "for recipe_emb in x_val_com_dataset:\n",
        "  recipe_emb = data['recipe'].to(device)\n",
        "  # noise = Variable(torch.FloatTensor(np.random.normal(0, 1, (recipe_emb.shape[0], args.latent_dim)))).to(device)\n",
        "  noise = Variable(torch.FloatTensor(np.full((recipe_emb.shape[0], args.latent_dim), 0.001))).to(device)\n",
        "  generated = generator(torch.cat((noise, recipe_emb), dim=1))\n",
        "  generated = generated.type(torch.float).to(device)\n",
        "  partition = classifier(generated)\n",
        "  missing_nodes_embeddings.append(partition)\n",
        "\n",
        "missing_nodes_embeddings = torch.cat(missing_nodes_embeddings, dim=0)"
      ],
      "metadata": {
        "id": "xL1cnbcn2pjF"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_nodes_embeddings = missing_nodes_embeddings.cpu().detach().numpy()"
      ],
      "metadata": {
        "id": "kuJVYJyptOJR"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def L2_loop_function(X_test, X_train):\n",
        "  test_data_shape = X_test.shape[0]\n",
        "  train_data_shape = X_train.shape[0]\n",
        "  distances = np.zeros((test_data_shape, train_data_shape))\n",
        "\n",
        "  for i in range(test_data_shape):\n",
        "      distances[i, :] = np.sum((X_train - X_test[i, :]) ** 2, axis = 1) #no need to sqrt as it causes the same effect\n",
        "\n",
        "  return distances\n",
        "\n",
        "def L2_vectorized_function(X_test, X_train):\n",
        "  X_test_squared = np.sum(np.square(X_test), axis=1, keepdims=True)\n",
        "  X_train_squared = np.sum(np.square(X_train), axis=1, keepdims=True)\n",
        "  X_test_X_train = np.dot(X_test, X_train.T)\n",
        "\n",
        "  return X_test_squared - (2 * X_test_X_train) + X_train_squared.T\n",
        "\n",
        "def predict_missing_node(X_test, X_train, typ=0):\n",
        "  if typ == 0:\n",
        "      method = L2_vectorized_function(X_test, X_train)\n",
        "  else:\n",
        "      method = L2_loop_function(X_test, X_train)\n",
        "  nodes = np.argmin(method, axis=1)\n",
        "  return nodes"
      ],
      "metadata": {
        "id": "li81WktQmdIO"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def val_completion_missing():\n",
        "  target = []\n",
        "  with open (\"validation_completion_answer.csv\", \"r\") as f:\n",
        "    data = f.readlines()\n",
        "    for i in range(len(data)):\n",
        "      target.append(int(data[i]))\n",
        "  return target\n",
        "  \n",
        "val_missing_nodes = val_completion_missing()"
      ],
      "metadata": {
        "id": "d0r-1q8Kxv2K"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_missing_nodes = predict_missing_node(missing_nodes_embeddings, embeddings.to_numpy(), 1).tolist()"
      ],
      "metadata": {
        "id": "U_WEhsZ2q33j"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for i, j in zip(pred_missing_nodes, val_missing_nodes):\n",
        "  if i == j:\n",
        "    count += 1\n",
        "print(f\"Matched: {count} Validation accuracy: {(count/len(val_missing_nodes))*100:.4} %\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxwCEaIzzFuh",
        "outputId": "17fcdd03-60f3-474a-9c28-ee2ceb552426"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matched: 0 Validation accuracy: 0.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqUFcRgtmUTZ"
      },
      "source": [
        "## **KNN**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = predict_missing_node(x_val_com_dataset, embeddings.to_numpy())"
      ],
      "metadata": {
        "id": "z6EEokFUSdJ8"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for i, j in zip(val_missing_nodes, output.tolist()):\n",
        "  if i == j:\n",
        "    count += 1\n",
        "print(f\"Matched: {count} Validation accuracy: {(count/len(val_missing_nodes))*100:.4} %\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPXHhJhhVr3o",
        "outputId": "194fcc7a-528e-48eb-e7b6-b03159b17b1e"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy: 0.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_ = predict_missing_node(x_test_com_dataset, scaled_node_features)"
      ],
      "metadata": {
        "id": "lgCxEZh_z4xG"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(output_.tolist(), columns = [\"ingredient\"]).to_csv(os.path.join(results, \"test_completion_answer.csv\"))"
      ],
      "metadata": {
        "id": "WaFAWkL4LOyO"
      },
      "execution_count": 72,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "term_project.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMWPotklXl7JTCY0kolN27l",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}