{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Coursework2_II.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOZtgOiXUVPcz2GWoRs7mAl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "333fc5d119294ae0981234e87e7fa546": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ea5171526dd44f7da12a98a5f5b8219c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_191e15dc58324de78f56f797defb8ae2",
              "IPY_MODEL_22fd99b64ecd4426991300130aab50dc",
              "IPY_MODEL_2e569528380e4325a40580f56e430d88"
            ]
          }
        },
        "ea5171526dd44f7da12a98a5f5b8219c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "191e15dc58324de78f56f797defb8ae2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_caf79f20bd3e421d8d0ddb69e4ee3608",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c4de0089ce6f4d64a91b8244177ea3db"
          }
        },
        "22fd99b64ecd4426991300130aab50dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fdb9373b6e6f4a5b85cdc577a8dfa0f6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 9912422,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9912422,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f1bd5c041d5b4cd2a51f033519f42814"
          }
        },
        "2e569528380e4325a40580f56e430d88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_08ec6437c8b748518becb60bd37a0bb1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9913344/? [00:00&lt;00:00, 23289272.40it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c4a30915bf77441597d875d9db264587"
          }
        },
        "caf79f20bd3e421d8d0ddb69e4ee3608": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c4de0089ce6f4d64a91b8244177ea3db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fdb9373b6e6f4a5b85cdc577a8dfa0f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f1bd5c041d5b4cd2a51f033519f42814": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "08ec6437c8b748518becb60bd37a0bb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c4a30915bf77441597d875d9db264587": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4a9a96b5a21c4a19b3f34ec7b9657f97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_af89c263e3f74d4fa00ea525bd78535a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_833385b8e62545aabaced72244b71f98",
              "IPY_MODEL_4c29379e57a244a49a5673817d29a2da",
              "IPY_MODEL_6f39663a247f49bfa93ca8ecc90eebfc"
            ]
          }
        },
        "af89c263e3f74d4fa00ea525bd78535a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "833385b8e62545aabaced72244b71f98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0dbb41be9b11455aa5468655681e5fdd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_02da38ad5388405ba3b43fc30b9bf25b"
          }
        },
        "4c29379e57a244a49a5673817d29a2da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1f71a1a7f8744362b865755182ebf69e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1350fa925c8e48fe8bf78c7ebc5d0492"
          }
        },
        "6f39663a247f49bfa93ca8ecc90eebfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_91673475d8fc48a7850f4f7be80c3080",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29696/? [00:00&lt;00:00, 1291384.67it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6f73ee9bf167443e8012720b791fa14b"
          }
        },
        "0dbb41be9b11455aa5468655681e5fdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "02da38ad5388405ba3b43fc30b9bf25b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f71a1a7f8744362b865755182ebf69e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1350fa925c8e48fe8bf78c7ebc5d0492": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "91673475d8fc48a7850f4f7be80c3080": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6f73ee9bf167443e8012720b791fa14b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c2cd76a8d20e423b9701e0692483c68d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b6f582d56a4f42d0a953f160b1037907",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cd09c1f08e1743afbae5ed1fd8726ef8",
              "IPY_MODEL_a0b325ac2cfe441e87841d76d762b2c1",
              "IPY_MODEL_2073b31d870c4387a1f49879e85e020a"
            ]
          }
        },
        "b6f582d56a4f42d0a953f160b1037907": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cd09c1f08e1743afbae5ed1fd8726ef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f14332c135a54cbd93a2052a276beeb3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cd6f5bf440e24637840cfaf9be3bc03e"
          }
        },
        "a0b325ac2cfe441e87841d76d762b2c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f1dab29c78ea4dc79b359aa6acca4778",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1648877,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1648877,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3a58ee7afa1e41c98d89bb4576ad0eff"
          }
        },
        "2073b31d870c4387a1f49879e85e020a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d2f864c499654328a3310397a5e82600",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1649664/? [00:00&lt;00:00, 3529101.31it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ec1f546cc32340538b425854ac171fc3"
          }
        },
        "f14332c135a54cbd93a2052a276beeb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cd6f5bf440e24637840cfaf9be3bc03e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f1dab29c78ea4dc79b359aa6acca4778": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3a58ee7afa1e41c98d89bb4576ad0eff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d2f864c499654328a3310397a5e82600": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ec1f546cc32340538b425854ac171fc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1c62c97c7ef84accba0933a50c71c943": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_504eaea69ebe46f1af6ad085aa3ca993",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d9782cfad5c54efbaf850ad63615a951",
              "IPY_MODEL_edc26b75d55c4199abcac1340d99e0fb",
              "IPY_MODEL_3d33c8218248454497f96a9f396792c8"
            ]
          }
        },
        "504eaea69ebe46f1af6ad085aa3ca993": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d9782cfad5c54efbaf850ad63615a951": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a3546db13f8f4b2c83a1468e0f867d51",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7cc10fd547a246ba83c86eb8fc44e2b7"
          }
        },
        "edc26b75d55c4199abcac1340d99e0fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bc9b74a4e33d4daaba87679d0ff23082",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4542,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4542,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ad8d375f073e4a14b93d21f0ebc1e0db"
          }
        },
        "3d33c8218248454497f96a9f396792c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c70d3db41abe41029f320ff434ef447c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5120/? [00:00&lt;00:00, 223393.70it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_738a607082bb43699a2c7c706fe164aa"
          }
        },
        "a3546db13f8f4b2c83a1468e0f867d51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7cc10fd547a246ba83c86eb8fc44e2b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bc9b74a4e33d4daaba87679d0ff23082": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ad8d375f073e4a14b93d21f0ebc1e0db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c70d3db41abe41029f320ff434ef447c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "738a607082bb43699a2c7c706fe164aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "42cbe151ca2c4b5c813646f3fb26e6fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_329ee380b2cc431db0e01c85099f7fdf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8b88673145f144c3ae424dd592f8bab1",
              "IPY_MODEL_8b6db8d1cc084264809a5132312ad4d2",
              "IPY_MODEL_f5d5b652635a446b887e586b9c0b9078"
            ]
          }
        },
        "329ee380b2cc431db0e01c85099f7fdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b88673145f144c3ae424dd592f8bab1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7cc36dd5df654108a525d2340d5880c2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d66b701cf8b34a60ab6eb2bab056e7e1"
          }
        },
        "8b6db8d1cc084264809a5132312ad4d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_922fa7c1a9a249ca8f202e1f87a51a93",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 9912422,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9912422,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ef70d76a2be94d6cb639706669a3542d"
          }
        },
        "f5d5b652635a446b887e586b9c0b9078": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_659ea88393a14dd19975ae60c3757bee",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9913344/? [00:00&lt;00:00, 27150401.35it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d3627d7a164644aa972053e68f3aae2f"
          }
        },
        "7cc36dd5df654108a525d2340d5880c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d66b701cf8b34a60ab6eb2bab056e7e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "922fa7c1a9a249ca8f202e1f87a51a93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ef70d76a2be94d6cb639706669a3542d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "659ea88393a14dd19975ae60c3757bee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d3627d7a164644aa972053e68f3aae2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8c94c269ad4848e5831eaadd588d0089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0cf134d555c949318dd69c7958dc3852",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1b515d557025496597e6945c78fcad4e",
              "IPY_MODEL_ea2c9473806e49cfaa54f27b2deabf57",
              "IPY_MODEL_827b32c404ce423889448dcc9c33fd6c"
            ]
          }
        },
        "0cf134d555c949318dd69c7958dc3852": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b515d557025496597e6945c78fcad4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a1ef3a89ac1d421bab6419c1e172a471",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3b341790b1db40f18659ddf336fc22ec"
          }
        },
        "ea2c9473806e49cfaa54f27b2deabf57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d450b455f70b472d97d5f91877de0d41",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3bd643dad5b04e2aa4f174379883995d"
          }
        },
        "827b32c404ce423889448dcc9c33fd6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b27527cfb48944afbb4984020b1ce314",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29696/? [00:00&lt;00:00, 1089692.67it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4b6e353c8cc64451ad4c50b1301cbd56"
          }
        },
        "a1ef3a89ac1d421bab6419c1e172a471": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3b341790b1db40f18659ddf336fc22ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d450b455f70b472d97d5f91877de0d41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3bd643dad5b04e2aa4f174379883995d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b27527cfb48944afbb4984020b1ce314": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4b6e353c8cc64451ad4c50b1301cbd56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ce2056a050e74ad185a609e8985f7d4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_efeccfea3ebe4c41a33beb3e929948be",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dd3153f229d44354b8541ffb1a69495d",
              "IPY_MODEL_40e5512c5f3d4a4daf507b6722cbf8dd",
              "IPY_MODEL_22e245acb46042a1aed07ef9b5d6466b"
            ]
          }
        },
        "efeccfea3ebe4c41a33beb3e929948be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dd3153f229d44354b8541ffb1a69495d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_aa932f104d264627a2a1dbade0bc5b52",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5317d83580d74e5e89061c05ef1afc62"
          }
        },
        "40e5512c5f3d4a4daf507b6722cbf8dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bdccbe889b584b9ab4c3b1f59450f822",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1648877,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1648877,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1a3fc536af7840cf9bb8c7197ccb545c"
          }
        },
        "22e245acb46042a1aed07ef9b5d6466b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_218e8334e8ab41dea6694f7b3776b826",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1649664/? [00:00&lt;00:00, 3337885.07it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_261e0ee31dd34bcf9555efd7bfb0b1b7"
          }
        },
        "aa932f104d264627a2a1dbade0bc5b52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5317d83580d74e5e89061c05ef1afc62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bdccbe889b584b9ab4c3b1f59450f822": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1a3fc536af7840cf9bb8c7197ccb545c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "218e8334e8ab41dea6694f7b3776b826": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "261e0ee31dd34bcf9555efd7bfb0b1b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "256a793c63fe4bd396c36a87ba458cff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d0d0ee7f44c8489f8b30343743344d9a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8c728c07b66146b59bd14629edfd13ce",
              "IPY_MODEL_1552f877ca1b4af894e7dda8ff8f8ef0",
              "IPY_MODEL_046871d9dc5d4d738ccc9eb8ebf82e8f"
            ]
          }
        },
        "d0d0ee7f44c8489f8b30343743344d9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8c728c07b66146b59bd14629edfd13ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f8b28765edd74090a95b250605d5772d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2f78ad22404c4c2da64e3519e3913734"
          }
        },
        "1552f877ca1b4af894e7dda8ff8f8ef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ae70b7ff3f2b41428ddca7f66c3d6515",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4542,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4542,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e3c1911bec44946a324f2c45cf1396f"
          }
        },
        "046871d9dc5d4d738ccc9eb8ebf82e8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_801c006f673f48c58c82a84f1545c08a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5120/? [00:00&lt;00:00, 228499.46it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dda768e6780f4ffbb169e54859fc7778"
          }
        },
        "f8b28765edd74090a95b250605d5772d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2f78ad22404c4c2da64e3519e3913734": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ae70b7ff3f2b41428ddca7f66c3d6515": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e3c1911bec44946a324f2c45cf1396f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "801c006f673f48c58c82a84f1545c08a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dda768e6780f4ffbb169e54859fc7778": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kaidavid/CS492A_Courseworks/blob/master/Coursework2_II.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/gdrive')\n",
        "root = '/gdrive/My Drive/CS492A/Courserwork2'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ea5RUYbkblqR",
        "outputId": "e67654f6-16c9-426c-93be-dcee63245899"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import plotly.graph_objects as go\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "from plotly.subplots import make_subplots\n",
        "from collections import Counter\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import make_grid\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.utils.data import DataLoader\n",
        "from easydict import EasyDict as edict"
      ],
      "metadata": {
        "id": "00SdPZRayIp6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(470)\n",
        "torch.cuda.manual_seed(470)\n",
        "\n",
        "opt = edict()\n",
        "\n",
        "opt.n_epochs = 200\n",
        "opt.batch_size = 128\n",
        "opt.lr = 0.0002\n",
        "opt.b1 = 0.5\n",
        "opt.b2 = 0.999\n",
        "opt.n_cpu = 8\n",
        "opt.latent_dim = 100\n",
        "opt.img_size = 32\n",
        "opt.channels = 1\n",
        "opt.sample_interval = 400\n",
        "\n",
        "cuda = True if torch.cuda.is_available() else False"
      ],
      "metadata": {
        "id": "I4f0j9jukVkD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "                                transforms.Resize(opt.img_size),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize([0.5], [0.5])\n",
        "                                ])\n",
        "\n",
        "train_dataset = MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Configure data loader\n",
        "train_loader = DataLoader(train_dataset, batch_size=opt.batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=opt.batch_size, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435,
          "referenced_widgets": [
            "333fc5d119294ae0981234e87e7fa546",
            "ea5171526dd44f7da12a98a5f5b8219c",
            "191e15dc58324de78f56f797defb8ae2",
            "22fd99b64ecd4426991300130aab50dc",
            "2e569528380e4325a40580f56e430d88",
            "caf79f20bd3e421d8d0ddb69e4ee3608",
            "c4de0089ce6f4d64a91b8244177ea3db",
            "fdb9373b6e6f4a5b85cdc577a8dfa0f6",
            "f1bd5c041d5b4cd2a51f033519f42814",
            "08ec6437c8b748518becb60bd37a0bb1",
            "c4a30915bf77441597d875d9db264587",
            "4a9a96b5a21c4a19b3f34ec7b9657f97",
            "af89c263e3f74d4fa00ea525bd78535a",
            "833385b8e62545aabaced72244b71f98",
            "4c29379e57a244a49a5673817d29a2da",
            "6f39663a247f49bfa93ca8ecc90eebfc",
            "0dbb41be9b11455aa5468655681e5fdd",
            "02da38ad5388405ba3b43fc30b9bf25b",
            "1f71a1a7f8744362b865755182ebf69e",
            "1350fa925c8e48fe8bf78c7ebc5d0492",
            "91673475d8fc48a7850f4f7be80c3080",
            "6f73ee9bf167443e8012720b791fa14b",
            "c2cd76a8d20e423b9701e0692483c68d",
            "b6f582d56a4f42d0a953f160b1037907",
            "cd09c1f08e1743afbae5ed1fd8726ef8",
            "a0b325ac2cfe441e87841d76d762b2c1",
            "2073b31d870c4387a1f49879e85e020a",
            "f14332c135a54cbd93a2052a276beeb3",
            "cd6f5bf440e24637840cfaf9be3bc03e",
            "f1dab29c78ea4dc79b359aa6acca4778",
            "3a58ee7afa1e41c98d89bb4576ad0eff",
            "d2f864c499654328a3310397a5e82600",
            "ec1f546cc32340538b425854ac171fc3",
            "1c62c97c7ef84accba0933a50c71c943",
            "504eaea69ebe46f1af6ad085aa3ca993",
            "d9782cfad5c54efbaf850ad63615a951",
            "edc26b75d55c4199abcac1340d99e0fb",
            "3d33c8218248454497f96a9f396792c8",
            "a3546db13f8f4b2c83a1468e0f867d51",
            "7cc10fd547a246ba83c86eb8fc44e2b7",
            "bc9b74a4e33d4daaba87679d0ff23082",
            "ad8d375f073e4a14b93d21f0ebc1e0db",
            "c70d3db41abe41029f320ff434ef447c",
            "738a607082bb43699a2c7c706fe164aa"
          ]
        },
        "id": "yUryVOWBk-5H",
        "outputId": "def4cd12-0d0e-4044-b951-1267d3136d41"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "333fc5d119294ae0981234e87e7fa546",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/9912422 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a9a96b5a21c4a19b3f34ec7b9657f97",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/28881 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c2cd76a8d20e423b9701e0692483c68d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1648877 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c62c97c7ef84accba0933a50c71c943",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/4542 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = []\n",
        "for _, label in train_dataset:\n",
        "    train_labels.append(label)\n",
        "test_labels = []\n",
        "for _, label in test_dataset:\n",
        "    test_labels.append(label)\n",
        "\n",
        "count_train_freq = Counter(train_labels).items()\n",
        "count_train_freq = sorted(count_train_freq)\n",
        "count_train_freq = [x[1] for x in count_train_freq]\n",
        "count_train_prop = [x/(len(train_labels)) for x in count_train_freq]\n",
        "\n",
        "count_test_freq = Counter(test_labels).items()\n",
        "count_test_freq = sorted(count_test_freq)\n",
        "count_test_freq = [x[1] for x in count_test_freq]\n",
        "count_test_prop = [x/(len(test_labels)) for x in count_test_freq]"
      ],
      "metadata": {
        "id": "PAHv3_vXPb8q"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig1 = make_subplots(rows=1, cols=2)\n",
        "fig1.append_trace(go.Bar(name='Train Data', x=np.arange(10), y=count_train_freq, marker_color='rgb(33, 75, 99)'), 1, 1)\n",
        "fig1.append_trace(go.Bar(name='Test Data', x=np.arange(10), y=count_test_freq, marker_color='rgb(79, 129, 102)'), 1, 1)\n",
        "fig1.append_trace(go.Bar(name='Train Data', x=np.arange(10), y=count_train_prop, marker_color='rgb(33, 75, 99)'), 1, 2)\n",
        "fig1.append_trace(go.Bar(name='Test Data', x=np.arange(10), y=count_test_prop, marker_color='rgb(79, 129, 102)'), 1, 2)\n",
        "\n",
        "fig1.update_layout(\n",
        "    barmode='group',\n",
        "    width=1200,\n",
        "    height=500,\n",
        "    xaxis = dict(\n",
        "        tickmode = 'array',\n",
        "        tickvals = [x for x in range(10)],\n",
        "        ticktext = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "    )\n",
        ")\n",
        "fig1.show()"
      ],
      "metadata": {
        "id": "QvFQnYW1M3C4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CNN**"
      ],
      "metadata": {
        "id": "gTBEikxFvFa7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = edict()\n",
        "args.batch_size = 64\n",
        "args.test_batch_size = 1000\n",
        "args.epochs = 14\n",
        "args.lr = 1.0\n",
        "args.gamma = 0.7\n",
        "args.dry_run = False\n",
        "args.log_interval = 10\n",
        "args.save_model = False\n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
        "train_kwargs = {'batch_size': args.batch_size}\n",
        "test_kwargs = {'batch_size': args.test_batch_size}\n",
        "\n",
        "if cuda:\n",
        "    cuda_kwargs = {'num_workers': 1,\n",
        "                    'pin_memory': True,\n",
        "                    'shuffle': True}\n",
        "    train_kwargs.update(cuda_kwargs)\n",
        "    test_kwargs.update(cuda_kwargs)\n",
        "\n",
        "\n",
        "transform_ = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "train_dataset_ = MNIST('../data', train=True, download=True, transform=transform_)\n",
        "test_dataset_ = MNIST('../data', train=False, download=True, transform=transform_)\n",
        "\n",
        "train_loader_ = torch.utils.data.DataLoader(train_dataset_, **train_kwargs)\n",
        "test_loader_ = torch.utils.data.DataLoader(test_dataset_, **test_kwargs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435,
          "referenced_widgets": [
            "42cbe151ca2c4b5c813646f3fb26e6fc",
            "329ee380b2cc431db0e01c85099f7fdf",
            "8b88673145f144c3ae424dd592f8bab1",
            "8b6db8d1cc084264809a5132312ad4d2",
            "f5d5b652635a446b887e586b9c0b9078",
            "7cc36dd5df654108a525d2340d5880c2",
            "d66b701cf8b34a60ab6eb2bab056e7e1",
            "922fa7c1a9a249ca8f202e1f87a51a93",
            "ef70d76a2be94d6cb639706669a3542d",
            "659ea88393a14dd19975ae60c3757bee",
            "d3627d7a164644aa972053e68f3aae2f",
            "8c94c269ad4848e5831eaadd588d0089",
            "0cf134d555c949318dd69c7958dc3852",
            "1b515d557025496597e6945c78fcad4e",
            "ea2c9473806e49cfaa54f27b2deabf57",
            "827b32c404ce423889448dcc9c33fd6c",
            "a1ef3a89ac1d421bab6419c1e172a471",
            "3b341790b1db40f18659ddf336fc22ec",
            "d450b455f70b472d97d5f91877de0d41",
            "3bd643dad5b04e2aa4f174379883995d",
            "b27527cfb48944afbb4984020b1ce314",
            "4b6e353c8cc64451ad4c50b1301cbd56",
            "ce2056a050e74ad185a609e8985f7d4b",
            "efeccfea3ebe4c41a33beb3e929948be",
            "dd3153f229d44354b8541ffb1a69495d",
            "40e5512c5f3d4a4daf507b6722cbf8dd",
            "22e245acb46042a1aed07ef9b5d6466b",
            "aa932f104d264627a2a1dbade0bc5b52",
            "5317d83580d74e5e89061c05ef1afc62",
            "bdccbe889b584b9ab4c3b1f59450f822",
            "1a3fc536af7840cf9bb8c7197ccb545c",
            "218e8334e8ab41dea6694f7b3776b826",
            "261e0ee31dd34bcf9555efd7bfb0b1b7",
            "256a793c63fe4bd396c36a87ba458cff",
            "d0d0ee7f44c8489f8b30343743344d9a",
            "8c728c07b66146b59bd14629edfd13ce",
            "1552f877ca1b4af894e7dda8ff8f8ef0",
            "046871d9dc5d4d738ccc9eb8ebf82e8f",
            "f8b28765edd74090a95b250605d5772d",
            "2f78ad22404c4c2da64e3519e3913734",
            "ae70b7ff3f2b41428ddca7f66c3d6515",
            "4e3c1911bec44946a324f2c45cf1396f",
            "801c006f673f48c58c82a84f1545c08a",
            "dda768e6780f4ffbb169e54859fc7778"
          ]
        },
        "id": "BJT2_V1oGlF3",
        "outputId": "3b3fcb27-0095-4173-b66c-178a8e190b40"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42cbe151ca2c4b5c813646f3fb26e6fc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/9912422 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c94c269ad4848e5831eaadd588d0089",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/28881 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce2056a050e74ad185a609e8985f7d4b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1648877 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "256a793c63fe4bd396c36a87ba458cff",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/4542 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1)\n",
        "    self.dropout1 = nn.Dropout(0.25)\n",
        "    self.dropout2 = nn.Dropout(0.5)\n",
        "    self.fc1 = nn.Linear(in_features=9216, out_features=128)\n",
        "    self.fc2 = nn.Linear(in_features=128, out_features=10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.conv2(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.max_pool2d(x, 2)\n",
        "    x = self.dropout1(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.dropout2(x)\n",
        "    x = self.fc2(x)\n",
        "    output = F.log_softmax(x, dim=1)\n",
        "    return output"
      ],
      "metadata": {
        "id": "UnCZjnxxvKig"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(args, model, device, train_loader, optimizer, epoch):\n",
        "  model.train()\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    loss = F.nll_loss(output, target)\n",
        "    loss.backward(retain_graph=True)\n",
        "    optimizer.step()\n",
        "    if batch_idx % args.log_interval == 0:\n",
        "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "          epoch, batch_idx * len(data), len(train_loader),\n",
        "          100. * batch_idx / len(train_loader), loss.item()))\n",
        "      if args.dry_run:\n",
        "        break\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      output = model(data)\n",
        "      test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "      pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "      correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "\n",
        "  print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "      test_loss, correct, len(test_loader.dataset),\n",
        "      100. * correct / len(test_loader.dataset)))"
      ],
      "metadata": {
        "id": "NYOP-__HKUts"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weights_init_noise(m):\n",
        "  classname = m.__class__.__name__\n",
        "  if classname.find(\"Conv\") != -1:\n",
        "      torch.nn.init.normal_(m.weight.data, 0.0, 1.0)\n",
        "  elif classname.find(\"BatchNorm2d\") != -1:\n",
        "      torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "      torch.nn.init.constant_(m.bias.data, 0.0)"
      ],
      "metadata": {
        "id": "Jn2CKKD2oiyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net().to(device)\n",
        "optimizer = torch.optim.Adadelta(model.parameters(), lr=args.lr)\n",
        "#model.apply(weights_init_noise)\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    train(args, model, device, train_loader_, optimizer, epoch)\n",
        "    test(model, device, test_loader_)\n",
        "    scheduler.step()\n",
        "\n",
        "if args.save_model:\n",
        "    torch.save(model.state_dict(), \"mnist_cnn.pt\")"
      ],
      "metadata": {
        "id": "Ek7Wosu6xxWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_images(loader, batch_id, how_many):\n",
        "  for batch_idx, (image, label) in enumerate(loader):\n",
        "    if batch_idx == batch_id:\n",
        "      actual_label = label[:how_many].numpy()      \n",
        "      plt.figure(figsize=(15,10))\n",
        "      plt.subplot(1,2,2)\n",
        "      plt.axis(\"off\")\n",
        "      plt.imshow(np.transpose(make_grid(image[:how_many]),(1,2,0)))\n",
        "      plt.show()\n",
        "      \n",
        "      image = image.to(device)\n",
        "      print(f\"Actual labels: {actual_label}\")\n",
        "      prediction = model(image[:how_many,:,:,:])\n",
        "      pred = prediction.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "      print(f\"Predcited labels: {pred.squeeze(-1).cpu().numpy()}\")\n",
        "      correct = pred.eq(torch.from_numpy(actual_label).to(device).view_as(pred)).sum().item()\n",
        "      print(f\"Number of correct classes: {correct}\")\n",
        "      break\n",
        "\n",
        "check_images(test_loader_, 0, 8)"
      ],
      "metadata": {
        "id": "xjz1Lc5D9dHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_accuracy(my_model):\n",
        "  test_labels = []\n",
        "  test_pred = []\n",
        "  total = 0\n",
        "  for batch_idx, (image, label) in enumerate(test_loader_):\n",
        "    test_labels += label.tolist()\n",
        "    image = image.to(device)\n",
        "    prediction = my_model(image)\n",
        "    pred = prediction.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "    test_pred += pred.squeeze(-1).tolist()\n",
        "    correct = pred.eq(label.to(device).view_as(pred)).sum().item()\n",
        "    total += correct\n",
        "  return test_labels, test_pred, total"
      ],
      "metadata": {
        "id": "ml48JaroYHu5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **GAN**"
      ],
      "metadata": {
        "id": "zqndvQFcQwpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find(\"Conv\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find(\"BatchNorm2d\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        torch.nn.init.constant_(m.bias.data, 0.0)"
      ],
      "metadata": {
        "id": "GdrV4mszkf7O"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class cGenerator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(cGenerator, self).__init__()\n",
        "        \n",
        "        self.label_embedding = nn.Embedding(10, 10)\n",
        "        self.init_size = opt.img_size // 4\n",
        "        self.l1 = nn.Sequential(nn.Linear(opt.latent_dim + 10, 128 * self.init_size ** 2)) # 110 -> 8192\n",
        "\n",
        "        self.conv_blocks = nn.Sequential(\n",
        "            \n",
        "            #state size 128, 8, 8\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            \n",
        "            #state size 128, 16, 16\n",
        "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),           \n",
        "            nn.Upsample(scale_factor=2),\n",
        "            \n",
        "            #state size 128, 32, 32\n",
        "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            #state size 64, 32, 32\n",
        "            nn.Conv2d(64, opt.channels, 3, stride=1, padding=1),\n",
        "\n",
        "            #state size 1, 32, 32\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, z, labels):\n",
        "        z = torch.cat((self.label_embedding(labels), z), -1) #110\n",
        "        out = self.l1(z)  # B -> 110 to 110 -> 8192 = B -> 8192\n",
        "        out = out.view(out.shape[0], 128, self.init_size, self.init_size) # [B, 128, 8, 8]\n",
        "        img = self.conv_blocks(out)\n",
        "        return img"
      ],
      "metadata": {
        "id": "ryAB6pXH0vE9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.init_size = opt.img_size // 4\n",
        "        self.l1 = nn.Sequential(nn.Linear(opt.latent_dim, 128 * self.init_size ** 2)) # 100 -> 8192\n",
        "\n",
        "        self.conv_blocks = nn.Sequential(\n",
        "            \n",
        "            #state size 128, 8, 8\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            \n",
        "            #state size 128, 16, 16\n",
        "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),           \n",
        "            nn.Upsample(scale_factor=2),\n",
        "            \n",
        "            #state size 128, 32, 32\n",
        "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            #state size 64, 32, 32\n",
        "            nn.Conv2d(64, opt.channels, 3, stride=1, padding=1),\n",
        "\n",
        "            #state size 1, 32, 32\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        out = self.l1(z)  # 32 -> 100 to 100 -> 8192 = 32 -> 8192\n",
        "        out = out.view(out.shape[0], 128, self.init_size, self.init_size) # [32, 128, 8, 8]\n",
        "        img = self.conv_blocks(out)\n",
        "        return img"
      ],
      "metadata": {
        "id": "uSCVGgVske6p"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class cDiscriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(cDiscriminator, self).__init__()\n",
        "\n",
        "        def discriminator_block(in_filters, out_filters, bn=True):\n",
        "          block = [nn.Conv2d(in_channels=in_filters, out_channels=out_filters, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "                   nn.LeakyReLU(0.2, inplace=True),\n",
        "                   nn.Dropout2d(0.25)]\n",
        "          if bn:\n",
        "            block = [nn.Conv2d(in_channels=in_filters, out_channels=out_filters, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "                     nn.BatchNorm2d(out_filters, 0.8),\n",
        "                     nn.LeakyReLU(0.2, inplace=True),\n",
        "                     nn.Dropout2d(0.25)]\n",
        "          return block\n",
        "        \n",
        "        self.label_embedding = nn.Embedding(10, 10)\n",
        "        self.linear = nn.Linear(10 + opt.img_size**2, opt.img_size**2)\n",
        "        self.model = nn.Sequential(\n",
        "            *discriminator_block(opt.channels, 16, bn=False),\n",
        "            *discriminator_block(16, 32),\n",
        "            *discriminator_block(32, 64),\n",
        "            *discriminator_block(64, 128),\n",
        "        )\n",
        "\n",
        "        # The height and width of downsampled image\n",
        "        ds_size = opt.img_size // 2 ** 4\n",
        "        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1), nn.Sigmoid())\n",
        "\n",
        "    def forward(self, img, labels):\n",
        "\n",
        "        img = torch.cat((img.view(img.size(0), -1), self.label_embedding(labels)), -1) # B,1*32*32 + B,10 = B,1034\n",
        "        img = self.linear(img)  # B, 1034 -> B, 1024\n",
        "        img = img.view(img.shape[0], opt.channels, opt.img_size, opt.img_size) # [B, 1, 32, 32]\n",
        "        out = self.model(img)\n",
        "        out = out.view(out.shape[0], -1)\n",
        "        validity = self.adv_layer(out)\n",
        "\n",
        "        return validity"
      ],
      "metadata": {
        "id": "jlMDSiF242V_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        def discriminator_block(in_filters, out_filters, bn=True):\n",
        "            block = [nn.Conv2d(in_channels=in_filters, out_channels=out_filters, kernel_size=4, stride=2, padding=1, bias=False), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n",
        "            if bn:\n",
        "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
        "            return block\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *discriminator_block(opt.channels, 16, bn=False),\n",
        "            *discriminator_block(16, 32),\n",
        "            *discriminator_block(32, 64),\n",
        "            *discriminator_block(64, 128),\n",
        "        )\n",
        "\n",
        "        # The height and width of downsampled image\n",
        "        ds_size = opt.img_size // 2 ** 4\n",
        "        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1), nn.Sigmoid())\n",
        "\n",
        "    def forward(self, img):\n",
        "        out = self.model(img)\n",
        "        out = out.view(out.shape[0], -1)\n",
        "        validity = self.adv_layer(out)\n",
        "\n",
        "        return validity"
      ],
      "metadata": {
        "id": "63S2Mu2Nki5t"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function\n",
        "adversarial_loss = torch.nn.BCELoss()\n",
        "\n",
        "# Initialize generator and discriminator\n",
        "generator = cGenerator()\n",
        "discriminator = cDiscriminator()\n",
        "\n",
        "if cuda:\n",
        "    generator.cuda()\n",
        "    discriminator.cuda()\n",
        "    adversarial_loss.cuda()\n",
        "\n",
        "# Initialize weights\n",
        "generator.apply(weights_init_normal)\n",
        "discriminator.apply(weights_init_normal)"
      ],
      "metadata": {
        "id": "1Ztk1cK1kwhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "\n",
        "FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
        "LongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor\n",
        "\n",
        "fixed_noise = Variable(FloatTensor(np.random.normal(0, 1, (1, opt.latent_dim))))\n",
        "fixed_label = Variable(LongTensor(np.random.randint(0, 10, 1)))"
      ],
      "metadata": {
        "id": "cGBdzug8k3Wp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------\n",
        "#  Training CGAN\n",
        "# ----------\n",
        "\n",
        "# Lists to keep track of progress\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "iters = 0\n",
        "\n",
        "for epoch in range(opt.n_epochs):\n",
        "    for i, (imgs, labels) in enumerate(train_loader):\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = Variable(FloatTensor(imgs.shape[0], 1).fill_(1.0), requires_grad=False)\n",
        "        fake = Variable(FloatTensor(imgs.shape[0], 1).fill_(0.0), requires_grad=False)\n",
        "\n",
        "        # Configure input\n",
        "        real_imgs = Variable(imgs.type(FloatTensor))\n",
        "        labels = Variable(labels.type(LongTensor))\n",
        "\n",
        "        # -----------------\n",
        "        #  Train Generator\n",
        "        # -----------------\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # Sample noise as generator input\n",
        "        z = Variable(FloatTensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim))))   # torch.Size([32, 100]\n",
        "        g_labels = Variable(LongTensor(np.random.randint(0, 10, imgs.shape[0])))\n",
        "\n",
        "        # Generate a batch of images\n",
        "        gen_imgs = generator(z, g_labels)\n",
        "\n",
        "        # Loss measures generator's ability to fool the discriminator\n",
        "        g_loss = adversarial_loss(discriminator(gen_imgs, g_labels), valid)\n",
        "\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # Measure discriminator's ability to classify real from generated samples\n",
        "        real_loss = adversarial_loss(discriminator(real_imgs, labels), valid)\n",
        "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach(), g_labels), fake)\n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "\n",
        "\n",
        "        # Output training stats\n",
        "        if i % 50 == 0:\n",
        "             print(\n",
        "              \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
        "              % (epoch, opt.n_epochs, i, len(train_loader), d_loss.item(), g_loss.item())\n",
        "              )\n",
        "\n",
        "        # Save Losses for plotting later\n",
        "        G_losses.append(g_loss.item())\n",
        "        D_losses.append(d_loss.item())\n",
        "\n",
        "        # Check how the generator is doing by saving G's output on fixed_noise\n",
        "        if (iters % 500 == 0) or ((epoch == opt.n_epochs-1) and (i == len(train_loader)-1)):\n",
        "            with torch.no_grad():\n",
        "                fake = generator(fixed_noise, fixed_label).detach().cpu()\n",
        "            img_list.append(make_grid(fake, padding=2, normalize=True)) #stored on every 500 epoch\n",
        "\n",
        "        iters += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1u2LxAmA9KM",
        "outputId": "6643be42-e1bf-4e64-d7e2-b54cdecc9f9d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 0/200] [Batch 0/469] [D loss: 0.693366] [G loss: 0.712816]\n",
            "[Epoch 0/200] [Batch 50/469] [D loss: 0.693103] [G loss: 0.676938]\n",
            "[Epoch 0/200] [Batch 100/469] [D loss: 0.684823] [G loss: 0.738325]\n",
            "[Epoch 0/200] [Batch 150/469] [D loss: 0.600452] [G loss: 0.829896]\n",
            "[Epoch 0/200] [Batch 200/469] [D loss: 0.657614] [G loss: 0.819600]\n",
            "[Epoch 0/200] [Batch 250/469] [D loss: 0.701446] [G loss: 0.694155]\n",
            "[Epoch 0/200] [Batch 300/469] [D loss: 0.648880] [G loss: 0.684781]\n",
            "[Epoch 0/200] [Batch 350/469] [D loss: 0.691532] [G loss: 0.687252]\n",
            "[Epoch 0/200] [Batch 400/469] [D loss: 0.685381] [G loss: 0.737905]\n",
            "[Epoch 0/200] [Batch 450/469] [D loss: 0.618637] [G loss: 0.661690]\n",
            "[Epoch 1/200] [Batch 0/469] [D loss: 0.680881] [G loss: 0.832762]\n",
            "[Epoch 1/200] [Batch 50/469] [D loss: 0.700295] [G loss: 0.685603]\n",
            "[Epoch 1/200] [Batch 100/469] [D loss: 0.627259] [G loss: 0.776577]\n",
            "[Epoch 1/200] [Batch 150/469] [D loss: 0.692603] [G loss: 0.711816]\n",
            "[Epoch 1/200] [Batch 200/469] [D loss: 0.668509] [G loss: 0.765521]\n",
            "[Epoch 1/200] [Batch 250/469] [D loss: 0.716177] [G loss: 0.645965]\n",
            "[Epoch 1/200] [Batch 300/469] [D loss: 0.666282] [G loss: 0.679335]\n",
            "[Epoch 1/200] [Batch 350/469] [D loss: 0.598591] [G loss: 1.024961]\n",
            "[Epoch 1/200] [Batch 400/469] [D loss: 0.690489] [G loss: 0.976252]\n",
            "[Epoch 1/200] [Batch 450/469] [D loss: 0.525254] [G loss: 0.933354]\n",
            "[Epoch 2/200] [Batch 0/469] [D loss: 0.560184] [G loss: 0.914418]\n",
            "[Epoch 2/200] [Batch 50/469] [D loss: 0.519620] [G loss: 0.514151]\n",
            "[Epoch 2/200] [Batch 100/469] [D loss: 0.397336] [G loss: 1.311526]\n",
            "[Epoch 2/200] [Batch 150/469] [D loss: 0.622095] [G loss: 0.855069]\n",
            "[Epoch 2/200] [Batch 200/469] [D loss: 0.435809] [G loss: 0.732650]\n",
            "[Epoch 2/200] [Batch 250/469] [D loss: 0.436835] [G loss: 1.912648]\n",
            "[Epoch 2/200] [Batch 300/469] [D loss: 0.598405] [G loss: 0.587344]\n",
            "[Epoch 2/200] [Batch 350/469] [D loss: 0.606723] [G loss: 1.960450]\n",
            "[Epoch 2/200] [Batch 400/469] [D loss: 0.409016] [G loss: 0.761141]\n",
            "[Epoch 2/200] [Batch 450/469] [D loss: 0.574387] [G loss: 1.669623]\n",
            "[Epoch 3/200] [Batch 0/469] [D loss: 0.343041] [G loss: 1.589354]\n",
            "[Epoch 3/200] [Batch 50/469] [D loss: 0.456864] [G loss: 0.623901]\n",
            "[Epoch 3/200] [Batch 100/469] [D loss: 0.300050] [G loss: 1.860292]\n",
            "[Epoch 3/200] [Batch 150/469] [D loss: 0.286175] [G loss: 1.032911]\n",
            "[Epoch 3/200] [Batch 200/469] [D loss: 0.438688] [G loss: 1.050245]\n",
            "[Epoch 3/200] [Batch 250/469] [D loss: 0.503029] [G loss: 1.535462]\n",
            "[Epoch 3/200] [Batch 300/469] [D loss: 0.667724] [G loss: 1.548597]\n",
            "[Epoch 3/200] [Batch 350/469] [D loss: 0.300931] [G loss: 0.990217]\n",
            "[Epoch 3/200] [Batch 400/469] [D loss: 0.400347] [G loss: 2.175495]\n",
            "[Epoch 3/200] [Batch 450/469] [D loss: 0.340866] [G loss: 0.956072]\n",
            "[Epoch 4/200] [Batch 0/469] [D loss: 0.303876] [G loss: 1.611900]\n",
            "[Epoch 4/200] [Batch 50/469] [D loss: 0.569909] [G loss: 0.516000]\n",
            "[Epoch 4/200] [Batch 100/469] [D loss: 0.435088] [G loss: 1.380945]\n",
            "[Epoch 4/200] [Batch 150/469] [D loss: 0.747973] [G loss: 0.575321]\n",
            "[Epoch 4/200] [Batch 200/469] [D loss: 0.480504] [G loss: 0.777417]\n",
            "[Epoch 4/200] [Batch 250/469] [D loss: 0.356882] [G loss: 1.180033]\n",
            "[Epoch 4/200] [Batch 300/469] [D loss: 0.513341] [G loss: 2.203941]\n",
            "[Epoch 4/200] [Batch 350/469] [D loss: 0.578888] [G loss: 0.780292]\n",
            "[Epoch 4/200] [Batch 400/469] [D loss: 0.473091] [G loss: 1.104007]\n",
            "[Epoch 4/200] [Batch 450/469] [D loss: 0.583041] [G loss: 2.443837]\n",
            "[Epoch 5/200] [Batch 0/469] [D loss: 0.460171] [G loss: 1.086257]\n",
            "[Epoch 5/200] [Batch 50/469] [D loss: 0.587352] [G loss: 0.698825]\n",
            "[Epoch 5/200] [Batch 100/469] [D loss: 1.144821] [G loss: 1.885454]\n",
            "[Epoch 5/200] [Batch 150/469] [D loss: 0.828062] [G loss: 0.514523]\n",
            "[Epoch 5/200] [Batch 200/469] [D loss: 0.733911] [G loss: 0.981063]\n",
            "[Epoch 5/200] [Batch 250/469] [D loss: 0.437306] [G loss: 1.230010]\n",
            "[Epoch 5/200] [Batch 300/469] [D loss: 0.832074] [G loss: 0.923846]\n",
            "[Epoch 5/200] [Batch 350/469] [D loss: 0.846051] [G loss: 1.025062]\n",
            "[Epoch 5/200] [Batch 400/469] [D loss: 0.363156] [G loss: 1.122132]\n",
            "[Epoch 5/200] [Batch 450/469] [D loss: 0.534440] [G loss: 1.126898]\n",
            "[Epoch 6/200] [Batch 0/469] [D loss: 0.744786] [G loss: 0.975464]\n",
            "[Epoch 6/200] [Batch 50/469] [D loss: 0.509326] [G loss: 1.616430]\n",
            "[Epoch 6/200] [Batch 100/469] [D loss: 0.487084] [G loss: 0.958187]\n",
            "[Epoch 6/200] [Batch 150/469] [D loss: 0.514471] [G loss: 1.119163]\n",
            "[Epoch 6/200] [Batch 200/469] [D loss: 0.629141] [G loss: 0.987760]\n",
            "[Epoch 6/200] [Batch 250/469] [D loss: 0.744981] [G loss: 2.049414]\n",
            "[Epoch 6/200] [Batch 300/469] [D loss: 0.754990] [G loss: 1.913133]\n",
            "[Epoch 6/200] [Batch 350/469] [D loss: 0.716702] [G loss: 1.091320]\n",
            "[Epoch 6/200] [Batch 400/469] [D loss: 0.763524] [G loss: 0.871758]\n",
            "[Epoch 6/200] [Batch 450/469] [D loss: 0.486114] [G loss: 0.944578]\n",
            "[Epoch 7/200] [Batch 0/469] [D loss: 0.592352] [G loss: 1.208509]\n",
            "[Epoch 7/200] [Batch 50/469] [D loss: 0.539863] [G loss: 0.492103]\n",
            "[Epoch 7/200] [Batch 100/469] [D loss: 0.675201] [G loss: 0.380348]\n",
            "[Epoch 7/200] [Batch 150/469] [D loss: 0.496970] [G loss: 1.065286]\n",
            "[Epoch 7/200] [Batch 200/469] [D loss: 0.673648] [G loss: 0.804720]\n",
            "[Epoch 7/200] [Batch 250/469] [D loss: 0.726380] [G loss: 0.640402]\n",
            "[Epoch 7/200] [Batch 300/469] [D loss: 0.602187] [G loss: 0.423739]\n",
            "[Epoch 7/200] [Batch 350/469] [D loss: 0.892708] [G loss: 0.888151]\n",
            "[Epoch 7/200] [Batch 400/469] [D loss: 0.434063] [G loss: 1.185145]\n",
            "[Epoch 7/200] [Batch 450/469] [D loss: 0.770770] [G loss: 0.380872]\n",
            "[Epoch 8/200] [Batch 0/469] [D loss: 0.515791] [G loss: 0.749952]\n",
            "[Epoch 8/200] [Batch 50/469] [D loss: 0.511729] [G loss: 1.414555]\n",
            "[Epoch 8/200] [Batch 100/469] [D loss: 0.658355] [G loss: 0.463127]\n",
            "[Epoch 8/200] [Batch 150/469] [D loss: 0.702372] [G loss: 0.664816]\n",
            "[Epoch 8/200] [Batch 200/469] [D loss: 0.460998] [G loss: 0.700939]\n",
            "[Epoch 8/200] [Batch 250/469] [D loss: 0.635699] [G loss: 0.679424]\n",
            "[Epoch 8/200] [Batch 300/469] [D loss: 0.430573] [G loss: 1.439734]\n",
            "[Epoch 8/200] [Batch 350/469] [D loss: 0.758833] [G loss: 0.470452]\n",
            "[Epoch 8/200] [Batch 400/469] [D loss: 0.299230] [G loss: 1.306878]\n",
            "[Epoch 8/200] [Batch 450/469] [D loss: 0.298321] [G loss: 1.514677]\n",
            "[Epoch 9/200] [Batch 0/469] [D loss: 0.585142] [G loss: 0.750674]\n",
            "[Epoch 9/200] [Batch 50/469] [D loss: 0.612536] [G loss: 1.425131]\n",
            "[Epoch 9/200] [Batch 100/469] [D loss: 0.547078] [G loss: 1.265430]\n",
            "[Epoch 9/200] [Batch 150/469] [D loss: 0.426764] [G loss: 0.913142]\n",
            "[Epoch 9/200] [Batch 200/469] [D loss: 0.548451] [G loss: 0.837575]\n",
            "[Epoch 9/200] [Batch 250/469] [D loss: 0.519508] [G loss: 0.733742]\n",
            "[Epoch 9/200] [Batch 300/469] [D loss: 0.563071] [G loss: 1.459637]\n",
            "[Epoch 9/200] [Batch 350/469] [D loss: 0.322418] [G loss: 1.479892]\n",
            "[Epoch 9/200] [Batch 400/469] [D loss: 0.567621] [G loss: 0.586847]\n",
            "[Epoch 9/200] [Batch 450/469] [D loss: 0.312797] [G loss: 1.146917]\n",
            "[Epoch 10/200] [Batch 0/469] [D loss: 0.669890] [G loss: 0.358550]\n",
            "[Epoch 10/200] [Batch 50/469] [D loss: 0.610979] [G loss: 1.035431]\n",
            "[Epoch 10/200] [Batch 100/469] [D loss: 0.408243] [G loss: 1.272600]\n",
            "[Epoch 10/200] [Batch 150/469] [D loss: 0.454376] [G loss: 1.179073]\n",
            "[Epoch 10/200] [Batch 200/469] [D loss: 0.948544] [G loss: 0.470414]\n",
            "[Epoch 10/200] [Batch 250/469] [D loss: 0.580900] [G loss: 1.080897]\n",
            "[Epoch 10/200] [Batch 300/469] [D loss: 0.645278] [G loss: 0.492955]\n",
            "[Epoch 10/200] [Batch 350/469] [D loss: 0.658026] [G loss: 1.311087]\n",
            "[Epoch 10/200] [Batch 400/469] [D loss: 0.274594] [G loss: 1.327540]\n",
            "[Epoch 10/200] [Batch 450/469] [D loss: 0.495047] [G loss: 1.453335]\n",
            "[Epoch 11/200] [Batch 0/469] [D loss: 0.587756] [G loss: 1.122271]\n",
            "[Epoch 11/200] [Batch 50/469] [D loss: 0.564817] [G loss: 0.771003]\n",
            "[Epoch 11/200] [Batch 100/469] [D loss: 0.379475] [G loss: 1.358540]\n",
            "[Epoch 11/200] [Batch 150/469] [D loss: 0.506474] [G loss: 1.864012]\n",
            "[Epoch 11/200] [Batch 200/469] [D loss: 0.390139] [G loss: 1.560657]\n",
            "[Epoch 11/200] [Batch 250/469] [D loss: 0.295360] [G loss: 1.429773]\n",
            "[Epoch 11/200] [Batch 300/469] [D loss: 0.819030] [G loss: 1.828930]\n",
            "[Epoch 11/200] [Batch 350/469] [D loss: 0.367321] [G loss: 1.187106]\n",
            "[Epoch 11/200] [Batch 400/469] [D loss: 0.499090] [G loss: 0.658711]\n",
            "[Epoch 11/200] [Batch 450/469] [D loss: 0.515954] [G loss: 0.933183]\n",
            "[Epoch 12/200] [Batch 0/469] [D loss: 0.501366] [G loss: 0.956552]\n",
            "[Epoch 12/200] [Batch 50/469] [D loss: 0.393086] [G loss: 0.854034]\n",
            "[Epoch 12/200] [Batch 100/469] [D loss: 0.666775] [G loss: 1.415495]\n",
            "[Epoch 12/200] [Batch 150/469] [D loss: 0.323827] [G loss: 0.821805]\n",
            "[Epoch 12/200] [Batch 200/469] [D loss: 0.353828] [G loss: 1.937577]\n",
            "[Epoch 12/200] [Batch 250/469] [D loss: 0.490175] [G loss: 1.475047]\n",
            "[Epoch 12/200] [Batch 300/469] [D loss: 0.387166] [G loss: 0.609264]\n",
            "[Epoch 12/200] [Batch 350/469] [D loss: 0.525394] [G loss: 0.425137]\n",
            "[Epoch 12/200] [Batch 400/469] [D loss: 0.593552] [G loss: 1.753185]\n",
            "[Epoch 12/200] [Batch 450/469] [D loss: 0.803871] [G loss: 0.705294]\n",
            "[Epoch 13/200] [Batch 0/469] [D loss: 0.397507] [G loss: 1.098548]\n",
            "[Epoch 13/200] [Batch 50/469] [D loss: 0.601013] [G loss: 0.817426]\n",
            "[Epoch 13/200] [Batch 100/469] [D loss: 0.530248] [G loss: 0.546956]\n",
            "[Epoch 13/200] [Batch 150/469] [D loss: 0.416013] [G loss: 0.578960]\n",
            "[Epoch 13/200] [Batch 200/469] [D loss: 0.289209] [G loss: 1.545352]\n",
            "[Epoch 13/200] [Batch 250/469] [D loss: 0.681142] [G loss: 0.248153]\n",
            "[Epoch 13/200] [Batch 300/469] [D loss: 0.909899] [G loss: 0.239972]\n",
            "[Epoch 13/200] [Batch 350/469] [D loss: 0.497988] [G loss: 2.233216]\n",
            "[Epoch 13/200] [Batch 400/469] [D loss: 0.291588] [G loss: 1.795578]\n",
            "[Epoch 13/200] [Batch 450/469] [D loss: 0.784479] [G loss: 0.463076]\n",
            "[Epoch 14/200] [Batch 0/469] [D loss: 0.506241] [G loss: 1.037077]\n",
            "[Epoch 14/200] [Batch 50/469] [D loss: 0.503256] [G loss: 1.007421]\n",
            "[Epoch 14/200] [Batch 100/469] [D loss: 0.783810] [G loss: 1.248650]\n",
            "[Epoch 14/200] [Batch 150/469] [D loss: 0.319476] [G loss: 0.708521]\n",
            "[Epoch 14/200] [Batch 200/469] [D loss: 0.341553] [G loss: 0.686174]\n",
            "[Epoch 14/200] [Batch 250/469] [D loss: 0.773491] [G loss: 0.663198]\n",
            "[Epoch 14/200] [Batch 300/469] [D loss: 0.424669] [G loss: 1.327114]\n",
            "[Epoch 14/200] [Batch 350/469] [D loss: 0.635089] [G loss: 0.290311]\n",
            "[Epoch 14/200] [Batch 400/469] [D loss: 0.388895] [G loss: 1.971814]\n",
            "[Epoch 14/200] [Batch 450/469] [D loss: 0.479928] [G loss: 0.834713]\n",
            "[Epoch 15/200] [Batch 0/469] [D loss: 0.491259] [G loss: 1.982885]\n",
            "[Epoch 15/200] [Batch 50/469] [D loss: 1.046240] [G loss: 1.535873]\n",
            "[Epoch 15/200] [Batch 100/469] [D loss: 0.884378] [G loss: 1.781558]\n",
            "[Epoch 15/200] [Batch 150/469] [D loss: 0.386774] [G loss: 1.062152]\n",
            "[Epoch 15/200] [Batch 200/469] [D loss: 0.286165] [G loss: 0.754762]\n",
            "[Epoch 15/200] [Batch 250/469] [D loss: 0.422558] [G loss: 1.711418]\n",
            "[Epoch 15/200] [Batch 300/469] [D loss: 0.851317] [G loss: 0.395809]\n",
            "[Epoch 15/200] [Batch 350/469] [D loss: 0.707376] [G loss: 1.435058]\n",
            "[Epoch 15/200] [Batch 400/469] [D loss: 0.598075] [G loss: 1.122958]\n",
            "[Epoch 15/200] [Batch 450/469] [D loss: 0.495284] [G loss: 1.635393]\n",
            "[Epoch 16/200] [Batch 0/469] [D loss: 0.342319] [G loss: 0.961278]\n",
            "[Epoch 16/200] [Batch 50/469] [D loss: 0.619300] [G loss: 0.369678]\n",
            "[Epoch 16/200] [Batch 100/469] [D loss: 0.917228] [G loss: 0.549491]\n",
            "[Epoch 16/200] [Batch 150/469] [D loss: 0.439701] [G loss: 0.461117]\n",
            "[Epoch 16/200] [Batch 200/469] [D loss: 0.705362] [G loss: 0.497904]\n",
            "[Epoch 16/200] [Batch 250/469] [D loss: 0.565837] [G loss: 0.471249]\n",
            "[Epoch 16/200] [Batch 300/469] [D loss: 0.456732] [G loss: 1.483854]\n",
            "[Epoch 16/200] [Batch 350/469] [D loss: 0.505728] [G loss: 1.100880]\n",
            "[Epoch 16/200] [Batch 400/469] [D loss: 0.720079] [G loss: 0.112055]\n",
            "[Epoch 16/200] [Batch 450/469] [D loss: 0.939682] [G loss: 0.202547]\n",
            "[Epoch 17/200] [Batch 0/469] [D loss: 0.619821] [G loss: 0.966369]\n",
            "[Epoch 17/200] [Batch 50/469] [D loss: 0.464762] [G loss: 1.794435]\n",
            "[Epoch 17/200] [Batch 100/469] [D loss: 0.845930] [G loss: 0.720597]\n",
            "[Epoch 17/200] [Batch 150/469] [D loss: 0.540009] [G loss: 0.739390]\n",
            "[Epoch 17/200] [Batch 200/469] [D loss: 0.762859] [G loss: 2.606940]\n",
            "[Epoch 17/200] [Batch 250/469] [D loss: 0.736348] [G loss: 0.479598]\n",
            "[Epoch 17/200] [Batch 300/469] [D loss: 0.664878] [G loss: 0.954728]\n",
            "[Epoch 17/200] [Batch 350/469] [D loss: 0.639675] [G loss: 0.875551]\n",
            "[Epoch 17/200] [Batch 400/469] [D loss: 0.483046] [G loss: 0.633735]\n",
            "[Epoch 17/200] [Batch 450/469] [D loss: 0.897048] [G loss: 0.199252]\n",
            "[Epoch 18/200] [Batch 0/469] [D loss: 0.390353] [G loss: 0.873995]\n",
            "[Epoch 18/200] [Batch 50/469] [D loss: 0.922278] [G loss: 0.181172]\n",
            "[Epoch 18/200] [Batch 100/469] [D loss: 0.849032] [G loss: 1.475958]\n",
            "[Epoch 18/200] [Batch 150/469] [D loss: 0.401003] [G loss: 0.998886]\n",
            "[Epoch 18/200] [Batch 200/469] [D loss: 0.735990] [G loss: 0.319943]\n",
            "[Epoch 18/200] [Batch 250/469] [D loss: 0.428615] [G loss: 1.014146]\n",
            "[Epoch 18/200] [Batch 300/469] [D loss: 0.341483] [G loss: 0.858936]\n",
            "[Epoch 18/200] [Batch 350/469] [D loss: 0.673052] [G loss: 0.561294]\n",
            "[Epoch 18/200] [Batch 400/469] [D loss: 0.693403] [G loss: 0.860195]\n",
            "[Epoch 18/200] [Batch 450/469] [D loss: 0.323423] [G loss: 0.836246]\n",
            "[Epoch 19/200] [Batch 0/469] [D loss: 0.376151] [G loss: 1.791357]\n",
            "[Epoch 19/200] [Batch 50/469] [D loss: 0.633603] [G loss: 1.588432]\n",
            "[Epoch 19/200] [Batch 100/469] [D loss: 0.360385] [G loss: 0.897547]\n",
            "[Epoch 19/200] [Batch 150/469] [D loss: 0.444737] [G loss: 2.337080]\n",
            "[Epoch 19/200] [Batch 200/469] [D loss: 0.854946] [G loss: 0.926771]\n",
            "[Epoch 19/200] [Batch 250/469] [D loss: 0.450697] [G loss: 1.611317]\n",
            "[Epoch 19/200] [Batch 300/469] [D loss: 0.839721] [G loss: 0.386155]\n",
            "[Epoch 19/200] [Batch 350/469] [D loss: 0.399133] [G loss: 0.879488]\n",
            "[Epoch 19/200] [Batch 400/469] [D loss: 0.299053] [G loss: 1.192074]\n",
            "[Epoch 19/200] [Batch 450/469] [D loss: 0.394122] [G loss: 0.772750]\n",
            "[Epoch 20/200] [Batch 0/469] [D loss: 0.465773] [G loss: 2.057081]\n",
            "[Epoch 20/200] [Batch 50/469] [D loss: 0.477812] [G loss: 1.249063]\n",
            "[Epoch 20/200] [Batch 100/469] [D loss: 0.483377] [G loss: 0.590776]\n",
            "[Epoch 20/200] [Batch 150/469] [D loss: 0.856702] [G loss: 0.150413]\n",
            "[Epoch 20/200] [Batch 200/469] [D loss: 0.348969] [G loss: 0.975505]\n",
            "[Epoch 20/200] [Batch 250/469] [D loss: 0.983789] [G loss: 0.332379]\n",
            "[Epoch 20/200] [Batch 300/469] [D loss: 0.461105] [G loss: 0.779308]\n",
            "[Epoch 20/200] [Batch 350/469] [D loss: 0.638917] [G loss: 0.557056]\n",
            "[Epoch 20/200] [Batch 400/469] [D loss: 0.425056] [G loss: 1.100919]\n",
            "[Epoch 20/200] [Batch 450/469] [D loss: 0.338522] [G loss: 0.484237]\n",
            "[Epoch 21/200] [Batch 0/469] [D loss: 0.498083] [G loss: 0.396621]\n",
            "[Epoch 21/200] [Batch 50/469] [D loss: 0.685225] [G loss: 1.636300]\n",
            "[Epoch 21/200] [Batch 100/469] [D loss: 0.789733] [G loss: 0.427795]\n",
            "[Epoch 21/200] [Batch 150/469] [D loss: 1.249244] [G loss: 0.171209]\n",
            "[Epoch 21/200] [Batch 200/469] [D loss: 0.527535] [G loss: 0.412151]\n",
            "[Epoch 21/200] [Batch 250/469] [D loss: 0.380064] [G loss: 1.195593]\n",
            "[Epoch 21/200] [Batch 300/469] [D loss: 0.551015] [G loss: 0.996731]\n",
            "[Epoch 21/200] [Batch 350/469] [D loss: 0.329551] [G loss: 1.603348]\n",
            "[Epoch 21/200] [Batch 400/469] [D loss: 0.394743] [G loss: 0.757752]\n",
            "[Epoch 21/200] [Batch 450/469] [D loss: 0.528140] [G loss: 0.602116]\n",
            "[Epoch 22/200] [Batch 0/469] [D loss: 0.429858] [G loss: 1.215624]\n",
            "[Epoch 22/200] [Batch 50/469] [D loss: 0.553910] [G loss: 0.768484]\n",
            "[Epoch 22/200] [Batch 100/469] [D loss: 0.828928] [G loss: 1.672558]\n",
            "[Epoch 22/200] [Batch 150/469] [D loss: 0.776460] [G loss: 1.198756]\n",
            "[Epoch 22/200] [Batch 200/469] [D loss: 0.501039] [G loss: 0.953899]\n",
            "[Epoch 22/200] [Batch 250/469] [D loss: 0.749208] [G loss: 0.659923]\n",
            "[Epoch 22/200] [Batch 300/469] [D loss: 1.018795] [G loss: 0.693935]\n",
            "[Epoch 22/200] [Batch 350/469] [D loss: 0.402742] [G loss: 0.520575]\n",
            "[Epoch 22/200] [Batch 400/469] [D loss: 0.800568] [G loss: 1.013894]\n",
            "[Epoch 22/200] [Batch 450/469] [D loss: 0.467733] [G loss: 2.372708]\n",
            "[Epoch 23/200] [Batch 0/469] [D loss: 0.427881] [G loss: 2.234424]\n",
            "[Epoch 23/200] [Batch 50/469] [D loss: 0.451985] [G loss: 2.074918]\n",
            "[Epoch 23/200] [Batch 100/469] [D loss: 0.243916] [G loss: 0.546046]\n",
            "[Epoch 23/200] [Batch 150/469] [D loss: 0.334528] [G loss: 2.150372]\n",
            "[Epoch 23/200] [Batch 200/469] [D loss: 0.448243] [G loss: 0.672226]\n",
            "[Epoch 23/200] [Batch 250/469] [D loss: 0.438974] [G loss: 1.585551]\n",
            "[Epoch 23/200] [Batch 300/469] [D loss: 0.383798] [G loss: 0.299315]\n",
            "[Epoch 23/200] [Batch 350/469] [D loss: 1.076604] [G loss: 0.684468]\n",
            "[Epoch 23/200] [Batch 400/469] [D loss: 0.823444] [G loss: 0.950054]\n",
            "[Epoch 23/200] [Batch 450/469] [D loss: 0.655104] [G loss: 0.689399]\n",
            "[Epoch 24/200] [Batch 0/469] [D loss: 0.955819] [G loss: 0.502126]\n",
            "[Epoch 24/200] [Batch 50/469] [D loss: 0.821152] [G loss: 0.567376]\n",
            "[Epoch 24/200] [Batch 100/469] [D loss: 0.925966] [G loss: 0.196766]\n",
            "[Epoch 24/200] [Batch 150/469] [D loss: 0.292341] [G loss: 2.341868]\n",
            "[Epoch 24/200] [Batch 200/469] [D loss: 0.412770] [G loss: 1.242040]\n",
            "[Epoch 24/200] [Batch 250/469] [D loss: 0.779082] [G loss: 0.120684]\n",
            "[Epoch 24/200] [Batch 300/469] [D loss: 0.599792] [G loss: 0.467955]\n",
            "[Epoch 24/200] [Batch 350/469] [D loss: 0.334929] [G loss: 1.120853]\n",
            "[Epoch 24/200] [Batch 400/469] [D loss: 0.645462] [G loss: 1.690794]\n",
            "[Epoch 24/200] [Batch 450/469] [D loss: 0.313890] [G loss: 0.979094]\n",
            "[Epoch 25/200] [Batch 0/469] [D loss: 0.960385] [G loss: 2.379415]\n",
            "[Epoch 25/200] [Batch 50/469] [D loss: 0.360503] [G loss: 2.142989]\n",
            "[Epoch 25/200] [Batch 100/469] [D loss: 0.620649] [G loss: 0.439997]\n",
            "[Epoch 25/200] [Batch 150/469] [D loss: 0.852979] [G loss: 0.185586]\n",
            "[Epoch 25/200] [Batch 200/469] [D loss: 0.444166] [G loss: 0.903574]\n",
            "[Epoch 25/200] [Batch 250/469] [D loss: 0.542647] [G loss: 0.610303]\n",
            "[Epoch 25/200] [Batch 300/469] [D loss: 1.179896] [G loss: 0.253914]\n",
            "[Epoch 25/200] [Batch 350/469] [D loss: 0.580460] [G loss: 1.583213]\n",
            "[Epoch 25/200] [Batch 400/469] [D loss: 0.310121] [G loss: 1.164509]\n",
            "[Epoch 25/200] [Batch 450/469] [D loss: 0.490540] [G loss: 0.670733]\n",
            "[Epoch 26/200] [Batch 0/469] [D loss: 0.700651] [G loss: 1.154466]\n",
            "[Epoch 26/200] [Batch 50/469] [D loss: 0.396829] [G loss: 1.929137]\n",
            "[Epoch 26/200] [Batch 100/469] [D loss: 0.825951] [G loss: 0.512196]\n",
            "[Epoch 26/200] [Batch 150/469] [D loss: 0.833036] [G loss: 1.245544]\n",
            "[Epoch 26/200] [Batch 200/469] [D loss: 0.488172] [G loss: 0.479277]\n",
            "[Epoch 26/200] [Batch 250/469] [D loss: 0.766662] [G loss: 0.437725]\n",
            "[Epoch 26/200] [Batch 300/469] [D loss: 0.370862] [G loss: 1.175500]\n",
            "[Epoch 26/200] [Batch 350/469] [D loss: 0.523897] [G loss: 0.633371]\n",
            "[Epoch 26/200] [Batch 400/469] [D loss: 0.568262] [G loss: 0.622831]\n",
            "[Epoch 26/200] [Batch 450/469] [D loss: 0.878903] [G loss: 0.211995]\n",
            "[Epoch 27/200] [Batch 0/469] [D loss: 0.607132] [G loss: 0.737535]\n",
            "[Epoch 27/200] [Batch 50/469] [D loss: 0.465725] [G loss: 0.898420]\n",
            "[Epoch 27/200] [Batch 100/469] [D loss: 0.546327] [G loss: 1.110984]\n",
            "[Epoch 27/200] [Batch 150/469] [D loss: 0.597616] [G loss: 0.554562]\n",
            "[Epoch 27/200] [Batch 200/469] [D loss: 0.618129] [G loss: 0.906456]\n",
            "[Epoch 27/200] [Batch 250/469] [D loss: 0.765866] [G loss: 0.477505]\n",
            "[Epoch 27/200] [Batch 300/469] [D loss: 0.320084] [G loss: 0.804664]\n",
            "[Epoch 27/200] [Batch 350/469] [D loss: 0.647264] [G loss: 0.885994]\n",
            "[Epoch 27/200] [Batch 400/469] [D loss: 0.524009] [G loss: 0.459368]\n",
            "[Epoch 27/200] [Batch 450/469] [D loss: 0.589483] [G loss: 1.666723]\n",
            "[Epoch 28/200] [Batch 0/469] [D loss: 0.287999] [G loss: 2.237726]\n",
            "[Epoch 28/200] [Batch 50/469] [D loss: 0.560039] [G loss: 1.430662]\n",
            "[Epoch 28/200] [Batch 100/469] [D loss: 0.525526] [G loss: 0.680564]\n",
            "[Epoch 28/200] [Batch 150/469] [D loss: 0.721635] [G loss: 0.213672]\n",
            "[Epoch 28/200] [Batch 200/469] [D loss: 0.803874] [G loss: 1.422349]\n",
            "[Epoch 28/200] [Batch 250/469] [D loss: 0.490284] [G loss: 1.041954]\n",
            "[Epoch 28/200] [Batch 300/469] [D loss: 0.653691] [G loss: 1.017774]\n",
            "[Epoch 28/200] [Batch 350/469] [D loss: 0.984681] [G loss: 1.345334]\n",
            "[Epoch 28/200] [Batch 400/469] [D loss: 0.901856] [G loss: 0.885842]\n",
            "[Epoch 28/200] [Batch 450/469] [D loss: 0.621916] [G loss: 1.142981]\n",
            "[Epoch 29/200] [Batch 0/469] [D loss: 0.585560] [G loss: 1.941591]\n",
            "[Epoch 29/200] [Batch 50/469] [D loss: 0.335314] [G loss: 0.620346]\n",
            "[Epoch 29/200] [Batch 100/469] [D loss: 0.356227] [G loss: 0.785759]\n",
            "[Epoch 29/200] [Batch 150/469] [D loss: 0.360920] [G loss: 2.116443]\n",
            "[Epoch 29/200] [Batch 200/469] [D loss: 0.487674] [G loss: 0.637675]\n",
            "[Epoch 29/200] [Batch 250/469] [D loss: 0.726271] [G loss: 0.654051]\n",
            "[Epoch 29/200] [Batch 300/469] [D loss: 0.577514] [G loss: 1.167998]\n",
            "[Epoch 29/200] [Batch 350/469] [D loss: 0.534717] [G loss: 1.415588]\n",
            "[Epoch 29/200] [Batch 400/469] [D loss: 0.506373] [G loss: 1.041749]\n",
            "[Epoch 29/200] [Batch 450/469] [D loss: 0.396566] [G loss: 1.316801]\n",
            "[Epoch 30/200] [Batch 0/469] [D loss: 0.593657] [G loss: 0.615011]\n",
            "[Epoch 30/200] [Batch 50/469] [D loss: 0.686278] [G loss: 0.402040]\n",
            "[Epoch 30/200] [Batch 100/469] [D loss: 0.531749] [G loss: 0.321621]\n",
            "[Epoch 30/200] [Batch 150/469] [D loss: 0.315544] [G loss: 1.842830]\n",
            "[Epoch 30/200] [Batch 200/469] [D loss: 0.662147] [G loss: 0.754421]\n",
            "[Epoch 30/200] [Batch 250/469] [D loss: 0.234900] [G loss: 2.011930]\n",
            "[Epoch 30/200] [Batch 300/469] [D loss: 0.764331] [G loss: 1.538209]\n",
            "[Epoch 30/200] [Batch 350/469] [D loss: 0.640169] [G loss: 0.850116]\n",
            "[Epoch 30/200] [Batch 400/469] [D loss: 0.811409] [G loss: 0.224441]\n",
            "[Epoch 30/200] [Batch 450/469] [D loss: 0.530645] [G loss: 0.956314]\n",
            "[Epoch 31/200] [Batch 0/469] [D loss: 0.714844] [G loss: 2.466819]\n",
            "[Epoch 31/200] [Batch 50/469] [D loss: 0.889308] [G loss: 0.492158]\n",
            "[Epoch 31/200] [Batch 100/469] [D loss: 0.581834] [G loss: 1.350763]\n",
            "[Epoch 31/200] [Batch 150/469] [D loss: 0.406830] [G loss: 1.658063]\n",
            "[Epoch 31/200] [Batch 200/469] [D loss: 0.575526] [G loss: 1.511977]\n",
            "[Epoch 31/200] [Batch 250/469] [D loss: 0.384454] [G loss: 1.017424]\n",
            "[Epoch 31/200] [Batch 300/469] [D loss: 0.790106] [G loss: 1.735700]\n",
            "[Epoch 31/200] [Batch 350/469] [D loss: 0.976827] [G loss: 0.956581]\n",
            "[Epoch 31/200] [Batch 400/469] [D loss: 0.307361] [G loss: 0.948337]\n",
            "[Epoch 31/200] [Batch 450/469] [D loss: 0.543726] [G loss: 0.992828]\n",
            "[Epoch 32/200] [Batch 0/469] [D loss: 0.564665] [G loss: 1.416395]\n",
            "[Epoch 32/200] [Batch 50/469] [D loss: 0.251877] [G loss: 1.310249]\n",
            "[Epoch 32/200] [Batch 100/469] [D loss: 0.150259] [G loss: 1.416161]\n",
            "[Epoch 32/200] [Batch 150/469] [D loss: 0.813542] [G loss: 0.853900]\n",
            "[Epoch 32/200] [Batch 200/469] [D loss: 0.755185] [G loss: 0.802289]\n",
            "[Epoch 32/200] [Batch 250/469] [D loss: 0.468414] [G loss: 1.017235]\n",
            "[Epoch 32/200] [Batch 300/469] [D loss: 0.848463] [G loss: 0.695880]\n",
            "[Epoch 32/200] [Batch 350/469] [D loss: 0.698216] [G loss: 0.232936]\n",
            "[Epoch 32/200] [Batch 400/469] [D loss: 0.737557] [G loss: 1.058889]\n",
            "[Epoch 32/200] [Batch 450/469] [D loss: 0.409124] [G loss: 2.005131]\n",
            "[Epoch 33/200] [Batch 0/469] [D loss: 0.995074] [G loss: 1.292740]\n",
            "[Epoch 33/200] [Batch 50/469] [D loss: 0.539492] [G loss: 0.298211]\n",
            "[Epoch 33/200] [Batch 100/469] [D loss: 0.411456] [G loss: 1.250567]\n",
            "[Epoch 33/200] [Batch 150/469] [D loss: 0.352512] [G loss: 0.805631]\n",
            "[Epoch 33/200] [Batch 200/469] [D loss: 0.314400] [G loss: 1.728106]\n",
            "[Epoch 33/200] [Batch 250/469] [D loss: 0.742276] [G loss: 1.226007]\n",
            "[Epoch 33/200] [Batch 300/469] [D loss: 0.451889] [G loss: 0.977980]\n",
            "[Epoch 33/200] [Batch 350/469] [D loss: 1.002872] [G loss: 0.960312]\n",
            "[Epoch 33/200] [Batch 400/469] [D loss: 0.566354] [G loss: 1.114449]\n",
            "[Epoch 33/200] [Batch 450/469] [D loss: 0.330674] [G loss: 2.450679]\n",
            "[Epoch 34/200] [Batch 0/469] [D loss: 0.217768] [G loss: 1.293509]\n",
            "[Epoch 34/200] [Batch 50/469] [D loss: 0.373290] [G loss: 1.522934]\n",
            "[Epoch 34/200] [Batch 100/469] [D loss: 0.547305] [G loss: 0.701044]\n",
            "[Epoch 34/200] [Batch 150/469] [D loss: 0.589598] [G loss: 0.767163]\n",
            "[Epoch 34/200] [Batch 200/469] [D loss: 0.933360] [G loss: 1.352837]\n",
            "[Epoch 34/200] [Batch 250/469] [D loss: 0.584770] [G loss: 1.273563]\n",
            "[Epoch 34/200] [Batch 300/469] [D loss: 0.682576] [G loss: 0.968832]\n",
            "[Epoch 34/200] [Batch 350/469] [D loss: 0.278295] [G loss: 1.512624]\n",
            "[Epoch 34/200] [Batch 400/469] [D loss: 1.127981] [G loss: 1.486898]\n",
            "[Epoch 34/200] [Batch 450/469] [D loss: 0.505651] [G loss: 0.568044]\n",
            "[Epoch 35/200] [Batch 0/469] [D loss: 0.583116] [G loss: 0.639984]\n",
            "[Epoch 35/200] [Batch 50/469] [D loss: 0.874214] [G loss: 1.751500]\n",
            "[Epoch 35/200] [Batch 100/469] [D loss: 0.532378] [G loss: 0.850277]\n",
            "[Epoch 35/200] [Batch 150/469] [D loss: 0.777250] [G loss: 0.603914]\n",
            "[Epoch 35/200] [Batch 200/469] [D loss: 0.723400] [G loss: 0.723013]\n",
            "[Epoch 35/200] [Batch 250/469] [D loss: 0.314995] [G loss: 1.895751]\n",
            "[Epoch 35/200] [Batch 300/469] [D loss: 0.432254] [G loss: 1.502386]\n",
            "[Epoch 35/200] [Batch 350/469] [D loss: 0.358121] [G loss: 1.047129]\n",
            "[Epoch 35/200] [Batch 400/469] [D loss: 0.574496] [G loss: 1.960424]\n",
            "[Epoch 35/200] [Batch 450/469] [D loss: 0.733328] [G loss: 0.643374]\n",
            "[Epoch 36/200] [Batch 0/469] [D loss: 0.384140] [G loss: 0.609623]\n",
            "[Epoch 36/200] [Batch 50/469] [D loss: 0.589568] [G loss: 0.574068]\n",
            "[Epoch 36/200] [Batch 100/469] [D loss: 0.161997] [G loss: 1.753478]\n",
            "[Epoch 36/200] [Batch 150/469] [D loss: 0.708933] [G loss: 0.847957]\n",
            "[Epoch 36/200] [Batch 200/469] [D loss: 0.715665] [G loss: 0.860206]\n",
            "[Epoch 36/200] [Batch 250/469] [D loss: 0.630980] [G loss: 0.359536]\n",
            "[Epoch 36/200] [Batch 300/469] [D loss: 0.236464] [G loss: 0.973040]\n",
            "[Epoch 36/200] [Batch 350/469] [D loss: 0.491687] [G loss: 1.313487]\n",
            "[Epoch 36/200] [Batch 400/469] [D loss: 0.556256] [G loss: 1.978424]\n",
            "[Epoch 36/200] [Batch 450/469] [D loss: 0.653650] [G loss: 0.463509]\n",
            "[Epoch 37/200] [Batch 0/469] [D loss: 0.861013] [G loss: 0.382510]\n",
            "[Epoch 37/200] [Batch 50/469] [D loss: 0.664843] [G loss: 1.627048]\n",
            "[Epoch 37/200] [Batch 100/469] [D loss: 0.520351] [G loss: 0.925524]\n",
            "[Epoch 37/200] [Batch 150/469] [D loss: 0.432525] [G loss: 0.717491]\n",
            "[Epoch 37/200] [Batch 200/469] [D loss: 0.436545] [G loss: 1.349067]\n",
            "[Epoch 37/200] [Batch 250/469] [D loss: 0.990265] [G loss: 0.738744]\n",
            "[Epoch 37/200] [Batch 300/469] [D loss: 0.381044] [G loss: 1.056066]\n",
            "[Epoch 37/200] [Batch 350/469] [D loss: 0.369582] [G loss: 1.182635]\n",
            "[Epoch 37/200] [Batch 400/469] [D loss: 0.301003] [G loss: 0.792335]\n",
            "[Epoch 37/200] [Batch 450/469] [D loss: 0.566639] [G loss: 0.418789]\n",
            "[Epoch 38/200] [Batch 0/469] [D loss: 0.841128] [G loss: 0.999452]\n",
            "[Epoch 38/200] [Batch 50/469] [D loss: 0.325692] [G loss: 1.557653]\n",
            "[Epoch 38/200] [Batch 100/469] [D loss: 0.845713] [G loss: 1.772153]\n",
            "[Epoch 38/200] [Batch 150/469] [D loss: 0.276181] [G loss: 1.604701]\n",
            "[Epoch 38/200] [Batch 200/469] [D loss: 0.380540] [G loss: 0.544083]\n",
            "[Epoch 38/200] [Batch 250/469] [D loss: 0.386083] [G loss: 1.425119]\n",
            "[Epoch 38/200] [Batch 300/469] [D loss: 0.353077] [G loss: 2.267248]\n",
            "[Epoch 38/200] [Batch 350/469] [D loss: 0.212601] [G loss: 1.888212]\n",
            "[Epoch 38/200] [Batch 400/469] [D loss: 0.876871] [G loss: 0.292850]\n",
            "[Epoch 38/200] [Batch 450/469] [D loss: 0.286794] [G loss: 0.800746]\n",
            "[Epoch 39/200] [Batch 0/469] [D loss: 0.088807] [G loss: 2.264912]\n",
            "[Epoch 39/200] [Batch 50/469] [D loss: 1.356359] [G loss: 2.019719]\n",
            "[Epoch 39/200] [Batch 100/469] [D loss: 0.568447] [G loss: 0.415463]\n",
            "[Epoch 39/200] [Batch 150/469] [D loss: 0.660443] [G loss: 1.341753]\n",
            "[Epoch 39/200] [Batch 200/469] [D loss: 0.555084] [G loss: 1.669306]\n",
            "[Epoch 39/200] [Batch 250/469] [D loss: 0.763619] [G loss: 1.920451]\n",
            "[Epoch 39/200] [Batch 300/469] [D loss: 1.124354] [G loss: 0.193080]\n",
            "[Epoch 39/200] [Batch 350/469] [D loss: 0.337628] [G loss: 1.890809]\n",
            "[Epoch 39/200] [Batch 400/469] [D loss: 0.230290] [G loss: 1.007696]\n",
            "[Epoch 39/200] [Batch 450/469] [D loss: 0.364907] [G loss: 1.675170]\n",
            "[Epoch 40/200] [Batch 0/469] [D loss: 0.299654] [G loss: 1.147897]\n",
            "[Epoch 40/200] [Batch 50/469] [D loss: 0.478846] [G loss: 1.612188]\n",
            "[Epoch 40/200] [Batch 100/469] [D loss: 0.680246] [G loss: 0.492137]\n",
            "[Epoch 40/200] [Batch 150/469] [D loss: 0.685412] [G loss: 0.933546]\n",
            "[Epoch 40/200] [Batch 200/469] [D loss: 0.775963] [G loss: 0.887529]\n",
            "[Epoch 40/200] [Batch 250/469] [D loss: 0.507663] [G loss: 1.069713]\n",
            "[Epoch 40/200] [Batch 300/469] [D loss: 0.819990] [G loss: 1.184348]\n",
            "[Epoch 40/200] [Batch 350/469] [D loss: 0.626735] [G loss: 1.652089]\n",
            "[Epoch 40/200] [Batch 400/469] [D loss: 0.900899] [G loss: 1.285698]\n",
            "[Epoch 40/200] [Batch 450/469] [D loss: 0.473985] [G loss: 0.858797]\n",
            "[Epoch 41/200] [Batch 0/469] [D loss: 0.289906] [G loss: 0.873573]\n",
            "[Epoch 41/200] [Batch 50/469] [D loss: 0.940773] [G loss: 1.858391]\n",
            "[Epoch 41/200] [Batch 100/469] [D loss: 0.528882] [G loss: 0.490735]\n",
            "[Epoch 41/200] [Batch 150/469] [D loss: 0.359544] [G loss: 1.536381]\n",
            "[Epoch 41/200] [Batch 200/469] [D loss: 0.404060] [G loss: 1.122306]\n",
            "[Epoch 41/200] [Batch 250/469] [D loss: 0.535679] [G loss: 2.473236]\n",
            "[Epoch 41/200] [Batch 300/469] [D loss: 0.882854] [G loss: 2.511453]\n",
            "[Epoch 41/200] [Batch 350/469] [D loss: 0.346264] [G loss: 2.058352]\n",
            "[Epoch 41/200] [Batch 400/469] [D loss: 0.841420] [G loss: 0.315808]\n",
            "[Epoch 41/200] [Batch 450/469] [D loss: 0.474418] [G loss: 0.565027]\n",
            "[Epoch 42/200] [Batch 0/469] [D loss: 0.675042] [G loss: 0.167308]\n",
            "[Epoch 42/200] [Batch 50/469] [D loss: 0.533875] [G loss: 1.042576]\n",
            "[Epoch 42/200] [Batch 100/469] [D loss: 0.611666] [G loss: 1.174772]\n",
            "[Epoch 42/200] [Batch 150/469] [D loss: 1.052923] [G loss: 0.210492]\n",
            "[Epoch 42/200] [Batch 200/469] [D loss: 0.411337] [G loss: 1.898261]\n",
            "[Epoch 42/200] [Batch 250/469] [D loss: 0.431053] [G loss: 2.667849]\n",
            "[Epoch 42/200] [Batch 300/469] [D loss: 0.905144] [G loss: 0.414112]\n",
            "[Epoch 42/200] [Batch 350/469] [D loss: 0.539193] [G loss: 1.337886]\n",
            "[Epoch 42/200] [Batch 400/469] [D loss: 0.567242] [G loss: 1.122228]\n",
            "[Epoch 42/200] [Batch 450/469] [D loss: 0.685472] [G loss: 1.497312]\n",
            "[Epoch 43/200] [Batch 0/469] [D loss: 0.343931] [G loss: 1.397397]\n",
            "[Epoch 43/200] [Batch 50/469] [D loss: 0.712568] [G loss: 2.003887]\n",
            "[Epoch 43/200] [Batch 100/469] [D loss: 0.376494] [G loss: 1.018166]\n",
            "[Epoch 43/200] [Batch 150/469] [D loss: 0.596084] [G loss: 0.442389]\n",
            "[Epoch 43/200] [Batch 200/469] [D loss: 0.311846] [G loss: 1.721868]\n",
            "[Epoch 43/200] [Batch 250/469] [D loss: 0.346180] [G loss: 0.592943]\n",
            "[Epoch 43/200] [Batch 300/469] [D loss: 0.807046] [G loss: 0.733286]\n",
            "[Epoch 43/200] [Batch 350/469] [D loss: 0.339920] [G loss: 0.422225]\n",
            "[Epoch 43/200] [Batch 400/469] [D loss: 0.332457] [G loss: 1.070050]\n",
            "[Epoch 43/200] [Batch 450/469] [D loss: 0.852945] [G loss: 0.295439]\n",
            "[Epoch 44/200] [Batch 0/469] [D loss: 0.531076] [G loss: 1.074506]\n",
            "[Epoch 44/200] [Batch 50/469] [D loss: 0.522443] [G loss: 1.888164]\n",
            "[Epoch 44/200] [Batch 100/469] [D loss: 0.499063] [G loss: 0.906621]\n",
            "[Epoch 44/200] [Batch 150/469] [D loss: 0.766874] [G loss: 0.451150]\n",
            "[Epoch 44/200] [Batch 200/469] [D loss: 0.496292] [G loss: 2.647800]\n",
            "[Epoch 44/200] [Batch 250/469] [D loss: 0.652825] [G loss: 1.112968]\n",
            "[Epoch 44/200] [Batch 300/469] [D loss: 0.810727] [G loss: 0.248851]\n",
            "[Epoch 44/200] [Batch 350/469] [D loss: 0.615067] [G loss: 0.939399]\n",
            "[Epoch 44/200] [Batch 400/469] [D loss: 0.854515] [G loss: 0.647378]\n",
            "[Epoch 44/200] [Batch 450/469] [D loss: 0.313914] [G loss: 1.857350]\n",
            "[Epoch 45/200] [Batch 0/469] [D loss: 0.772197] [G loss: 1.381059]\n",
            "[Epoch 45/200] [Batch 50/469] [D loss: 0.632135] [G loss: 0.635829]\n",
            "[Epoch 45/200] [Batch 100/469] [D loss: 0.238992] [G loss: 1.397038]\n",
            "[Epoch 45/200] [Batch 150/469] [D loss: 0.426300] [G loss: 0.910331]\n",
            "[Epoch 45/200] [Batch 200/469] [D loss: 0.613394] [G loss: 0.516711]\n",
            "[Epoch 45/200] [Batch 250/469] [D loss: 0.426440] [G loss: 1.421985]\n",
            "[Epoch 45/200] [Batch 300/469] [D loss: 0.622618] [G loss: 1.402570]\n",
            "[Epoch 45/200] [Batch 350/469] [D loss: 0.564640] [G loss: 1.013990]\n",
            "[Epoch 45/200] [Batch 400/469] [D loss: 0.387465] [G loss: 1.364010]\n",
            "[Epoch 45/200] [Batch 450/469] [D loss: 0.791512] [G loss: 0.399743]\n",
            "[Epoch 46/200] [Batch 0/469] [D loss: 0.378082] [G loss: 1.133250]\n",
            "[Epoch 46/200] [Batch 50/469] [D loss: 0.967685] [G loss: 0.281496]\n",
            "[Epoch 46/200] [Batch 100/469] [D loss: 0.719435] [G loss: 0.877561]\n",
            "[Epoch 46/200] [Batch 150/469] [D loss: 0.445388] [G loss: 1.302585]\n",
            "[Epoch 46/200] [Batch 200/469] [D loss: 0.391591] [G loss: 1.461189]\n",
            "[Epoch 46/200] [Batch 250/469] [D loss: 0.435125] [G loss: 0.854148]\n",
            "[Epoch 46/200] [Batch 300/469] [D loss: 0.511492] [G loss: 0.932818]\n",
            "[Epoch 46/200] [Batch 350/469] [D loss: 0.265330] [G loss: 0.854532]\n",
            "[Epoch 46/200] [Batch 400/469] [D loss: 0.469384] [G loss: 0.238286]\n",
            "[Epoch 46/200] [Batch 450/469] [D loss: 0.486399] [G loss: 0.649618]\n",
            "[Epoch 47/200] [Batch 0/469] [D loss: 0.716586] [G loss: 1.117925]\n",
            "[Epoch 47/200] [Batch 50/469] [D loss: 0.532138] [G loss: 0.869725]\n",
            "[Epoch 47/200] [Batch 100/469] [D loss: 0.663320] [G loss: 1.139555]\n",
            "[Epoch 47/200] [Batch 150/469] [D loss: 0.397643] [G loss: 1.842615]\n",
            "[Epoch 47/200] [Batch 200/469] [D loss: 0.572684] [G loss: 1.166729]\n",
            "[Epoch 47/200] [Batch 250/469] [D loss: 0.438180] [G loss: 1.087186]\n",
            "[Epoch 47/200] [Batch 300/469] [D loss: 0.539205] [G loss: 1.981418]\n",
            "[Epoch 47/200] [Batch 350/469] [D loss: 0.382141] [G loss: 2.602580]\n",
            "[Epoch 47/200] [Batch 400/469] [D loss: 0.762496] [G loss: 1.071831]\n",
            "[Epoch 47/200] [Batch 450/469] [D loss: 0.382297] [G loss: 1.285786]\n",
            "[Epoch 48/200] [Batch 0/469] [D loss: 0.764366] [G loss: 1.105098]\n",
            "[Epoch 48/200] [Batch 50/469] [D loss: 0.491449] [G loss: 1.393157]\n",
            "[Epoch 48/200] [Batch 100/469] [D loss: 0.306260] [G loss: 0.395987]\n",
            "[Epoch 48/200] [Batch 150/469] [D loss: 0.890853] [G loss: 0.415271]\n",
            "[Epoch 48/200] [Batch 200/469] [D loss: 0.616615] [G loss: 0.649239]\n",
            "[Epoch 48/200] [Batch 250/469] [D loss: 0.806584] [G loss: 0.806936]\n",
            "[Epoch 48/200] [Batch 300/469] [D loss: 0.504900] [G loss: 0.976376]\n",
            "[Epoch 48/200] [Batch 350/469] [D loss: 0.409608] [G loss: 0.578459]\n",
            "[Epoch 48/200] [Batch 400/469] [D loss: 0.872505] [G loss: 0.642520]\n",
            "[Epoch 48/200] [Batch 450/469] [D loss: 0.549094] [G loss: 0.463733]\n",
            "[Epoch 49/200] [Batch 0/469] [D loss: 0.370867] [G loss: 0.490508]\n",
            "[Epoch 49/200] [Batch 50/469] [D loss: 0.208322] [G loss: 1.644179]\n",
            "[Epoch 49/200] [Batch 100/469] [D loss: 0.572002] [G loss: 1.840552]\n",
            "[Epoch 49/200] [Batch 150/469] [D loss: 0.539928] [G loss: 0.503134]\n",
            "[Epoch 49/200] [Batch 200/469] [D loss: 0.319821] [G loss: 1.346053]\n",
            "[Epoch 49/200] [Batch 250/469] [D loss: 0.261203] [G loss: 2.586070]\n",
            "[Epoch 49/200] [Batch 300/469] [D loss: 0.812707] [G loss: 0.213595]\n",
            "[Epoch 49/200] [Batch 350/469] [D loss: 0.757100] [G loss: 0.936102]\n",
            "[Epoch 49/200] [Batch 400/469] [D loss: 0.381102] [G loss: 1.710636]\n",
            "[Epoch 49/200] [Batch 450/469] [D loss: 1.114993] [G loss: 0.327155]\n",
            "[Epoch 50/200] [Batch 0/469] [D loss: 0.313242] [G loss: 1.492755]\n",
            "[Epoch 50/200] [Batch 50/469] [D loss: 0.421620] [G loss: 1.025924]\n",
            "[Epoch 50/200] [Batch 100/469] [D loss: 0.449952] [G loss: 0.893647]\n",
            "[Epoch 50/200] [Batch 150/469] [D loss: 0.836158] [G loss: 0.894297]\n",
            "[Epoch 50/200] [Batch 200/469] [D loss: 0.292867] [G loss: 2.806528]\n",
            "[Epoch 50/200] [Batch 250/469] [D loss: 0.960447] [G loss: 1.663868]\n",
            "[Epoch 50/200] [Batch 300/469] [D loss: 0.379071] [G loss: 1.211442]\n",
            "[Epoch 50/200] [Batch 350/469] [D loss: 0.777837] [G loss: 2.402490]\n",
            "[Epoch 50/200] [Batch 400/469] [D loss: 0.634680] [G loss: 3.057382]\n",
            "[Epoch 50/200] [Batch 450/469] [D loss: 0.163466] [G loss: 1.750443]\n",
            "[Epoch 51/200] [Batch 0/469] [D loss: 0.776851] [G loss: 2.001230]\n",
            "[Epoch 51/200] [Batch 50/469] [D loss: 0.627391] [G loss: 0.458117]\n",
            "[Epoch 51/200] [Batch 100/469] [D loss: 0.686455] [G loss: 0.810548]\n",
            "[Epoch 51/200] [Batch 150/469] [D loss: 1.016509] [G loss: 1.266058]\n",
            "[Epoch 51/200] [Batch 200/469] [D loss: 0.209826] [G loss: 2.389408]\n",
            "[Epoch 51/200] [Batch 250/469] [D loss: 0.433715] [G loss: 1.060913]\n",
            "[Epoch 51/200] [Batch 300/469] [D loss: 0.501275] [G loss: 2.275510]\n",
            "[Epoch 51/200] [Batch 350/469] [D loss: 0.563292] [G loss: 2.198514]\n",
            "[Epoch 51/200] [Batch 400/469] [D loss: 0.589991] [G loss: 0.492178]\n",
            "[Epoch 51/200] [Batch 450/469] [D loss: 0.513436] [G loss: 2.535691]\n",
            "[Epoch 52/200] [Batch 0/469] [D loss: 0.713980] [G loss: 1.054379]\n",
            "[Epoch 52/200] [Batch 50/469] [D loss: 0.925563] [G loss: 0.811232]\n",
            "[Epoch 52/200] [Batch 100/469] [D loss: 0.160832] [G loss: 2.109743]\n",
            "[Epoch 52/200] [Batch 150/469] [D loss: 0.890909] [G loss: 1.812364]\n",
            "[Epoch 52/200] [Batch 200/469] [D loss: 0.648789] [G loss: 0.988392]\n",
            "[Epoch 52/200] [Batch 250/469] [D loss: 0.492296] [G loss: 1.285851]\n",
            "[Epoch 52/200] [Batch 300/469] [D loss: 0.348696] [G loss: 1.257309]\n",
            "[Epoch 52/200] [Batch 350/469] [D loss: 0.505500] [G loss: 0.906267]\n",
            "[Epoch 52/200] [Batch 400/469] [D loss: 0.540394] [G loss: 0.907243]\n",
            "[Epoch 52/200] [Batch 450/469] [D loss: 0.300713] [G loss: 1.319795]\n",
            "[Epoch 53/200] [Batch 0/469] [D loss: 0.625916] [G loss: 1.013673]\n",
            "[Epoch 53/200] [Batch 50/469] [D loss: 0.484589] [G loss: 0.776699]\n",
            "[Epoch 53/200] [Batch 100/469] [D loss: 0.391859] [G loss: 1.125049]\n",
            "[Epoch 53/200] [Batch 150/469] [D loss: 0.323314] [G loss: 0.963194]\n",
            "[Epoch 53/200] [Batch 200/469] [D loss: 0.395227] [G loss: 2.436810]\n",
            "[Epoch 53/200] [Batch 250/469] [D loss: 0.730602] [G loss: 1.845196]\n",
            "[Epoch 53/200] [Batch 300/469] [D loss: 0.660501] [G loss: 2.151187]\n",
            "[Epoch 53/200] [Batch 350/469] [D loss: 0.719810] [G loss: 0.503866]\n",
            "[Epoch 53/200] [Batch 400/469] [D loss: 0.593325] [G loss: 2.305584]\n",
            "[Epoch 53/200] [Batch 450/469] [D loss: 0.944107] [G loss: 2.061984]\n",
            "[Epoch 54/200] [Batch 0/469] [D loss: 0.620839] [G loss: 2.037934]\n",
            "[Epoch 54/200] [Batch 50/469] [D loss: 0.174367] [G loss: 2.008655]\n",
            "[Epoch 54/200] [Batch 100/469] [D loss: 0.388593] [G loss: 1.794714]\n",
            "[Epoch 54/200] [Batch 150/469] [D loss: 0.235054] [G loss: 2.758513]\n",
            "[Epoch 54/200] [Batch 200/469] [D loss: 0.522753] [G loss: 0.319869]\n",
            "[Epoch 54/200] [Batch 250/469] [D loss: 0.317748] [G loss: 1.125390]\n",
            "[Epoch 54/200] [Batch 300/469] [D loss: 0.411415] [G loss: 1.019573]\n",
            "[Epoch 54/200] [Batch 350/469] [D loss: 0.404118] [G loss: 0.810620]\n",
            "[Epoch 54/200] [Batch 400/469] [D loss: 0.400835] [G loss: 1.893067]\n",
            "[Epoch 54/200] [Batch 450/469] [D loss: 0.275378] [G loss: 0.817794]\n",
            "[Epoch 55/200] [Batch 0/469] [D loss: 1.465898] [G loss: 0.083437]\n",
            "[Epoch 55/200] [Batch 50/469] [D loss: 0.246166] [G loss: 0.770629]\n",
            "[Epoch 55/200] [Batch 100/469] [D loss: 0.598813] [G loss: 0.581215]\n",
            "[Epoch 55/200] [Batch 150/469] [D loss: 0.646577] [G loss: 0.647016]\n",
            "[Epoch 55/200] [Batch 200/469] [D loss: 0.768557] [G loss: 1.033245]\n",
            "[Epoch 55/200] [Batch 250/469] [D loss: 0.517778] [G loss: 0.673248]\n",
            "[Epoch 55/200] [Batch 300/469] [D loss: 0.552666] [G loss: 3.088682]\n",
            "[Epoch 55/200] [Batch 350/469] [D loss: 0.390763] [G loss: 2.848481]\n",
            "[Epoch 55/200] [Batch 400/469] [D loss: 0.831953] [G loss: 0.654185]\n",
            "[Epoch 55/200] [Batch 450/469] [D loss: 0.567719] [G loss: 0.436449]\n",
            "[Epoch 56/200] [Batch 0/469] [D loss: 0.446534] [G loss: 1.390187]\n",
            "[Epoch 56/200] [Batch 50/469] [D loss: 0.197078] [G loss: 1.861513]\n",
            "[Epoch 56/200] [Batch 100/469] [D loss: 1.080209] [G loss: 0.286984]\n",
            "[Epoch 56/200] [Batch 150/469] [D loss: 0.543392] [G loss: 0.303626]\n",
            "[Epoch 56/200] [Batch 200/469] [D loss: 0.389908] [G loss: 0.175965]\n",
            "[Epoch 56/200] [Batch 250/469] [D loss: 0.130194] [G loss: 1.759286]\n",
            "[Epoch 56/200] [Batch 300/469] [D loss: 0.804008] [G loss: 0.297924]\n",
            "[Epoch 56/200] [Batch 350/469] [D loss: 0.265490] [G loss: 0.918961]\n",
            "[Epoch 56/200] [Batch 400/469] [D loss: 0.245106] [G loss: 1.141547]\n",
            "[Epoch 56/200] [Batch 450/469] [D loss: 0.274163] [G loss: 2.059743]\n",
            "[Epoch 57/200] [Batch 0/469] [D loss: 0.191590] [G loss: 2.088245]\n",
            "[Epoch 57/200] [Batch 50/469] [D loss: 0.621756] [G loss: 1.246280]\n",
            "[Epoch 57/200] [Batch 100/469] [D loss: 0.380637] [G loss: 1.498154]\n",
            "[Epoch 57/200] [Batch 150/469] [D loss: 0.180966] [G loss: 2.123422]\n",
            "[Epoch 57/200] [Batch 200/469] [D loss: 0.890258] [G loss: 0.154380]\n",
            "[Epoch 57/200] [Batch 250/469] [D loss: 0.344552] [G loss: 2.325378]\n",
            "[Epoch 57/200] [Batch 300/469] [D loss: 0.543551] [G loss: 1.106618]\n",
            "[Epoch 57/200] [Batch 350/469] [D loss: 0.578290] [G loss: 2.336195]\n",
            "[Epoch 57/200] [Batch 400/469] [D loss: 0.338703] [G loss: 2.602088]\n",
            "[Epoch 57/200] [Batch 450/469] [D loss: 0.395628] [G loss: 0.996846]\n",
            "[Epoch 58/200] [Batch 0/469] [D loss: 0.412894] [G loss: 1.802908]\n",
            "[Epoch 58/200] [Batch 50/469] [D loss: 0.544598] [G loss: 0.778327]\n",
            "[Epoch 58/200] [Batch 100/469] [D loss: 0.471556] [G loss: 1.055434]\n",
            "[Epoch 58/200] [Batch 150/469] [D loss: 0.267272] [G loss: 1.049320]\n",
            "[Epoch 58/200] [Batch 200/469] [D loss: 0.345994] [G loss: 2.123469]\n",
            "[Epoch 58/200] [Batch 250/469] [D loss: 0.372078] [G loss: 1.847059]\n",
            "[Epoch 58/200] [Batch 300/469] [D loss: 0.417688] [G loss: 0.310944]\n",
            "[Epoch 58/200] [Batch 350/469] [D loss: 0.661107] [G loss: 1.569681]\n",
            "[Epoch 58/200] [Batch 400/469] [D loss: 0.537619] [G loss: 0.353737]\n",
            "[Epoch 58/200] [Batch 450/469] [D loss: 0.802816] [G loss: 0.748497]\n",
            "[Epoch 59/200] [Batch 0/469] [D loss: 0.696094] [G loss: 0.341448]\n",
            "[Epoch 59/200] [Batch 50/469] [D loss: 1.022203] [G loss: 0.370321]\n",
            "[Epoch 59/200] [Batch 100/469] [D loss: 1.130141] [G loss: 1.104691]\n",
            "[Epoch 59/200] [Batch 150/469] [D loss: 0.580506] [G loss: 1.139343]\n",
            "[Epoch 59/200] [Batch 200/469] [D loss: 0.214866] [G loss: 1.649642]\n",
            "[Epoch 59/200] [Batch 250/469] [D loss: 0.324735] [G loss: 0.960379]\n",
            "[Epoch 59/200] [Batch 300/469] [D loss: 0.261493] [G loss: 1.702849]\n",
            "[Epoch 59/200] [Batch 350/469] [D loss: 0.437210] [G loss: 0.399874]\n",
            "[Epoch 59/200] [Batch 400/469] [D loss: 0.301698] [G loss: 2.148473]\n",
            "[Epoch 59/200] [Batch 450/469] [D loss: 0.468186] [G loss: 2.795172]\n",
            "[Epoch 60/200] [Batch 0/469] [D loss: 0.808673] [G loss: 0.411463]\n",
            "[Epoch 60/200] [Batch 50/469] [D loss: 0.404258] [G loss: 3.333687]\n",
            "[Epoch 60/200] [Batch 100/469] [D loss: 0.860749] [G loss: 0.489744]\n",
            "[Epoch 60/200] [Batch 150/469] [D loss: 0.401475] [G loss: 1.154579]\n",
            "[Epoch 60/200] [Batch 200/469] [D loss: 0.303848] [G loss: 1.334288]\n",
            "[Epoch 60/200] [Batch 250/469] [D loss: 1.138194] [G loss: 0.399681]\n",
            "[Epoch 60/200] [Batch 300/469] [D loss: 0.793375] [G loss: 0.313071]\n",
            "[Epoch 60/200] [Batch 350/469] [D loss: 0.471066] [G loss: 2.105590]\n",
            "[Epoch 60/200] [Batch 400/469] [D loss: 0.483246] [G loss: 0.944022]\n",
            "[Epoch 60/200] [Batch 450/469] [D loss: 1.226228] [G loss: 0.301666]\n",
            "[Epoch 61/200] [Batch 0/469] [D loss: 1.479203] [G loss: 0.309330]\n",
            "[Epoch 61/200] [Batch 50/469] [D loss: 0.824582] [G loss: 1.320599]\n",
            "[Epoch 61/200] [Batch 100/469] [D loss: 0.735639] [G loss: 0.742323]\n",
            "[Epoch 61/200] [Batch 150/469] [D loss: 0.475896] [G loss: 1.037239]\n",
            "[Epoch 61/200] [Batch 200/469] [D loss: 0.596503] [G loss: 1.031892]\n",
            "[Epoch 61/200] [Batch 250/469] [D loss: 0.218662] [G loss: 0.728489]\n",
            "[Epoch 61/200] [Batch 300/469] [D loss: 0.596206] [G loss: 2.299712]\n",
            "[Epoch 61/200] [Batch 350/469] [D loss: 0.842801] [G loss: 2.866268]\n",
            "[Epoch 61/200] [Batch 400/469] [D loss: 0.565790] [G loss: 0.482578]\n",
            "[Epoch 61/200] [Batch 450/469] [D loss: 0.347916] [G loss: 1.170840]\n",
            "[Epoch 62/200] [Batch 0/469] [D loss: 0.465578] [G loss: 1.737861]\n",
            "[Epoch 62/200] [Batch 50/469] [D loss: 0.294411] [G loss: 0.770065]\n",
            "[Epoch 62/200] [Batch 100/469] [D loss: 0.436553] [G loss: 0.991059]\n",
            "[Epoch 62/200] [Batch 150/469] [D loss: 0.500173] [G loss: 1.356078]\n",
            "[Epoch 62/200] [Batch 200/469] [D loss: 0.431206] [G loss: 0.522538]\n",
            "[Epoch 62/200] [Batch 250/469] [D loss: 0.463797] [G loss: 0.347745]\n",
            "[Epoch 62/200] [Batch 300/469] [D loss: 0.414073] [G loss: 3.197994]\n",
            "[Epoch 62/200] [Batch 350/469] [D loss: 1.051403] [G loss: 0.374248]\n",
            "[Epoch 62/200] [Batch 400/469] [D loss: 0.946113] [G loss: 0.256036]\n",
            "[Epoch 62/200] [Batch 450/469] [D loss: 0.498939] [G loss: 2.043919]\n",
            "[Epoch 63/200] [Batch 0/469] [D loss: 0.221376] [G loss: 1.403210]\n",
            "[Epoch 63/200] [Batch 50/469] [D loss: 0.235885] [G loss: 0.649669]\n",
            "[Epoch 63/200] [Batch 100/469] [D loss: 0.651101] [G loss: 0.782877]\n",
            "[Epoch 63/200] [Batch 150/469] [D loss: 0.510450] [G loss: 0.876380]\n",
            "[Epoch 63/200] [Batch 200/469] [D loss: 1.054680] [G loss: 3.473121]\n",
            "[Epoch 63/200] [Batch 250/469] [D loss: 0.728659] [G loss: 2.526008]\n",
            "[Epoch 63/200] [Batch 300/469] [D loss: 0.085067] [G loss: 3.033062]\n",
            "[Epoch 63/200] [Batch 350/469] [D loss: 0.261418] [G loss: 2.252760]\n",
            "[Epoch 63/200] [Batch 400/469] [D loss: 0.786107] [G loss: 0.715730]\n",
            "[Epoch 63/200] [Batch 450/469] [D loss: 0.391423] [G loss: 2.527395]\n",
            "[Epoch 64/200] [Batch 0/469] [D loss: 0.420687] [G loss: 0.439114]\n",
            "[Epoch 64/200] [Batch 50/469] [D loss: 0.480745] [G loss: 2.201526]\n",
            "[Epoch 64/200] [Batch 100/469] [D loss: 0.492938] [G loss: 0.949690]\n",
            "[Epoch 64/200] [Batch 150/469] [D loss: 0.510821] [G loss: 1.409361]\n",
            "[Epoch 64/200] [Batch 200/469] [D loss: 0.758656] [G loss: 0.432040]\n",
            "[Epoch 64/200] [Batch 250/469] [D loss: 0.541988] [G loss: 0.434080]\n",
            "[Epoch 64/200] [Batch 300/469] [D loss: 0.488391] [G loss: 2.778162]\n",
            "[Epoch 64/200] [Batch 350/469] [D loss: 0.576342] [G loss: 1.377583]\n",
            "[Epoch 64/200] [Batch 400/469] [D loss: 0.293605] [G loss: 1.049272]\n",
            "[Epoch 64/200] [Batch 450/469] [D loss: 0.184246] [G loss: 1.422955]\n",
            "[Epoch 65/200] [Batch 0/469] [D loss: 0.322288] [G loss: 1.791195]\n",
            "[Epoch 65/200] [Batch 50/469] [D loss: 0.409222] [G loss: 1.687176]\n",
            "[Epoch 65/200] [Batch 100/469] [D loss: 0.392286] [G loss: 1.746965]\n",
            "[Epoch 65/200] [Batch 150/469] [D loss: 0.155053] [G loss: 0.997495]\n",
            "[Epoch 65/200] [Batch 200/469] [D loss: 0.779938] [G loss: 0.824151]\n",
            "[Epoch 65/200] [Batch 250/469] [D loss: 0.176085] [G loss: 0.718547]\n",
            "[Epoch 65/200] [Batch 300/469] [D loss: 0.445852] [G loss: 1.605530]\n",
            "[Epoch 65/200] [Batch 350/469] [D loss: 0.435680] [G loss: 1.940311]\n",
            "[Epoch 65/200] [Batch 400/469] [D loss: 0.310884] [G loss: 1.082255]\n",
            "[Epoch 65/200] [Batch 450/469] [D loss: 0.717832] [G loss: 1.577328]\n",
            "[Epoch 66/200] [Batch 0/469] [D loss: 0.759464] [G loss: 0.689583]\n",
            "[Epoch 66/200] [Batch 50/469] [D loss: 0.410830] [G loss: 0.932624]\n",
            "[Epoch 66/200] [Batch 100/469] [D loss: 0.215866] [G loss: 1.810571]\n",
            "[Epoch 66/200] [Batch 150/469] [D loss: 0.278563] [G loss: 1.544042]\n",
            "[Epoch 66/200] [Batch 200/469] [D loss: 0.420199] [G loss: 1.891698]\n",
            "[Epoch 66/200] [Batch 250/469] [D loss: 0.237999] [G loss: 1.099927]\n",
            "[Epoch 66/200] [Batch 300/469] [D loss: 0.514730] [G loss: 3.059162]\n",
            "[Epoch 66/200] [Batch 350/469] [D loss: 0.131478] [G loss: 1.790643]\n",
            "[Epoch 66/200] [Batch 400/469] [D loss: 0.861246] [G loss: 0.195857]\n",
            "[Epoch 66/200] [Batch 450/469] [D loss: 0.504004] [G loss: 0.747650]\n",
            "[Epoch 67/200] [Batch 0/469] [D loss: 0.169428] [G loss: 2.059687]\n",
            "[Epoch 67/200] [Batch 50/469] [D loss: 0.312279] [G loss: 1.564747]\n",
            "[Epoch 67/200] [Batch 100/469] [D loss: 0.811062] [G loss: 3.560523]\n",
            "[Epoch 67/200] [Batch 150/469] [D loss: 0.613501] [G loss: 1.665285]\n",
            "[Epoch 67/200] [Batch 200/469] [D loss: 0.127693] [G loss: 1.853796]\n",
            "[Epoch 67/200] [Batch 250/469] [D loss: 0.295474] [G loss: 3.284067]\n",
            "[Epoch 67/200] [Batch 300/469] [D loss: 0.546631] [G loss: 1.987671]\n",
            "[Epoch 67/200] [Batch 350/469] [D loss: 0.354413] [G loss: 1.448735]\n",
            "[Epoch 67/200] [Batch 400/469] [D loss: 0.395983] [G loss: 1.739756]\n",
            "[Epoch 67/200] [Batch 450/469] [D loss: 0.683545] [G loss: 0.497537]\n",
            "[Epoch 68/200] [Batch 0/469] [D loss: 0.200410] [G loss: 2.788673]\n",
            "[Epoch 68/200] [Batch 50/469] [D loss: 0.353987] [G loss: 1.011906]\n",
            "[Epoch 68/200] [Batch 100/469] [D loss: 0.637392] [G loss: 1.038678]\n",
            "[Epoch 68/200] [Batch 150/469] [D loss: 0.541950] [G loss: 1.242627]\n",
            "[Epoch 68/200] [Batch 200/469] [D loss: 0.321740] [G loss: 2.014805]\n",
            "[Epoch 68/200] [Batch 250/469] [D loss: 0.404498] [G loss: 1.703739]\n",
            "[Epoch 68/200] [Batch 300/469] [D loss: 0.641351] [G loss: 0.745690]\n",
            "[Epoch 68/200] [Batch 350/469] [D loss: 0.356727] [G loss: 1.256092]\n",
            "[Epoch 68/200] [Batch 400/469] [D loss: 0.148445] [G loss: 2.103936]\n",
            "[Epoch 68/200] [Batch 450/469] [D loss: 0.401161] [G loss: 1.558896]\n",
            "[Epoch 69/200] [Batch 0/469] [D loss: 0.255728] [G loss: 2.980436]\n",
            "[Epoch 69/200] [Batch 50/469] [D loss: 0.376806] [G loss: 2.213350]\n",
            "[Epoch 69/200] [Batch 100/469] [D loss: 0.227700] [G loss: 2.476137]\n",
            "[Epoch 69/200] [Batch 150/469] [D loss: 0.767061] [G loss: 1.526738]\n",
            "[Epoch 69/200] [Batch 200/469] [D loss: 0.237574] [G loss: 2.451357]\n",
            "[Epoch 69/200] [Batch 250/469] [D loss: 0.377641] [G loss: 0.362227]\n",
            "[Epoch 69/200] [Batch 300/469] [D loss: 0.944554] [G loss: 2.317824]\n",
            "[Epoch 69/200] [Batch 350/469] [D loss: 0.658789] [G loss: 3.216281]\n",
            "[Epoch 69/200] [Batch 400/469] [D loss: 0.775731] [G loss: 0.479671]\n",
            "[Epoch 69/200] [Batch 450/469] [D loss: 0.631886] [G loss: 2.577823]\n",
            "[Epoch 70/200] [Batch 0/469] [D loss: 0.409047] [G loss: 0.474911]\n",
            "[Epoch 70/200] [Batch 50/469] [D loss: 0.270660] [G loss: 1.675543]\n",
            "[Epoch 70/200] [Batch 100/469] [D loss: 0.462576] [G loss: 0.743798]\n",
            "[Epoch 70/200] [Batch 150/469] [D loss: 0.937002] [G loss: 5.016027]\n",
            "[Epoch 70/200] [Batch 200/469] [D loss: 0.474277] [G loss: 0.127576]\n",
            "[Epoch 70/200] [Batch 250/469] [D loss: 0.657844] [G loss: 1.605479]\n",
            "[Epoch 70/200] [Batch 300/469] [D loss: 0.502925] [G loss: 0.676464]\n",
            "[Epoch 70/200] [Batch 350/469] [D loss: 0.396862] [G loss: 2.820779]\n",
            "[Epoch 70/200] [Batch 400/469] [D loss: 0.095639] [G loss: 3.537642]\n",
            "[Epoch 70/200] [Batch 450/469] [D loss: 0.693811] [G loss: 1.493616]\n",
            "[Epoch 71/200] [Batch 0/469] [D loss: 0.601454] [G loss: 0.827369]\n",
            "[Epoch 71/200] [Batch 50/469] [D loss: 0.529666] [G loss: 0.132496]\n",
            "[Epoch 71/200] [Batch 100/469] [D loss: 0.456756] [G loss: 0.846495]\n",
            "[Epoch 71/200] [Batch 150/469] [D loss: 0.276678] [G loss: 1.836073]\n",
            "[Epoch 71/200] [Batch 200/469] [D loss: 0.341876] [G loss: 1.934074]\n",
            "[Epoch 71/200] [Batch 250/469] [D loss: 0.555735] [G loss: 0.818494]\n",
            "[Epoch 71/200] [Batch 300/469] [D loss: 0.098725] [G loss: 1.771602]\n",
            "[Epoch 71/200] [Batch 350/469] [D loss: 1.156485] [G loss: 0.185347]\n",
            "[Epoch 71/200] [Batch 400/469] [D loss: 0.558528] [G loss: 3.229280]\n",
            "[Epoch 71/200] [Batch 450/469] [D loss: 0.320809] [G loss: 2.029707]\n",
            "[Epoch 72/200] [Batch 0/469] [D loss: 0.432620] [G loss: 1.598573]\n",
            "[Epoch 72/200] [Batch 50/469] [D loss: 0.551668] [G loss: 0.525914]\n",
            "[Epoch 72/200] [Batch 100/469] [D loss: 0.377911] [G loss: 0.481236]\n",
            "[Epoch 72/200] [Batch 150/469] [D loss: 0.497535] [G loss: 1.099288]\n",
            "[Epoch 72/200] [Batch 200/469] [D loss: 0.245484] [G loss: 1.053984]\n",
            "[Epoch 72/200] [Batch 250/469] [D loss: 0.348448] [G loss: 0.569462]\n",
            "[Epoch 72/200] [Batch 300/469] [D loss: 0.821771] [G loss: 3.324566]\n",
            "[Epoch 72/200] [Batch 350/469] [D loss: 0.592309] [G loss: 0.295714]\n",
            "[Epoch 72/200] [Batch 400/469] [D loss: 0.327130] [G loss: 0.432255]\n",
            "[Epoch 72/200] [Batch 450/469] [D loss: 0.519593] [G loss: 1.061298]\n",
            "[Epoch 73/200] [Batch 0/469] [D loss: 0.427203] [G loss: 1.864251]\n",
            "[Epoch 73/200] [Batch 50/469] [D loss: 1.157817] [G loss: 0.387951]\n",
            "[Epoch 73/200] [Batch 100/469] [D loss: 0.319587] [G loss: 0.467303]\n",
            "[Epoch 73/200] [Batch 150/469] [D loss: 0.290186] [G loss: 0.974067]\n",
            "[Epoch 73/200] [Batch 200/469] [D loss: 0.192356] [G loss: 1.598103]\n",
            "[Epoch 73/200] [Batch 250/469] [D loss: 0.246769] [G loss: 2.329104]\n",
            "[Epoch 73/200] [Batch 300/469] [D loss: 1.047525] [G loss: 0.349639]\n",
            "[Epoch 73/200] [Batch 350/469] [D loss: 0.269157] [G loss: 2.155132]\n",
            "[Epoch 73/200] [Batch 400/469] [D loss: 0.356876] [G loss: 1.254704]\n",
            "[Epoch 73/200] [Batch 450/469] [D loss: 0.182338] [G loss: 1.508157]\n",
            "[Epoch 74/200] [Batch 0/469] [D loss: 0.181379] [G loss: 1.823878]\n",
            "[Epoch 74/200] [Batch 50/469] [D loss: 0.599809] [G loss: 2.135568]\n",
            "[Epoch 74/200] [Batch 100/469] [D loss: 0.309987] [G loss: 2.040189]\n",
            "[Epoch 74/200] [Batch 150/469] [D loss: 0.356490] [G loss: 1.178541]\n",
            "[Epoch 74/200] [Batch 200/469] [D loss: 0.956458] [G loss: 0.244249]\n",
            "[Epoch 74/200] [Batch 250/469] [D loss: 0.340727] [G loss: 2.653087]\n",
            "[Epoch 74/200] [Batch 300/469] [D loss: 0.361596] [G loss: 2.826102]\n",
            "[Epoch 74/200] [Batch 350/469] [D loss: 0.925024] [G loss: 4.679097]\n",
            "[Epoch 74/200] [Batch 400/469] [D loss: 0.560881] [G loss: 2.310563]\n",
            "[Epoch 74/200] [Batch 450/469] [D loss: 0.338759] [G loss: 3.000149]\n",
            "[Epoch 75/200] [Batch 0/469] [D loss: 0.412783] [G loss: 1.056666]\n",
            "[Epoch 75/200] [Batch 50/469] [D loss: 0.271372] [G loss: 1.040243]\n",
            "[Epoch 75/200] [Batch 100/469] [D loss: 1.215441] [G loss: 0.365878]\n",
            "[Epoch 75/200] [Batch 150/469] [D loss: 0.363306] [G loss: 3.490882]\n",
            "[Epoch 75/200] [Batch 200/469] [D loss: 0.138390] [G loss: 3.686933]\n",
            "[Epoch 75/200] [Batch 250/469] [D loss: 0.334519] [G loss: 0.866912]\n",
            "[Epoch 75/200] [Batch 300/469] [D loss: 0.229256] [G loss: 2.272295]\n",
            "[Epoch 75/200] [Batch 350/469] [D loss: 0.726819] [G loss: 2.314121]\n",
            "[Epoch 75/200] [Batch 400/469] [D loss: 0.470110] [G loss: 0.964184]\n",
            "[Epoch 75/200] [Batch 450/469] [D loss: 0.423607] [G loss: 1.115060]\n",
            "[Epoch 76/200] [Batch 0/469] [D loss: 0.172673] [G loss: 2.414271]\n",
            "[Epoch 76/200] [Batch 50/469] [D loss: 0.538082] [G loss: 4.748420]\n",
            "[Epoch 76/200] [Batch 100/469] [D loss: 0.341735] [G loss: 0.704974]\n",
            "[Epoch 76/200] [Batch 150/469] [D loss: 0.322884] [G loss: 1.393700]\n",
            "[Epoch 76/200] [Batch 200/469] [D loss: 0.389358] [G loss: 0.227355]\n",
            "[Epoch 76/200] [Batch 250/469] [D loss: 0.206008] [G loss: 2.008546]\n",
            "[Epoch 76/200] [Batch 300/469] [D loss: 0.273142] [G loss: 1.067846]\n",
            "[Epoch 76/200] [Batch 350/469] [D loss: 0.360859] [G loss: 0.930680]\n",
            "[Epoch 76/200] [Batch 400/469] [D loss: 0.568577] [G loss: 0.773194]\n",
            "[Epoch 76/200] [Batch 450/469] [D loss: 0.333019] [G loss: 1.925102]\n",
            "[Epoch 77/200] [Batch 0/469] [D loss: 0.064789] [G loss: 1.929487]\n",
            "[Epoch 77/200] [Batch 50/469] [D loss: 0.127189] [G loss: 2.489817]\n",
            "[Epoch 77/200] [Batch 100/469] [D loss: 0.358080] [G loss: 0.546987]\n",
            "[Epoch 77/200] [Batch 150/469] [D loss: 0.300106] [G loss: 1.437803]\n",
            "[Epoch 77/200] [Batch 200/469] [D loss: 0.196565] [G loss: 0.439374]\n",
            "[Epoch 77/200] [Batch 250/469] [D loss: 0.253640] [G loss: 2.816078]\n",
            "[Epoch 77/200] [Batch 300/469] [D loss: 0.508999] [G loss: 2.289332]\n",
            "[Epoch 77/200] [Batch 350/469] [D loss: 0.932695] [G loss: 0.327205]\n",
            "[Epoch 77/200] [Batch 400/469] [D loss: 0.936403] [G loss: 2.400515]\n",
            "[Epoch 77/200] [Batch 450/469] [D loss: 0.625550] [G loss: 3.481164]\n",
            "[Epoch 78/200] [Batch 0/469] [D loss: 0.190866] [G loss: 2.320918]\n",
            "[Epoch 78/200] [Batch 50/469] [D loss: 0.383173] [G loss: 2.627928]\n",
            "[Epoch 78/200] [Batch 100/469] [D loss: 0.388920] [G loss: 2.090871]\n",
            "[Epoch 78/200] [Batch 150/469] [D loss: 0.312676] [G loss: 1.236377]\n",
            "[Epoch 78/200] [Batch 200/469] [D loss: 0.394790] [G loss: 1.469938]\n",
            "[Epoch 78/200] [Batch 250/469] [D loss: 0.314647] [G loss: 0.863380]\n",
            "[Epoch 78/200] [Batch 300/469] [D loss: 0.377932] [G loss: 1.714173]\n",
            "[Epoch 78/200] [Batch 350/469] [D loss: 0.336645] [G loss: 3.091181]\n",
            "[Epoch 78/200] [Batch 400/469] [D loss: 0.195129] [G loss: 1.792282]\n",
            "[Epoch 78/200] [Batch 450/469] [D loss: 0.223915] [G loss: 2.453065]\n",
            "[Epoch 79/200] [Batch 0/469] [D loss: 0.235354] [G loss: 1.279715]\n",
            "[Epoch 79/200] [Batch 50/469] [D loss: 0.375546] [G loss: 0.743534]\n",
            "[Epoch 79/200] [Batch 100/469] [D loss: 0.396465] [G loss: 0.355689]\n",
            "[Epoch 79/200] [Batch 150/469] [D loss: 0.282778] [G loss: 3.953380]\n",
            "[Epoch 79/200] [Batch 200/469] [D loss: 0.453126] [G loss: 2.716591]\n",
            "[Epoch 79/200] [Batch 250/469] [D loss: 1.020126] [G loss: 0.298586]\n",
            "[Epoch 79/200] [Batch 300/469] [D loss: 0.197476] [G loss: 2.725054]\n",
            "[Epoch 79/200] [Batch 350/469] [D loss: 0.518671] [G loss: 0.887972]\n",
            "[Epoch 79/200] [Batch 400/469] [D loss: 0.114248] [G loss: 2.803224]\n",
            "[Epoch 79/200] [Batch 450/469] [D loss: 0.331709] [G loss: 1.053684]\n",
            "[Epoch 80/200] [Batch 0/469] [D loss: 0.124706] [G loss: 1.372086]\n",
            "[Epoch 80/200] [Batch 50/469] [D loss: 0.803384] [G loss: 3.199114]\n",
            "[Epoch 80/200] [Batch 100/469] [D loss: 0.113602] [G loss: 2.561022]\n",
            "[Epoch 80/200] [Batch 150/469] [D loss: 0.688837] [G loss: 1.127333]\n",
            "[Epoch 80/200] [Batch 200/469] [D loss: 0.326563] [G loss: 1.088345]\n",
            "[Epoch 80/200] [Batch 250/469] [D loss: 0.210663] [G loss: 2.019602]\n",
            "[Epoch 80/200] [Batch 300/469] [D loss: 0.104505] [G loss: 2.293522]\n",
            "[Epoch 80/200] [Batch 350/469] [D loss: 0.742350] [G loss: 0.825191]\n",
            "[Epoch 80/200] [Batch 400/469] [D loss: 0.992507] [G loss: 0.334967]\n",
            "[Epoch 80/200] [Batch 450/469] [D loss: 0.856382] [G loss: 0.374601]\n",
            "[Epoch 81/200] [Batch 0/469] [D loss: 0.200258] [G loss: 1.128407]\n",
            "[Epoch 81/200] [Batch 50/469] [D loss: 0.401007] [G loss: 0.649520]\n",
            "[Epoch 81/200] [Batch 100/469] [D loss: 0.371133] [G loss: 0.342990]\n",
            "[Epoch 81/200] [Batch 150/469] [D loss: 0.751619] [G loss: 0.099797]\n",
            "[Epoch 81/200] [Batch 200/469] [D loss: 0.682163] [G loss: 2.681060]\n",
            "[Epoch 81/200] [Batch 250/469] [D loss: 0.288993] [G loss: 1.242981]\n",
            "[Epoch 81/200] [Batch 300/469] [D loss: 0.344914] [G loss: 1.330350]\n",
            "[Epoch 81/200] [Batch 350/469] [D loss: 0.593130] [G loss: 1.677271]\n",
            "[Epoch 81/200] [Batch 400/469] [D loss: 0.207742] [G loss: 1.898888]\n",
            "[Epoch 81/200] [Batch 450/469] [D loss: 0.350736] [G loss: 3.705345]\n",
            "[Epoch 82/200] [Batch 0/469] [D loss: 0.395035] [G loss: 2.598967]\n",
            "[Epoch 82/200] [Batch 50/469] [D loss: 0.629229] [G loss: 2.709633]\n",
            "[Epoch 82/200] [Batch 100/469] [D loss: 0.401029] [G loss: 2.371434]\n",
            "[Epoch 82/200] [Batch 150/469] [D loss: 0.425790] [G loss: 0.346558]\n",
            "[Epoch 82/200] [Batch 200/469] [D loss: 0.146899] [G loss: 0.327616]\n",
            "[Epoch 82/200] [Batch 250/469] [D loss: 0.192190] [G loss: 0.659696]\n",
            "[Epoch 82/200] [Batch 300/469] [D loss: 0.415592] [G loss: 1.899190]\n",
            "[Epoch 82/200] [Batch 350/469] [D loss: 0.689629] [G loss: 0.400368]\n",
            "[Epoch 82/200] [Batch 400/469] [D loss: 0.153536] [G loss: 1.869740]\n",
            "[Epoch 82/200] [Batch 450/469] [D loss: 0.941930] [G loss: 0.211042]\n",
            "[Epoch 83/200] [Batch 0/469] [D loss: 0.488003] [G loss: 0.655359]\n",
            "[Epoch 83/200] [Batch 50/469] [D loss: 0.991386] [G loss: 0.247565]\n",
            "[Epoch 83/200] [Batch 100/469] [D loss: 0.631321] [G loss: 1.684436]\n",
            "[Epoch 83/200] [Batch 150/469] [D loss: 0.434097] [G loss: 0.742227]\n",
            "[Epoch 83/200] [Batch 200/469] [D loss: 0.294474] [G loss: 1.034717]\n",
            "[Epoch 83/200] [Batch 250/469] [D loss: 0.210538] [G loss: 1.580249]\n",
            "[Epoch 83/200] [Batch 300/469] [D loss: 0.391633] [G loss: 1.679829]\n",
            "[Epoch 83/200] [Batch 350/469] [D loss: 0.296680] [G loss: 1.525616]\n",
            "[Epoch 83/200] [Batch 400/469] [D loss: 0.368299] [G loss: 0.964527]\n",
            "[Epoch 83/200] [Batch 450/469] [D loss: 0.241860] [G loss: 2.355086]\n",
            "[Epoch 84/200] [Batch 0/469] [D loss: 0.710520] [G loss: 5.085536]\n",
            "[Epoch 84/200] [Batch 50/469] [D loss: 0.285257] [G loss: 0.424798]\n",
            "[Epoch 84/200] [Batch 100/469] [D loss: 0.167316] [G loss: 0.589069]\n",
            "[Epoch 84/200] [Batch 150/469] [D loss: 0.450480] [G loss: 0.511185]\n",
            "[Epoch 84/200] [Batch 200/469] [D loss: 0.317099] [G loss: 2.059079]\n",
            "[Epoch 84/200] [Batch 250/469] [D loss: 0.378077] [G loss: 0.887807]\n",
            "[Epoch 84/200] [Batch 300/469] [D loss: 0.168028] [G loss: 1.790453]\n",
            "[Epoch 84/200] [Batch 350/469] [D loss: 0.869298] [G loss: 0.386543]\n",
            "[Epoch 84/200] [Batch 400/469] [D loss: 0.400503] [G loss: 1.999850]\n",
            "[Epoch 84/200] [Batch 450/469] [D loss: 0.549549] [G loss: 0.273471]\n",
            "[Epoch 85/200] [Batch 0/469] [D loss: 0.211565] [G loss: 0.511431]\n",
            "[Epoch 85/200] [Batch 50/469] [D loss: 0.098058] [G loss: 3.761188]\n",
            "[Epoch 85/200] [Batch 100/469] [D loss: 0.428607] [G loss: 1.378304]\n",
            "[Epoch 85/200] [Batch 150/469] [D loss: 0.180517] [G loss: 3.413232]\n",
            "[Epoch 85/200] [Batch 200/469] [D loss: 0.116623] [G loss: 1.500434]\n",
            "[Epoch 85/200] [Batch 250/469] [D loss: 0.285300] [G loss: 1.236617]\n",
            "[Epoch 85/200] [Batch 300/469] [D loss: 0.141251] [G loss: 1.489011]\n",
            "[Epoch 85/200] [Batch 350/469] [D loss: 0.293724] [G loss: 0.611063]\n",
            "[Epoch 85/200] [Batch 400/469] [D loss: 0.212528] [G loss: 1.885766]\n",
            "[Epoch 85/200] [Batch 450/469] [D loss: 0.594196] [G loss: 0.472424]\n",
            "[Epoch 86/200] [Batch 0/469] [D loss: 0.169817] [G loss: 1.890003]\n",
            "[Epoch 86/200] [Batch 50/469] [D loss: 0.189027] [G loss: 2.754647]\n",
            "[Epoch 86/200] [Batch 100/469] [D loss: 0.779701] [G loss: 2.012873]\n",
            "[Epoch 86/200] [Batch 150/469] [D loss: 0.195555] [G loss: 0.534666]\n",
            "[Epoch 86/200] [Batch 200/469] [D loss: 0.142763] [G loss: 2.588210]\n",
            "[Epoch 86/200] [Batch 250/469] [D loss: 0.572406] [G loss: 0.588139]\n",
            "[Epoch 86/200] [Batch 300/469] [D loss: 0.337746] [G loss: 2.281168]\n",
            "[Epoch 86/200] [Batch 350/469] [D loss: 0.270465] [G loss: 1.409873]\n",
            "[Epoch 86/200] [Batch 400/469] [D loss: 0.195757] [G loss: 1.041892]\n",
            "[Epoch 86/200] [Batch 450/469] [D loss: 0.161858] [G loss: 1.491320]\n",
            "[Epoch 87/200] [Batch 0/469] [D loss: 0.580672] [G loss: 0.895360]\n",
            "[Epoch 87/200] [Batch 50/469] [D loss: 1.084016] [G loss: 0.263666]\n",
            "[Epoch 87/200] [Batch 100/469] [D loss: 1.141251] [G loss: 0.818870]\n",
            "[Epoch 87/200] [Batch 150/469] [D loss: 0.349634] [G loss: 1.937202]\n",
            "[Epoch 87/200] [Batch 200/469] [D loss: 0.174880] [G loss: 0.357181]\n",
            "[Epoch 87/200] [Batch 250/469] [D loss: 0.156835] [G loss: 3.900507]\n",
            "[Epoch 87/200] [Batch 300/469] [D loss: 0.687056] [G loss: 2.032265]\n",
            "[Epoch 87/200] [Batch 350/469] [D loss: 0.228677] [G loss: 0.439724]\n",
            "[Epoch 87/200] [Batch 400/469] [D loss: 1.328326] [G loss: 1.120089]\n",
            "[Epoch 87/200] [Batch 450/469] [D loss: 0.104371] [G loss: 1.377759]\n",
            "[Epoch 88/200] [Batch 0/469] [D loss: 0.291049] [G loss: 1.970802]\n",
            "[Epoch 88/200] [Batch 50/469] [D loss: 0.583670] [G loss: 2.851937]\n",
            "[Epoch 88/200] [Batch 100/469] [D loss: 0.251028] [G loss: 1.661329]\n",
            "[Epoch 88/200] [Batch 150/469] [D loss: 0.355661] [G loss: 0.341333]\n",
            "[Epoch 88/200] [Batch 200/469] [D loss: 0.243677] [G loss: 1.892902]\n",
            "[Epoch 88/200] [Batch 250/469] [D loss: 0.134786] [G loss: 1.507224]\n",
            "[Epoch 88/200] [Batch 300/469] [D loss: 0.370784] [G loss: 0.585415]\n",
            "[Epoch 88/200] [Batch 350/469] [D loss: 0.349753] [G loss: 2.974896]\n",
            "[Epoch 88/200] [Batch 400/469] [D loss: 0.367321] [G loss: 0.937662]\n",
            "[Epoch 88/200] [Batch 450/469] [D loss: 0.606073] [G loss: 0.791605]\n",
            "[Epoch 89/200] [Batch 0/469] [D loss: 0.246749] [G loss: 3.817734]\n",
            "[Epoch 89/200] [Batch 50/469] [D loss: 1.229633] [G loss: 3.618670]\n",
            "[Epoch 89/200] [Batch 100/469] [D loss: 0.041776] [G loss: 2.568882]\n",
            "[Epoch 89/200] [Batch 150/469] [D loss: 0.315923] [G loss: 3.153286]\n",
            "[Epoch 89/200] [Batch 200/469] [D loss: 0.114803] [G loss: 2.410192]\n",
            "[Epoch 89/200] [Batch 250/469] [D loss: 0.429042] [G loss: 0.471947]\n",
            "[Epoch 89/200] [Batch 300/469] [D loss: 0.241168] [G loss: 2.612126]\n",
            "[Epoch 89/200] [Batch 350/469] [D loss: 0.156156] [G loss: 3.240253]\n",
            "[Epoch 89/200] [Batch 400/469] [D loss: 0.369647] [G loss: 1.678893]\n",
            "[Epoch 89/200] [Batch 450/469] [D loss: 0.781080] [G loss: 0.483059]\n",
            "[Epoch 90/200] [Batch 0/469] [D loss: 0.923621] [G loss: 0.135877]\n",
            "[Epoch 90/200] [Batch 50/469] [D loss: 0.504734] [G loss: 4.054140]\n",
            "[Epoch 90/200] [Batch 100/469] [D loss: 0.076505] [G loss: 1.784585]\n",
            "[Epoch 90/200] [Batch 150/469] [D loss: 0.546688] [G loss: 3.914510]\n",
            "[Epoch 90/200] [Batch 200/469] [D loss: 0.156702] [G loss: 4.094516]\n",
            "[Epoch 90/200] [Batch 250/469] [D loss: 0.906641] [G loss: 1.928616]\n",
            "[Epoch 90/200] [Batch 300/469] [D loss: 0.852613] [G loss: 1.900117]\n",
            "[Epoch 90/200] [Batch 350/469] [D loss: 0.300730] [G loss: 0.997718]\n",
            "[Epoch 90/200] [Batch 400/469] [D loss: 0.597405] [G loss: 1.969108]\n",
            "[Epoch 90/200] [Batch 450/469] [D loss: 0.123699] [G loss: 3.097746]\n",
            "[Epoch 91/200] [Batch 0/469] [D loss: 0.393257] [G loss: 2.623836]\n",
            "[Epoch 91/200] [Batch 50/469] [D loss: 0.248316] [G loss: 1.408479]\n",
            "[Epoch 91/200] [Batch 100/469] [D loss: 0.241588] [G loss: 1.317574]\n",
            "[Epoch 91/200] [Batch 150/469] [D loss: 0.816949] [G loss: 2.511171]\n",
            "[Epoch 91/200] [Batch 200/469] [D loss: 0.199203] [G loss: 1.396685]\n",
            "[Epoch 91/200] [Batch 250/469] [D loss: 0.315092] [G loss: 1.195524]\n",
            "[Epoch 91/200] [Batch 300/469] [D loss: 0.139781] [G loss: 0.667964]\n",
            "[Epoch 91/200] [Batch 350/469] [D loss: 0.271284] [G loss: 2.228911]\n",
            "[Epoch 91/200] [Batch 400/469] [D loss: 0.136953] [G loss: 1.737602]\n",
            "[Epoch 91/200] [Batch 450/469] [D loss: 0.288750] [G loss: 1.627368]\n",
            "[Epoch 92/200] [Batch 0/469] [D loss: 0.339688] [G loss: 0.910642]\n",
            "[Epoch 92/200] [Batch 50/469] [D loss: 0.231206] [G loss: 3.230992]\n",
            "[Epoch 92/200] [Batch 100/469] [D loss: 0.587857] [G loss: 1.680453]\n",
            "[Epoch 92/200] [Batch 150/469] [D loss: 1.538831] [G loss: 2.412021]\n",
            "[Epoch 92/200] [Batch 200/469] [D loss: 0.636646] [G loss: 0.387509]\n",
            "[Epoch 92/200] [Batch 250/469] [D loss: 0.257405] [G loss: 0.791961]\n",
            "[Epoch 92/200] [Batch 300/469] [D loss: 0.181596] [G loss: 2.370512]\n",
            "[Epoch 92/200] [Batch 350/469] [D loss: 0.801934] [G loss: 0.076391]\n",
            "[Epoch 92/200] [Batch 400/469] [D loss: 0.270857] [G loss: 0.319971]\n",
            "[Epoch 92/200] [Batch 450/469] [D loss: 0.236563] [G loss: 1.817927]\n",
            "[Epoch 93/200] [Batch 0/469] [D loss: 0.599508] [G loss: 1.179792]\n",
            "[Epoch 93/200] [Batch 50/469] [D loss: 1.274823] [G loss: 4.587346]\n",
            "[Epoch 93/200] [Batch 100/469] [D loss: 0.685180] [G loss: 3.277716]\n",
            "[Epoch 93/200] [Batch 150/469] [D loss: 0.275888] [G loss: 0.719418]\n",
            "[Epoch 93/200] [Batch 200/469] [D loss: 0.122714] [G loss: 1.516625]\n",
            "[Epoch 93/200] [Batch 250/469] [D loss: 0.606155] [G loss: 3.000485]\n",
            "[Epoch 93/200] [Batch 300/469] [D loss: 0.125359] [G loss: 1.982658]\n",
            "[Epoch 93/200] [Batch 350/469] [D loss: 0.326199] [G loss: 2.869176]\n",
            "[Epoch 93/200] [Batch 400/469] [D loss: 0.828736] [G loss: 2.637356]\n",
            "[Epoch 93/200] [Batch 450/469] [D loss: 0.271940] [G loss: 2.574484]\n",
            "[Epoch 94/200] [Batch 0/469] [D loss: 0.147050] [G loss: 1.088587]\n",
            "[Epoch 94/200] [Batch 50/469] [D loss: 0.457154] [G loss: 2.481743]\n",
            "[Epoch 94/200] [Batch 100/469] [D loss: 0.733751] [G loss: 0.225084]\n",
            "[Epoch 94/200] [Batch 150/469] [D loss: 0.131713] [G loss: 2.447476]\n",
            "[Epoch 94/200] [Batch 200/469] [D loss: 0.220906] [G loss: 2.331972]\n",
            "[Epoch 94/200] [Batch 250/469] [D loss: 0.102288] [G loss: 1.750686]\n",
            "[Epoch 94/200] [Batch 300/469] [D loss: 0.184089] [G loss: 2.842279]\n",
            "[Epoch 94/200] [Batch 350/469] [D loss: 0.151821] [G loss: 2.336066]\n",
            "[Epoch 94/200] [Batch 400/469] [D loss: 0.254683] [G loss: 3.542511]\n",
            "[Epoch 94/200] [Batch 450/469] [D loss: 0.333546] [G loss: 2.245445]\n",
            "[Epoch 95/200] [Batch 0/469] [D loss: 0.202269] [G loss: 2.705652]\n",
            "[Epoch 95/200] [Batch 50/469] [D loss: 0.140098] [G loss: 1.804205]\n",
            "[Epoch 95/200] [Batch 100/469] [D loss: 1.146082] [G loss: 0.328039]\n",
            "[Epoch 95/200] [Batch 150/469] [D loss: 0.374704] [G loss: 1.555419]\n",
            "[Epoch 95/200] [Batch 200/469] [D loss: 0.338473] [G loss: 1.457505]\n",
            "[Epoch 95/200] [Batch 250/469] [D loss: 0.167905] [G loss: 1.279104]\n",
            "[Epoch 95/200] [Batch 300/469] [D loss: 0.307181] [G loss: 1.706376]\n",
            "[Epoch 95/200] [Batch 350/469] [D loss: 0.613438] [G loss: 1.842610]\n",
            "[Epoch 95/200] [Batch 400/469] [D loss: 0.244806] [G loss: 0.987146]\n",
            "[Epoch 95/200] [Batch 450/469] [D loss: 0.335648] [G loss: 0.619815]\n",
            "[Epoch 96/200] [Batch 0/469] [D loss: 0.359177] [G loss: 1.409050]\n",
            "[Epoch 96/200] [Batch 50/469] [D loss: 0.110259] [G loss: 1.630904]\n",
            "[Epoch 96/200] [Batch 100/469] [D loss: 0.300376] [G loss: 1.072411]\n",
            "[Epoch 96/200] [Batch 150/469] [D loss: 0.760208] [G loss: 2.398090]\n",
            "[Epoch 96/200] [Batch 200/469] [D loss: 0.193410] [G loss: 0.920611]\n",
            "[Epoch 96/200] [Batch 250/469] [D loss: 0.967927] [G loss: 2.317614]\n",
            "[Epoch 96/200] [Batch 300/469] [D loss: 0.483278] [G loss: 0.956693]\n",
            "[Epoch 96/200] [Batch 350/469] [D loss: 0.298039] [G loss: 3.373206]\n",
            "[Epoch 96/200] [Batch 400/469] [D loss: 0.390860] [G loss: 0.741039]\n",
            "[Epoch 96/200] [Batch 450/469] [D loss: 0.202886] [G loss: 1.876508]\n",
            "[Epoch 97/200] [Batch 0/469] [D loss: 0.135343] [G loss: 1.715562]\n",
            "[Epoch 97/200] [Batch 50/469] [D loss: 0.129775] [G loss: 2.065776]\n",
            "[Epoch 97/200] [Batch 100/469] [D loss: 0.128693] [G loss: 3.367240]\n",
            "[Epoch 97/200] [Batch 150/469] [D loss: 0.168455] [G loss: 1.978248]\n",
            "[Epoch 97/200] [Batch 200/469] [D loss: 0.135127] [G loss: 2.323741]\n",
            "[Epoch 97/200] [Batch 250/469] [D loss: 0.174531] [G loss: 1.572643]\n",
            "[Epoch 97/200] [Batch 300/469] [D loss: 0.193462] [G loss: 3.241858]\n",
            "[Epoch 97/200] [Batch 350/469] [D loss: 0.298375] [G loss: 1.695477]\n",
            "[Epoch 97/200] [Batch 400/469] [D loss: 0.164577] [G loss: 2.506266]\n",
            "[Epoch 97/200] [Batch 450/469] [D loss: 0.124925] [G loss: 2.532251]\n",
            "[Epoch 98/200] [Batch 0/469] [D loss: 0.211104] [G loss: 2.282344]\n",
            "[Epoch 98/200] [Batch 50/469] [D loss: 0.669611] [G loss: 0.474738]\n",
            "[Epoch 98/200] [Batch 100/469] [D loss: 1.092561] [G loss: 0.089953]\n",
            "[Epoch 98/200] [Batch 150/469] [D loss: 0.156928] [G loss: 1.359750]\n",
            "[Epoch 98/200] [Batch 200/469] [D loss: 1.015153] [G loss: 0.272767]\n",
            "[Epoch 98/200] [Batch 250/469] [D loss: 0.084343] [G loss: 3.182114]\n",
            "[Epoch 98/200] [Batch 300/469] [D loss: 0.186669] [G loss: 2.780107]\n",
            "[Epoch 98/200] [Batch 350/469] [D loss: 0.980536] [G loss: 2.409232]\n",
            "[Epoch 98/200] [Batch 400/469] [D loss: 0.197564] [G loss: 2.088006]\n",
            "[Epoch 98/200] [Batch 450/469] [D loss: 0.121969] [G loss: 2.044530]\n",
            "[Epoch 99/200] [Batch 0/469] [D loss: 0.417596] [G loss: 0.600819]\n",
            "[Epoch 99/200] [Batch 50/469] [D loss: 0.396231] [G loss: 1.614276]\n",
            "[Epoch 99/200] [Batch 100/469] [D loss: 0.419005] [G loss: 2.306734]\n",
            "[Epoch 99/200] [Batch 150/469] [D loss: 0.655996] [G loss: 1.183249]\n",
            "[Epoch 99/200] [Batch 200/469] [D loss: 0.116912] [G loss: 1.041215]\n",
            "[Epoch 99/200] [Batch 250/469] [D loss: 0.061444] [G loss: 1.331569]\n",
            "[Epoch 99/200] [Batch 300/469] [D loss: 0.176354] [G loss: 3.328915]\n",
            "[Epoch 99/200] [Batch 350/469] [D loss: 0.923883] [G loss: 4.343780]\n",
            "[Epoch 99/200] [Batch 400/469] [D loss: 0.236070] [G loss: 2.855078]\n",
            "[Epoch 99/200] [Batch 450/469] [D loss: 0.300623] [G loss: 0.662851]\n",
            "[Epoch 100/200] [Batch 0/469] [D loss: 0.521391] [G loss: 0.753697]\n",
            "[Epoch 100/200] [Batch 50/469] [D loss: 0.244292] [G loss: 1.794757]\n",
            "[Epoch 100/200] [Batch 100/469] [D loss: 0.125867] [G loss: 1.928042]\n",
            "[Epoch 100/200] [Batch 150/469] [D loss: 0.710548] [G loss: 1.316636]\n",
            "[Epoch 100/200] [Batch 200/469] [D loss: 0.532820] [G loss: 0.068205]\n",
            "[Epoch 100/200] [Batch 250/469] [D loss: 0.561801] [G loss: 0.410822]\n",
            "[Epoch 100/200] [Batch 300/469] [D loss: 0.086118] [G loss: 2.005064]\n",
            "[Epoch 100/200] [Batch 350/469] [D loss: 1.135031] [G loss: 4.287901]\n",
            "[Epoch 100/200] [Batch 400/469] [D loss: 0.309319] [G loss: 0.411095]\n",
            "[Epoch 100/200] [Batch 450/469] [D loss: 0.491113] [G loss: 3.223509]\n",
            "[Epoch 101/200] [Batch 0/469] [D loss: 0.457031] [G loss: 0.407240]\n",
            "[Epoch 101/200] [Batch 50/469] [D loss: 0.033934] [G loss: 2.313543]\n",
            "[Epoch 101/200] [Batch 100/469] [D loss: 0.134842] [G loss: 2.088717]\n",
            "[Epoch 101/200] [Batch 150/469] [D loss: 0.144978] [G loss: 1.794463]\n",
            "[Epoch 101/200] [Batch 200/469] [D loss: 0.391412] [G loss: 3.664509]\n",
            "[Epoch 101/200] [Batch 250/469] [D loss: 0.118776] [G loss: 2.567895]\n",
            "[Epoch 101/200] [Batch 300/469] [D loss: 0.509519] [G loss: 0.237204]\n",
            "[Epoch 101/200] [Batch 350/469] [D loss: 1.130909] [G loss: 2.483000]\n",
            "[Epoch 101/200] [Batch 400/469] [D loss: 0.090402] [G loss: 3.255508]\n",
            "[Epoch 101/200] [Batch 450/469] [D loss: 0.258774] [G loss: 2.667650]\n",
            "[Epoch 102/200] [Batch 0/469] [D loss: 0.082605] [G loss: 2.094911]\n",
            "[Epoch 102/200] [Batch 50/469] [D loss: 0.055449] [G loss: 3.441399]\n",
            "[Epoch 102/200] [Batch 100/469] [D loss: 0.264544] [G loss: 2.107512]\n",
            "[Epoch 102/200] [Batch 150/469] [D loss: 0.243686] [G loss: 1.257907]\n",
            "[Epoch 102/200] [Batch 200/469] [D loss: 0.178149] [G loss: 1.430296]\n",
            "[Epoch 102/200] [Batch 250/469] [D loss: 0.102291] [G loss: 3.635980]\n",
            "[Epoch 102/200] [Batch 300/469] [D loss: 1.581978] [G loss: 0.021846]\n",
            "[Epoch 102/200] [Batch 350/469] [D loss: 0.499029] [G loss: 0.128209]\n",
            "[Epoch 102/200] [Batch 400/469] [D loss: 0.699609] [G loss: 4.358202]\n",
            "[Epoch 102/200] [Batch 450/469] [D loss: 0.496949] [G loss: 2.468214]\n",
            "[Epoch 103/200] [Batch 0/469] [D loss: 0.162169] [G loss: 1.545520]\n",
            "[Epoch 103/200] [Batch 50/469] [D loss: 0.139281] [G loss: 2.496983]\n",
            "[Epoch 103/200] [Batch 100/469] [D loss: 0.917488] [G loss: 1.380285]\n",
            "[Epoch 103/200] [Batch 150/469] [D loss: 0.224260] [G loss: 3.791705]\n",
            "[Epoch 103/200] [Batch 200/469] [D loss: 0.689777] [G loss: 1.688698]\n",
            "[Epoch 103/200] [Batch 250/469] [D loss: 0.107340] [G loss: 2.458100]\n",
            "[Epoch 103/200] [Batch 300/469] [D loss: 0.781000] [G loss: 2.029746]\n",
            "[Epoch 103/200] [Batch 350/469] [D loss: 0.506679] [G loss: 3.222867]\n",
            "[Epoch 103/200] [Batch 400/469] [D loss: 0.239536] [G loss: 2.857467]\n",
            "[Epoch 103/200] [Batch 450/469] [D loss: 0.280977] [G loss: 2.125620]\n",
            "[Epoch 104/200] [Batch 0/469] [D loss: 0.639604] [G loss: 0.299083]\n",
            "[Epoch 104/200] [Batch 50/469] [D loss: 0.362189] [G loss: 1.516712]\n",
            "[Epoch 104/200] [Batch 100/469] [D loss: 0.441643] [G loss: 1.180767]\n",
            "[Epoch 104/200] [Batch 150/469] [D loss: 0.250253] [G loss: 0.322229]\n",
            "[Epoch 104/200] [Batch 200/469] [D loss: 0.963915] [G loss: 0.145326]\n",
            "[Epoch 104/200] [Batch 250/469] [D loss: 1.145265] [G loss: 0.337421]\n",
            "[Epoch 104/200] [Batch 300/469] [D loss: 1.046067] [G loss: 0.420478]\n",
            "[Epoch 104/200] [Batch 350/469] [D loss: 0.324590] [G loss: 1.025344]\n",
            "[Epoch 104/200] [Batch 400/469] [D loss: 0.233552] [G loss: 3.914553]\n",
            "[Epoch 104/200] [Batch 450/469] [D loss: 0.255019] [G loss: 4.588516]\n",
            "[Epoch 105/200] [Batch 0/469] [D loss: 0.337375] [G loss: 0.085450]\n",
            "[Epoch 105/200] [Batch 50/469] [D loss: 0.156782] [G loss: 3.842323]\n",
            "[Epoch 105/200] [Batch 100/469] [D loss: 0.574684] [G loss: 1.290843]\n",
            "[Epoch 105/200] [Batch 150/469] [D loss: 0.519884] [G loss: 1.000440]\n",
            "[Epoch 105/200] [Batch 200/469] [D loss: 0.578410] [G loss: 0.153395]\n",
            "[Epoch 105/200] [Batch 250/469] [D loss: 0.198548] [G loss: 3.195290]\n",
            "[Epoch 105/200] [Batch 300/469] [D loss: 0.292550] [G loss: 2.363280]\n",
            "[Epoch 105/200] [Batch 350/469] [D loss: 0.502242] [G loss: 2.418632]\n",
            "[Epoch 105/200] [Batch 400/469] [D loss: 0.079121] [G loss: 2.181565]\n",
            "[Epoch 105/200] [Batch 450/469] [D loss: 1.045237] [G loss: 0.391236]\n",
            "[Epoch 106/200] [Batch 0/469] [D loss: 0.417955] [G loss: 0.466233]\n",
            "[Epoch 106/200] [Batch 50/469] [D loss: 0.818551] [G loss: 0.226043]\n",
            "[Epoch 106/200] [Batch 100/469] [D loss: 0.334901] [G loss: 0.634847]\n",
            "[Epoch 106/200] [Batch 150/469] [D loss: 0.556418] [G loss: 1.080732]\n",
            "[Epoch 106/200] [Batch 200/469] [D loss: 0.247044] [G loss: 3.154390]\n",
            "[Epoch 106/200] [Batch 250/469] [D loss: 1.344176] [G loss: 3.434058]\n",
            "[Epoch 106/200] [Batch 300/469] [D loss: 0.088213] [G loss: 2.140079]\n",
            "[Epoch 106/200] [Batch 350/469] [D loss: 0.186151] [G loss: 1.100177]\n",
            "[Epoch 106/200] [Batch 400/469] [D loss: 0.151196] [G loss: 2.039737]\n",
            "[Epoch 106/200] [Batch 450/469] [D loss: 0.700259] [G loss: 1.775265]\n",
            "[Epoch 107/200] [Batch 0/469] [D loss: 0.208815] [G loss: 1.670499]\n",
            "[Epoch 107/200] [Batch 50/469] [D loss: 0.018218] [G loss: 4.193536]\n",
            "[Epoch 107/200] [Batch 100/469] [D loss: 0.626413] [G loss: 2.543684]\n",
            "[Epoch 107/200] [Batch 150/469] [D loss: 1.166572] [G loss: 0.259879]\n",
            "[Epoch 107/200] [Batch 200/469] [D loss: 0.224228] [G loss: 2.195555]\n",
            "[Epoch 107/200] [Batch 250/469] [D loss: 0.242595] [G loss: 1.420659]\n",
            "[Epoch 107/200] [Batch 300/469] [D loss: 0.124854] [G loss: 2.400269]\n",
            "[Epoch 107/200] [Batch 350/469] [D loss: 0.744706] [G loss: 1.500098]\n",
            "[Epoch 107/200] [Batch 400/469] [D loss: 0.079076] [G loss: 3.892247]\n",
            "[Epoch 107/200] [Batch 450/469] [D loss: 0.333089] [G loss: 2.304087]\n",
            "[Epoch 108/200] [Batch 0/469] [D loss: 0.144272] [G loss: 0.686073]\n",
            "[Epoch 108/200] [Batch 50/469] [D loss: 0.618694] [G loss: 4.704230]\n",
            "[Epoch 108/200] [Batch 100/469] [D loss: 0.560617] [G loss: 0.883715]\n",
            "[Epoch 108/200] [Batch 150/469] [D loss: 1.418963] [G loss: 0.294531]\n",
            "[Epoch 108/200] [Batch 200/469] [D loss: 0.100994] [G loss: 2.696207]\n",
            "[Epoch 108/200] [Batch 250/469] [D loss: 0.460664] [G loss: 0.402723]\n",
            "[Epoch 108/200] [Batch 300/469] [D loss: 0.242874] [G loss: 1.063434]\n",
            "[Epoch 108/200] [Batch 350/469] [D loss: 1.104422] [G loss: 1.125017]\n",
            "[Epoch 108/200] [Batch 400/469] [D loss: 0.117837] [G loss: 3.063034]\n",
            "[Epoch 108/200] [Batch 450/469] [D loss: 0.113908] [G loss: 2.990660]\n",
            "[Epoch 109/200] [Batch 0/469] [D loss: 0.633418] [G loss: 4.470245]\n",
            "[Epoch 109/200] [Batch 50/469] [D loss: 0.495427] [G loss: 0.862005]\n",
            "[Epoch 109/200] [Batch 100/469] [D loss: 0.109602] [G loss: 4.611690]\n",
            "[Epoch 109/200] [Batch 150/469] [D loss: 0.176668] [G loss: 3.274779]\n",
            "[Epoch 109/200] [Batch 200/469] [D loss: 0.221746] [G loss: 1.245491]\n",
            "[Epoch 109/200] [Batch 250/469] [D loss: 0.594836] [G loss: 4.923187]\n",
            "[Epoch 109/200] [Batch 300/469] [D loss: 0.363147] [G loss: 1.133178]\n",
            "[Epoch 109/200] [Batch 350/469] [D loss: 0.105012] [G loss: 3.901565]\n",
            "[Epoch 109/200] [Batch 400/469] [D loss: 0.125404] [G loss: 2.852057]\n",
            "[Epoch 109/200] [Batch 450/469] [D loss: 0.080528] [G loss: 1.696793]\n",
            "[Epoch 110/200] [Batch 0/469] [D loss: 0.870054] [G loss: 2.303571]\n",
            "[Epoch 110/200] [Batch 50/469] [D loss: 0.262720] [G loss: 1.814139]\n",
            "[Epoch 110/200] [Batch 100/469] [D loss: 0.293875] [G loss: 1.035119]\n",
            "[Epoch 110/200] [Batch 150/469] [D loss: 0.101571] [G loss: 2.202882]\n",
            "[Epoch 110/200] [Batch 200/469] [D loss: 0.309307] [G loss: 2.094566]\n",
            "[Epoch 110/200] [Batch 250/469] [D loss: 0.324095] [G loss: 1.546159]\n",
            "[Epoch 110/200] [Batch 300/469] [D loss: 0.209243] [G loss: 2.918328]\n",
            "[Epoch 110/200] [Batch 350/469] [D loss: 0.152793] [G loss: 2.389512]\n",
            "[Epoch 110/200] [Batch 400/469] [D loss: 0.487057] [G loss: 0.673688]\n",
            "[Epoch 110/200] [Batch 450/469] [D loss: 0.090332] [G loss: 1.911951]\n",
            "[Epoch 111/200] [Batch 0/469] [D loss: 0.263026] [G loss: 4.308200]\n",
            "[Epoch 111/200] [Batch 50/469] [D loss: 0.526608] [G loss: 4.711114]\n",
            "[Epoch 111/200] [Batch 100/469] [D loss: 0.098906] [G loss: 1.025431]\n",
            "[Epoch 111/200] [Batch 150/469] [D loss: 0.135918] [G loss: 1.615464]\n",
            "[Epoch 111/200] [Batch 200/469] [D loss: 0.411216] [G loss: 1.273261]\n",
            "[Epoch 111/200] [Batch 250/469] [D loss: 0.202096] [G loss: 0.633861]\n",
            "[Epoch 111/200] [Batch 300/469] [D loss: 0.148053] [G loss: 1.635396]\n",
            "[Epoch 111/200] [Batch 350/469] [D loss: 0.020629] [G loss: 2.534856]\n",
            "[Epoch 111/200] [Batch 400/469] [D loss: 1.517715] [G loss: 0.612316]\n",
            "[Epoch 111/200] [Batch 450/469] [D loss: 1.241089] [G loss: 2.323739]\n",
            "[Epoch 112/200] [Batch 0/469] [D loss: 0.158988] [G loss: 1.270507]\n",
            "[Epoch 112/200] [Batch 50/469] [D loss: 0.612351] [G loss: 1.326866]\n",
            "[Epoch 112/200] [Batch 100/469] [D loss: 0.238690] [G loss: 3.371042]\n",
            "[Epoch 112/200] [Batch 150/469] [D loss: 0.318341] [G loss: 4.738662]\n",
            "[Epoch 112/200] [Batch 200/469] [D loss: 0.169259] [G loss: 2.964646]\n",
            "[Epoch 112/200] [Batch 250/469] [D loss: 0.260764] [G loss: 1.221955]\n",
            "[Epoch 112/200] [Batch 300/469] [D loss: 0.280820] [G loss: 2.620382]\n",
            "[Epoch 112/200] [Batch 350/469] [D loss: 0.079924] [G loss: 1.073497]\n",
            "[Epoch 112/200] [Batch 400/469] [D loss: 0.370999] [G loss: 0.799661]\n",
            "[Epoch 112/200] [Batch 450/469] [D loss: 0.363381] [G loss: 1.038717]\n",
            "[Epoch 113/200] [Batch 0/469] [D loss: 0.162125] [G loss: 2.494368]\n",
            "[Epoch 113/200] [Batch 50/469] [D loss: 0.491179] [G loss: 0.489863]\n",
            "[Epoch 113/200] [Batch 100/469] [D loss: 0.337216] [G loss: 0.891431]\n",
            "[Epoch 113/200] [Batch 150/469] [D loss: 0.707782] [G loss: 2.307472]\n",
            "[Epoch 113/200] [Batch 200/469] [D loss: 0.106064] [G loss: 1.810598]\n",
            "[Epoch 113/200] [Batch 250/469] [D loss: 0.207199] [G loss: 2.501872]\n",
            "[Epoch 113/200] [Batch 300/469] [D loss: 0.038659] [G loss: 2.047403]\n",
            "[Epoch 113/200] [Batch 350/469] [D loss: 0.078775] [G loss: 2.539837]\n",
            "[Epoch 113/200] [Batch 400/469] [D loss: 0.116869] [G loss: 3.206519]\n",
            "[Epoch 113/200] [Batch 450/469] [D loss: 0.497857] [G loss: 0.865513]\n",
            "[Epoch 114/200] [Batch 0/469] [D loss: 0.166541] [G loss: 4.132360]\n",
            "[Epoch 114/200] [Batch 50/469] [D loss: 0.163180] [G loss: 3.390500]\n",
            "[Epoch 114/200] [Batch 100/469] [D loss: 0.156901] [G loss: 3.708132]\n",
            "[Epoch 114/200] [Batch 150/469] [D loss: 0.069291] [G loss: 1.159111]\n",
            "[Epoch 114/200] [Batch 200/469] [D loss: 0.213280] [G loss: 1.662561]\n",
            "[Epoch 114/200] [Batch 250/469] [D loss: 0.363964] [G loss: 3.468775]\n",
            "[Epoch 114/200] [Batch 300/469] [D loss: 0.389874] [G loss: 2.998650]\n",
            "[Epoch 114/200] [Batch 350/469] [D loss: 0.491890] [G loss: 0.196030]\n",
            "[Epoch 114/200] [Batch 400/469] [D loss: 0.092159] [G loss: 3.395355]\n",
            "[Epoch 114/200] [Batch 450/469] [D loss: 0.053711] [G loss: 3.027896]\n",
            "[Epoch 115/200] [Batch 0/469] [D loss: 0.662073] [G loss: 1.630399]\n",
            "[Epoch 115/200] [Batch 50/469] [D loss: 0.820443] [G loss: 3.543654]\n",
            "[Epoch 115/200] [Batch 100/469] [D loss: 0.419672] [G loss: 2.603154]\n",
            "[Epoch 115/200] [Batch 150/469] [D loss: 0.541414] [G loss: 2.198239]\n",
            "[Epoch 115/200] [Batch 200/469] [D loss: 0.388871] [G loss: 0.540378]\n",
            "[Epoch 115/200] [Batch 250/469] [D loss: 0.814404] [G loss: 0.129021]\n",
            "[Epoch 115/200] [Batch 300/469] [D loss: 0.335798] [G loss: 1.385745]\n",
            "[Epoch 115/200] [Batch 350/469] [D loss: 0.523369] [G loss: 0.639649]\n",
            "[Epoch 115/200] [Batch 400/469] [D loss: 0.056474] [G loss: 3.557805]\n",
            "[Epoch 115/200] [Batch 450/469] [D loss: 0.757740] [G loss: 0.475703]\n",
            "[Epoch 116/200] [Batch 0/469] [D loss: 1.217450] [G loss: 0.989748]\n",
            "[Epoch 116/200] [Batch 50/469] [D loss: 0.150515] [G loss: 0.835437]\n",
            "[Epoch 116/200] [Batch 100/469] [D loss: 0.203993] [G loss: 2.440264]\n",
            "[Epoch 116/200] [Batch 150/469] [D loss: 0.675905] [G loss: 2.115370]\n",
            "[Epoch 116/200] [Batch 200/469] [D loss: 0.254084] [G loss: 2.242572]\n",
            "[Epoch 116/200] [Batch 250/469] [D loss: 1.175139] [G loss: 3.335779]\n",
            "[Epoch 116/200] [Batch 300/469] [D loss: 0.071378] [G loss: 3.765801]\n",
            "[Epoch 116/200] [Batch 350/469] [D loss: 0.876292] [G loss: 5.540320]\n",
            "[Epoch 116/200] [Batch 400/469] [D loss: 0.131560] [G loss: 0.760415]\n",
            "[Epoch 116/200] [Batch 450/469] [D loss: 0.247825] [G loss: 0.276099]\n",
            "[Epoch 117/200] [Batch 0/469] [D loss: 0.450218] [G loss: 0.703691]\n",
            "[Epoch 117/200] [Batch 50/469] [D loss: 1.855525] [G loss: 5.715256]\n",
            "[Epoch 117/200] [Batch 100/469] [D loss: 0.403285] [G loss: 1.045993]\n",
            "[Epoch 117/200] [Batch 150/469] [D loss: 0.035138] [G loss: 1.910900]\n",
            "[Epoch 117/200] [Batch 200/469] [D loss: 0.407748] [G loss: 3.331447]\n",
            "[Epoch 117/200] [Batch 250/469] [D loss: 0.722467] [G loss: 3.420560]\n",
            "[Epoch 117/200] [Batch 300/469] [D loss: 0.208657] [G loss: 0.932042]\n",
            "[Epoch 117/200] [Batch 350/469] [D loss: 0.316449] [G loss: 0.438006]\n",
            "[Epoch 117/200] [Batch 400/469] [D loss: 0.409965] [G loss: 0.482084]\n",
            "[Epoch 117/200] [Batch 450/469] [D loss: 0.601085] [G loss: 0.460581]\n",
            "[Epoch 118/200] [Batch 0/469] [D loss: 0.649767] [G loss: 0.600175]\n",
            "[Epoch 118/200] [Batch 50/469] [D loss: 0.249193] [G loss: 2.602895]\n",
            "[Epoch 118/200] [Batch 100/469] [D loss: 0.150882] [G loss: 1.983330]\n",
            "[Epoch 118/200] [Batch 150/469] [D loss: 0.454539] [G loss: 1.258236]\n",
            "[Epoch 118/200] [Batch 200/469] [D loss: 0.057750] [G loss: 2.321001]\n",
            "[Epoch 118/200] [Batch 250/469] [D loss: 0.204340] [G loss: 2.046762]\n",
            "[Epoch 118/200] [Batch 300/469] [D loss: 0.162459] [G loss: 2.512529]\n",
            "[Epoch 118/200] [Batch 350/469] [D loss: 0.038749] [G loss: 4.618146]\n",
            "[Epoch 118/200] [Batch 400/469] [D loss: 0.451911] [G loss: 2.876372]\n",
            "[Epoch 118/200] [Batch 450/469] [D loss: 0.649894] [G loss: 1.043960]\n",
            "[Epoch 119/200] [Batch 0/469] [D loss: 0.188723] [G loss: 3.430314]\n",
            "[Epoch 119/200] [Batch 50/469] [D loss: 0.150535] [G loss: 1.727436]\n",
            "[Epoch 119/200] [Batch 100/469] [D loss: 0.215239] [G loss: 2.944219]\n",
            "[Epoch 119/200] [Batch 150/469] [D loss: 0.463913] [G loss: 1.643613]\n",
            "[Epoch 119/200] [Batch 200/469] [D loss: 0.234319] [G loss: 3.571539]\n",
            "[Epoch 119/200] [Batch 250/469] [D loss: 0.310967] [G loss: 1.945639]\n",
            "[Epoch 119/200] [Batch 300/469] [D loss: 0.296286] [G loss: 0.570431]\n",
            "[Epoch 119/200] [Batch 350/469] [D loss: 0.049108] [G loss: 1.630787]\n",
            "[Epoch 119/200] [Batch 400/469] [D loss: 0.310599] [G loss: 2.155953]\n",
            "[Epoch 119/200] [Batch 450/469] [D loss: 0.251542] [G loss: 1.597814]\n",
            "[Epoch 120/200] [Batch 0/469] [D loss: 0.256904] [G loss: 1.401944]\n",
            "[Epoch 120/200] [Batch 50/469] [D loss: 0.112485] [G loss: 2.365627]\n",
            "[Epoch 120/200] [Batch 100/469] [D loss: 0.127195] [G loss: 0.329839]\n",
            "[Epoch 120/200] [Batch 150/469] [D loss: 0.111103] [G loss: 2.029586]\n",
            "[Epoch 120/200] [Batch 200/469] [D loss: 0.183293] [G loss: 3.219981]\n",
            "[Epoch 120/200] [Batch 250/469] [D loss: 0.180252] [G loss: 5.347458]\n",
            "[Epoch 120/200] [Batch 300/469] [D loss: 0.252080] [G loss: 0.834281]\n",
            "[Epoch 120/200] [Batch 350/469] [D loss: 0.468136] [G loss: 0.402349]\n",
            "[Epoch 120/200] [Batch 400/469] [D loss: 0.122582] [G loss: 2.501353]\n",
            "[Epoch 120/200] [Batch 450/469] [D loss: 0.177470] [G loss: 3.004576]\n",
            "[Epoch 121/200] [Batch 0/469] [D loss: 0.446731] [G loss: 0.583123]\n",
            "[Epoch 121/200] [Batch 50/469] [D loss: 0.511765] [G loss: 1.705421]\n",
            "[Epoch 121/200] [Batch 100/469] [D loss: 0.110155] [G loss: 1.448187]\n",
            "[Epoch 121/200] [Batch 150/469] [D loss: 0.040942] [G loss: 3.407912]\n",
            "[Epoch 121/200] [Batch 200/469] [D loss: 0.179247] [G loss: 2.548282]\n",
            "[Epoch 121/200] [Batch 250/469] [D loss: 0.139107] [G loss: 2.931303]\n",
            "[Epoch 121/200] [Batch 300/469] [D loss: 0.228295] [G loss: 0.737203]\n",
            "[Epoch 121/200] [Batch 350/469] [D loss: 0.933559] [G loss: 1.484043]\n",
            "[Epoch 121/200] [Batch 400/469] [D loss: 0.033704] [G loss: 3.303240]\n",
            "[Epoch 121/200] [Batch 450/469] [D loss: 0.707857] [G loss: 3.329736]\n",
            "[Epoch 122/200] [Batch 0/469] [D loss: 0.204470] [G loss: 2.476288]\n",
            "[Epoch 122/200] [Batch 50/469] [D loss: 0.215324] [G loss: 3.234057]\n",
            "[Epoch 122/200] [Batch 100/469] [D loss: 1.125249] [G loss: 0.209103]\n",
            "[Epoch 122/200] [Batch 150/469] [D loss: 0.119796] [G loss: 2.222047]\n",
            "[Epoch 122/200] [Batch 200/469] [D loss: 0.270964] [G loss: 1.319299]\n",
            "[Epoch 122/200] [Batch 250/469] [D loss: 0.723237] [G loss: 1.614732]\n",
            "[Epoch 122/200] [Batch 300/469] [D loss: 0.276536] [G loss: 4.636765]\n",
            "[Epoch 122/200] [Batch 350/469] [D loss: 0.272100] [G loss: 2.202725]\n",
            "[Epoch 122/200] [Batch 400/469] [D loss: 0.190122] [G loss: 2.584858]\n",
            "[Epoch 122/200] [Batch 450/469] [D loss: 0.139215] [G loss: 3.206940]\n",
            "[Epoch 123/200] [Batch 0/469] [D loss: 0.482286] [G loss: 0.529282]\n",
            "[Epoch 123/200] [Batch 50/469] [D loss: 0.136142] [G loss: 1.889514]\n",
            "[Epoch 123/200] [Batch 100/469] [D loss: 0.378447] [G loss: 0.389884]\n",
            "[Epoch 123/200] [Batch 150/469] [D loss: 1.186564] [G loss: 4.026759]\n",
            "[Epoch 123/200] [Batch 200/469] [D loss: 0.127545] [G loss: 2.274018]\n",
            "[Epoch 123/200] [Batch 250/469] [D loss: 0.864495] [G loss: 2.639854]\n",
            "[Epoch 123/200] [Batch 300/469] [D loss: 0.135426] [G loss: 3.144314]\n",
            "[Epoch 123/200] [Batch 350/469] [D loss: 1.357167] [G loss: 0.526045]\n",
            "[Epoch 123/200] [Batch 400/469] [D loss: 0.205499] [G loss: 3.842978]\n",
            "[Epoch 123/200] [Batch 450/469] [D loss: 1.253372] [G loss: 0.458612]\n",
            "[Epoch 124/200] [Batch 0/469] [D loss: 0.334064] [G loss: 0.497624]\n",
            "[Epoch 124/200] [Batch 50/469] [D loss: 0.195124] [G loss: 2.991831]\n",
            "[Epoch 124/200] [Batch 100/469] [D loss: 0.399323] [G loss: 1.965470]\n",
            "[Epoch 124/200] [Batch 150/469] [D loss: 0.213758] [G loss: 1.810208]\n",
            "[Epoch 124/200] [Batch 200/469] [D loss: 0.158756] [G loss: 3.395253]\n",
            "[Epoch 124/200] [Batch 250/469] [D loss: 0.052551] [G loss: 1.335734]\n",
            "[Epoch 124/200] [Batch 300/469] [D loss: 0.164267] [G loss: 1.718401]\n",
            "[Epoch 124/200] [Batch 350/469] [D loss: 0.830132] [G loss: 0.481529]\n",
            "[Epoch 124/200] [Batch 400/469] [D loss: 0.235530] [G loss: 0.830117]\n",
            "[Epoch 124/200] [Batch 450/469] [D loss: 0.086106] [G loss: 3.155887]\n",
            "[Epoch 125/200] [Batch 0/469] [D loss: 0.309554] [G loss: 2.018994]\n",
            "[Epoch 125/200] [Batch 50/469] [D loss: 0.065955] [G loss: 3.348555]\n",
            "[Epoch 125/200] [Batch 100/469] [D loss: 0.372122] [G loss: 3.746228]\n",
            "[Epoch 125/200] [Batch 150/469] [D loss: 0.219294] [G loss: 4.510421]\n",
            "[Epoch 125/200] [Batch 200/469] [D loss: 0.236205] [G loss: 1.459382]\n",
            "[Epoch 125/200] [Batch 250/469] [D loss: 0.443357] [G loss: 0.175023]\n",
            "[Epoch 125/200] [Batch 300/469] [D loss: 0.450892] [G loss: 1.323909]\n",
            "[Epoch 125/200] [Batch 350/469] [D loss: 0.447253] [G loss: 1.158825]\n",
            "[Epoch 125/200] [Batch 400/469] [D loss: 0.088059] [G loss: 2.313192]\n",
            "[Epoch 125/200] [Batch 450/469] [D loss: 0.241363] [G loss: 1.557148]\n",
            "[Epoch 126/200] [Batch 0/469] [D loss: 0.226781] [G loss: 0.557168]\n",
            "[Epoch 126/200] [Batch 50/469] [D loss: 0.340794] [G loss: 0.870084]\n",
            "[Epoch 126/200] [Batch 100/469] [D loss: 0.761891] [G loss: 1.359545]\n",
            "[Epoch 126/200] [Batch 150/469] [D loss: 0.640513] [G loss: 5.091002]\n",
            "[Epoch 126/200] [Batch 200/469] [D loss: 0.143241] [G loss: 0.988303]\n",
            "[Epoch 126/200] [Batch 250/469] [D loss: 0.114412] [G loss: 1.710668]\n",
            "[Epoch 126/200] [Batch 300/469] [D loss: 0.299879] [G loss: 4.843108]\n",
            "[Epoch 126/200] [Batch 350/469] [D loss: 0.042972] [G loss: 3.246117]\n",
            "[Epoch 126/200] [Batch 400/469] [D loss: 0.119903] [G loss: 2.208070]\n",
            "[Epoch 126/200] [Batch 450/469] [D loss: 0.056698] [G loss: 2.602526]\n",
            "[Epoch 127/200] [Batch 0/469] [D loss: 0.214385] [G loss: 2.281771]\n",
            "[Epoch 127/200] [Batch 50/469] [D loss: 0.067526] [G loss: 5.201949]\n",
            "[Epoch 127/200] [Batch 100/469] [D loss: 0.231228] [G loss: 0.751952]\n",
            "[Epoch 127/200] [Batch 150/469] [D loss: 0.066102] [G loss: 2.990747]\n",
            "[Epoch 127/200] [Batch 200/469] [D loss: 0.248713] [G loss: 1.355673]\n",
            "[Epoch 127/200] [Batch 250/469] [D loss: 0.501417] [G loss: 1.098397]\n",
            "[Epoch 127/200] [Batch 300/469] [D loss: 0.059560] [G loss: 2.449132]\n",
            "[Epoch 127/200] [Batch 350/469] [D loss: 0.135722] [G loss: 2.398801]\n",
            "[Epoch 127/200] [Batch 400/469] [D loss: 0.522025] [G loss: 4.429630]\n",
            "[Epoch 127/200] [Batch 450/469] [D loss: 0.064124] [G loss: 5.199745]\n",
            "[Epoch 128/200] [Batch 0/469] [D loss: 0.229928] [G loss: 1.518065]\n",
            "[Epoch 128/200] [Batch 50/469] [D loss: 0.355861] [G loss: 3.807665]\n",
            "[Epoch 128/200] [Batch 100/469] [D loss: 0.173326] [G loss: 2.631798]\n",
            "[Epoch 128/200] [Batch 150/469] [D loss: 0.429971] [G loss: 1.036820]\n",
            "[Epoch 128/200] [Batch 200/469] [D loss: 0.410417] [G loss: 2.220593]\n",
            "[Epoch 128/200] [Batch 250/469] [D loss: 0.294498] [G loss: 5.819654]\n",
            "[Epoch 128/200] [Batch 300/469] [D loss: 0.094468] [G loss: 1.253693]\n",
            "[Epoch 128/200] [Batch 350/469] [D loss: 0.394741] [G loss: 3.994259]\n",
            "[Epoch 128/200] [Batch 400/469] [D loss: 0.220592] [G loss: 2.499317]\n",
            "[Epoch 128/200] [Batch 450/469] [D loss: 0.008900] [G loss: 4.194798]\n",
            "[Epoch 129/200] [Batch 0/469] [D loss: 0.311053] [G loss: 2.058018]\n",
            "[Epoch 129/200] [Batch 50/469] [D loss: 0.142523] [G loss: 3.099882]\n",
            "[Epoch 129/200] [Batch 100/469] [D loss: 0.117378] [G loss: 3.008787]\n",
            "[Epoch 129/200] [Batch 150/469] [D loss: 0.120888] [G loss: 2.534357]\n",
            "[Epoch 129/200] [Batch 200/469] [D loss: 0.162172] [G loss: 1.795167]\n",
            "[Epoch 129/200] [Batch 250/469] [D loss: 0.642094] [G loss: 2.258271]\n",
            "[Epoch 129/200] [Batch 300/469] [D loss: 0.829741] [G loss: 0.130413]\n",
            "[Epoch 129/200] [Batch 350/469] [D loss: 0.740428] [G loss: 1.901362]\n",
            "[Epoch 129/200] [Batch 400/469] [D loss: 0.067143] [G loss: 5.648448]\n",
            "[Epoch 129/200] [Batch 450/469] [D loss: 0.230042] [G loss: 1.416154]\n",
            "[Epoch 130/200] [Batch 0/469] [D loss: 0.072200] [G loss: 1.925875]\n",
            "[Epoch 130/200] [Batch 50/469] [D loss: 0.088168] [G loss: 1.159029]\n",
            "[Epoch 130/200] [Batch 100/469] [D loss: 1.030528] [G loss: 0.571678]\n",
            "[Epoch 130/200] [Batch 150/469] [D loss: 0.063421] [G loss: 2.164918]\n",
            "[Epoch 130/200] [Batch 200/469] [D loss: 0.821858] [G loss: 2.800274]\n",
            "[Epoch 130/200] [Batch 250/469] [D loss: 0.158634] [G loss: 2.911176]\n",
            "[Epoch 130/200] [Batch 300/469] [D loss: 0.174064] [G loss: 2.983545]\n",
            "[Epoch 130/200] [Batch 350/469] [D loss: 0.325843] [G loss: 1.439060]\n",
            "[Epoch 130/200] [Batch 400/469] [D loss: 0.398267] [G loss: 1.329067]\n",
            "[Epoch 130/200] [Batch 450/469] [D loss: 0.144498] [G loss: 1.225630]\n",
            "[Epoch 131/200] [Batch 0/469] [D loss: 0.131078] [G loss: 2.377605]\n",
            "[Epoch 131/200] [Batch 50/469] [D loss: 0.153590] [G loss: 2.180915]\n",
            "[Epoch 131/200] [Batch 100/469] [D loss: 0.378632] [G loss: 2.813964]\n",
            "[Epoch 131/200] [Batch 150/469] [D loss: 0.456087] [G loss: 1.551880]\n",
            "[Epoch 131/200] [Batch 200/469] [D loss: 0.312180] [G loss: 1.358064]\n",
            "[Epoch 131/200] [Batch 250/469] [D loss: 0.099864] [G loss: 1.762602]\n",
            "[Epoch 131/200] [Batch 300/469] [D loss: 0.154376] [G loss: 0.983249]\n",
            "[Epoch 131/200] [Batch 350/469] [D loss: 0.172818] [G loss: 1.582125]\n",
            "[Epoch 131/200] [Batch 400/469] [D loss: 0.391851] [G loss: 2.759155]\n",
            "[Epoch 131/200] [Batch 450/469] [D loss: 0.527816] [G loss: 3.694612]\n",
            "[Epoch 132/200] [Batch 0/469] [D loss: 0.125026] [G loss: 1.478784]\n",
            "[Epoch 132/200] [Batch 50/469] [D loss: 0.072106] [G loss: 3.321218]\n",
            "[Epoch 132/200] [Batch 100/469] [D loss: 0.517986] [G loss: 0.318758]\n",
            "[Epoch 132/200] [Batch 150/469] [D loss: 0.117969] [G loss: 2.030792]\n",
            "[Epoch 132/200] [Batch 200/469] [D loss: 0.666235] [G loss: 2.546825]\n",
            "[Epoch 132/200] [Batch 250/469] [D loss: 0.208210] [G loss: 3.331898]\n",
            "[Epoch 132/200] [Batch 300/469] [D loss: 0.047653] [G loss: 2.294430]\n",
            "[Epoch 132/200] [Batch 350/469] [D loss: 0.207714] [G loss: 3.988878]\n",
            "[Epoch 132/200] [Batch 400/469] [D loss: 0.239511] [G loss: 0.459137]\n",
            "[Epoch 132/200] [Batch 450/469] [D loss: 0.360022] [G loss: 2.206588]\n",
            "[Epoch 133/200] [Batch 0/469] [D loss: 0.218136] [G loss: 1.862873]\n",
            "[Epoch 133/200] [Batch 50/469] [D loss: 1.113201] [G loss: 4.885612]\n",
            "[Epoch 133/200] [Batch 100/469] [D loss: 0.169649] [G loss: 0.397419]\n",
            "[Epoch 133/200] [Batch 150/469] [D loss: 0.098161] [G loss: 3.427190]\n",
            "[Epoch 133/200] [Batch 200/469] [D loss: 0.367513] [G loss: 0.214693]\n",
            "[Epoch 133/200] [Batch 250/469] [D loss: 0.042977] [G loss: 4.062971]\n",
            "[Epoch 133/200] [Batch 300/469] [D loss: 0.165331] [G loss: 2.188688]\n",
            "[Epoch 133/200] [Batch 350/469] [D loss: 0.440461] [G loss: 3.505412]\n",
            "[Epoch 133/200] [Batch 400/469] [D loss: 0.110342] [G loss: 3.529161]\n",
            "[Epoch 133/200] [Batch 450/469] [D loss: 0.304498] [G loss: 1.165259]\n",
            "[Epoch 134/200] [Batch 0/469] [D loss: 0.257838] [G loss: 0.786433]\n",
            "[Epoch 134/200] [Batch 50/469] [D loss: 0.041248] [G loss: 3.481418]\n",
            "[Epoch 134/200] [Batch 100/469] [D loss: 0.062116] [G loss: 4.703870]\n",
            "[Epoch 134/200] [Batch 150/469] [D loss: 0.162227] [G loss: 1.630127]\n",
            "[Epoch 134/200] [Batch 200/469] [D loss: 0.187043] [G loss: 3.396523]\n",
            "[Epoch 134/200] [Batch 250/469] [D loss: 0.205310] [G loss: 1.706692]\n",
            "[Epoch 134/200] [Batch 300/469] [D loss: 0.276599] [G loss: 3.966282]\n",
            "[Epoch 134/200] [Batch 350/469] [D loss: 0.070977] [G loss: 4.509511]\n",
            "[Epoch 134/200] [Batch 400/469] [D loss: 0.177288] [G loss: 1.173431]\n",
            "[Epoch 134/200] [Batch 450/469] [D loss: 0.316491] [G loss: 4.842016]\n",
            "[Epoch 135/200] [Batch 0/469] [D loss: 0.049810] [G loss: 4.780487]\n",
            "[Epoch 135/200] [Batch 50/469] [D loss: 0.166597] [G loss: 3.118656]\n",
            "[Epoch 135/200] [Batch 100/469] [D loss: 0.147082] [G loss: 4.628695]\n",
            "[Epoch 135/200] [Batch 150/469] [D loss: 0.039877] [G loss: 2.113908]\n",
            "[Epoch 135/200] [Batch 200/469] [D loss: 0.128511] [G loss: 2.577672]\n",
            "[Epoch 135/200] [Batch 250/469] [D loss: 0.157100] [G loss: 1.760734]\n",
            "[Epoch 135/200] [Batch 300/469] [D loss: 0.170200] [G loss: 3.743276]\n",
            "[Epoch 135/200] [Batch 350/469] [D loss: 0.226421] [G loss: 1.805687]\n",
            "[Epoch 135/200] [Batch 400/469] [D loss: 0.186744] [G loss: 5.106955]\n",
            "[Epoch 135/200] [Batch 450/469] [D loss: 0.131351] [G loss: 1.985818]\n",
            "[Epoch 136/200] [Batch 0/469] [D loss: 0.130898] [G loss: 3.852692]\n",
            "[Epoch 136/200] [Batch 50/469] [D loss: 0.451723] [G loss: 0.669371]\n",
            "[Epoch 136/200] [Batch 100/469] [D loss: 0.226668] [G loss: 3.781981]\n",
            "[Epoch 136/200] [Batch 150/469] [D loss: 0.225199] [G loss: 1.882090]\n",
            "[Epoch 136/200] [Batch 200/469] [D loss: 0.420967] [G loss: 1.487357]\n",
            "[Epoch 136/200] [Batch 250/469] [D loss: 0.396581] [G loss: 1.674614]\n",
            "[Epoch 136/200] [Batch 300/469] [D loss: 0.414723] [G loss: 3.229957]\n",
            "[Epoch 136/200] [Batch 350/469] [D loss: 0.184931] [G loss: 0.928739]\n",
            "[Epoch 136/200] [Batch 400/469] [D loss: 0.091925] [G loss: 1.449414]\n",
            "[Epoch 136/200] [Batch 450/469] [D loss: 0.140126] [G loss: 1.133577]\n",
            "[Epoch 137/200] [Batch 0/469] [D loss: 0.075652] [G loss: 2.374200]\n",
            "[Epoch 137/200] [Batch 50/469] [D loss: 0.126438] [G loss: 2.279474]\n",
            "[Epoch 137/200] [Batch 100/469] [D loss: 1.104242] [G loss: 0.259420]\n",
            "[Epoch 137/200] [Batch 150/469] [D loss: 0.442337] [G loss: 0.910902]\n",
            "[Epoch 137/200] [Batch 200/469] [D loss: 0.160188] [G loss: 1.323390]\n",
            "[Epoch 137/200] [Batch 250/469] [D loss: 0.744599] [G loss: 1.233305]\n",
            "[Epoch 137/200] [Batch 300/469] [D loss: 0.421067] [G loss: 0.899452]\n",
            "[Epoch 137/200] [Batch 350/469] [D loss: 0.703980] [G loss: 1.678947]\n",
            "[Epoch 137/200] [Batch 400/469] [D loss: 0.339556] [G loss: 6.532589]\n",
            "[Epoch 137/200] [Batch 450/469] [D loss: 0.262662] [G loss: 2.865564]\n",
            "[Epoch 138/200] [Batch 0/469] [D loss: 0.208882] [G loss: 2.609211]\n",
            "[Epoch 138/200] [Batch 50/469] [D loss: 0.182730] [G loss: 1.905971]\n",
            "[Epoch 138/200] [Batch 100/469] [D loss: 0.081771] [G loss: 2.611844]\n",
            "[Epoch 138/200] [Batch 150/469] [D loss: 0.063824] [G loss: 2.178351]\n",
            "[Epoch 138/200] [Batch 200/469] [D loss: 0.766151] [G loss: 0.649505]\n",
            "[Epoch 138/200] [Batch 250/469] [D loss: 0.232172] [G loss: 1.737423]\n",
            "[Epoch 138/200] [Batch 300/469] [D loss: 0.560894] [G loss: 3.111313]\n",
            "[Epoch 138/200] [Batch 350/469] [D loss: 1.510576] [G loss: 5.252821]\n",
            "[Epoch 138/200] [Batch 400/469] [D loss: 0.041239] [G loss: 1.333382]\n",
            "[Epoch 138/200] [Batch 450/469] [D loss: 0.541808] [G loss: 3.409858]\n",
            "[Epoch 139/200] [Batch 0/469] [D loss: 0.149925] [G loss: 1.809922]\n",
            "[Epoch 139/200] [Batch 50/469] [D loss: 0.073453] [G loss: 2.765345]\n",
            "[Epoch 139/200] [Batch 100/469] [D loss: 0.321864] [G loss: 2.844690]\n",
            "[Epoch 139/200] [Batch 150/469] [D loss: 0.025619] [G loss: 3.050678]\n",
            "[Epoch 139/200] [Batch 200/469] [D loss: 0.110247] [G loss: 0.177988]\n",
            "[Epoch 139/200] [Batch 250/469] [D loss: 0.118311] [G loss: 2.337690]\n",
            "[Epoch 139/200] [Batch 300/469] [D loss: 0.069257] [G loss: 2.204703]\n",
            "[Epoch 139/200] [Batch 350/469] [D loss: 0.431328] [G loss: 0.347790]\n",
            "[Epoch 139/200] [Batch 400/469] [D loss: 0.543369] [G loss: 2.387185]\n",
            "[Epoch 139/200] [Batch 450/469] [D loss: 0.159307] [G loss: 1.741233]\n",
            "[Epoch 140/200] [Batch 0/469] [D loss: 0.461408] [G loss: 2.490217]\n",
            "[Epoch 140/200] [Batch 50/469] [D loss: 0.192411] [G loss: 1.819911]\n",
            "[Epoch 140/200] [Batch 100/469] [D loss: 0.199148] [G loss: 3.941291]\n",
            "[Epoch 140/200] [Batch 150/469] [D loss: 0.039404] [G loss: 1.822132]\n",
            "[Epoch 140/200] [Batch 200/469] [D loss: 0.057253] [G loss: 4.679916]\n",
            "[Epoch 140/200] [Batch 250/469] [D loss: 0.446391] [G loss: 3.077036]\n",
            "[Epoch 140/200] [Batch 300/469] [D loss: 0.216878] [G loss: 1.594897]\n",
            "[Epoch 140/200] [Batch 350/469] [D loss: 0.439391] [G loss: 1.685144]\n",
            "[Epoch 140/200] [Batch 400/469] [D loss: 0.125684] [G loss: 1.812615]\n",
            "[Epoch 140/200] [Batch 450/469] [D loss: 0.201997] [G loss: 2.394582]\n",
            "[Epoch 141/200] [Batch 0/469] [D loss: 0.228834] [G loss: 0.743251]\n",
            "[Epoch 141/200] [Batch 50/469] [D loss: 0.136097] [G loss: 2.506929]\n",
            "[Epoch 141/200] [Batch 100/469] [D loss: 0.472150] [G loss: 2.809857]\n",
            "[Epoch 141/200] [Batch 150/469] [D loss: 0.415413] [G loss: 1.320988]\n",
            "[Epoch 141/200] [Batch 200/469] [D loss: 0.325312] [G loss: 1.008690]\n",
            "[Epoch 141/200] [Batch 250/469] [D loss: 0.083252] [G loss: 2.040957]\n",
            "[Epoch 141/200] [Batch 300/469] [D loss: 0.811464] [G loss: 3.492321]\n",
            "[Epoch 141/200] [Batch 350/469] [D loss: 0.213356] [G loss: 0.695777]\n",
            "[Epoch 141/200] [Batch 400/469] [D loss: 0.433933] [G loss: 2.484652]\n",
            "[Epoch 141/200] [Batch 450/469] [D loss: 0.739682] [G loss: 1.756049]\n",
            "[Epoch 142/200] [Batch 0/469] [D loss: 0.035290] [G loss: 3.696322]\n",
            "[Epoch 142/200] [Batch 50/469] [D loss: 0.051577] [G loss: 1.360023]\n",
            "[Epoch 142/200] [Batch 100/469] [D loss: 0.162581] [G loss: 0.869940]\n",
            "[Epoch 142/200] [Batch 150/469] [D loss: 0.162487] [G loss: 2.090561]\n",
            "[Epoch 142/200] [Batch 200/469] [D loss: 0.037681] [G loss: 3.306901]\n",
            "[Epoch 142/200] [Batch 250/469] [D loss: 0.484322] [G loss: 2.515272]\n",
            "[Epoch 142/200] [Batch 300/469] [D loss: 0.131824] [G loss: 1.197300]\n",
            "[Epoch 142/200] [Batch 350/469] [D loss: 0.056056] [G loss: 1.865595]\n",
            "[Epoch 142/200] [Batch 400/469] [D loss: 0.592571] [G loss: 0.921135]\n",
            "[Epoch 142/200] [Batch 450/469] [D loss: 0.478341] [G loss: 3.022472]\n",
            "[Epoch 143/200] [Batch 0/469] [D loss: 0.398045] [G loss: 4.408440]\n",
            "[Epoch 143/200] [Batch 50/469] [D loss: 0.097026] [G loss: 3.415513]\n",
            "[Epoch 143/200] [Batch 100/469] [D loss: 0.439769] [G loss: 1.984764]\n",
            "[Epoch 143/200] [Batch 150/469] [D loss: 0.144875] [G loss: 1.450565]\n",
            "[Epoch 143/200] [Batch 200/469] [D loss: 0.173287] [G loss: 2.768465]\n",
            "[Epoch 143/200] [Batch 250/469] [D loss: 0.020208] [G loss: 4.452430]\n",
            "[Epoch 143/200] [Batch 300/469] [D loss: 0.026519] [G loss: 1.202752]\n",
            "[Epoch 143/200] [Batch 350/469] [D loss: 0.025223] [G loss: 4.539491]\n",
            "[Epoch 143/200] [Batch 400/469] [D loss: 0.355433] [G loss: 4.197380]\n",
            "[Epoch 143/200] [Batch 450/469] [D loss: 0.266867] [G loss: 3.718000]\n",
            "[Epoch 144/200] [Batch 0/469] [D loss: 0.169445] [G loss: 5.333568]\n",
            "[Epoch 144/200] [Batch 50/469] [D loss: 0.110952] [G loss: 2.930393]\n",
            "[Epoch 144/200] [Batch 100/469] [D loss: 0.713052] [G loss: 2.575831]\n",
            "[Epoch 144/200] [Batch 150/469] [D loss: 0.013382] [G loss: 3.476328]\n",
            "[Epoch 144/200] [Batch 200/469] [D loss: 0.144986] [G loss: 2.334167]\n",
            "[Epoch 144/200] [Batch 250/469] [D loss: 0.061780] [G loss: 2.570155]\n",
            "[Epoch 144/200] [Batch 300/469] [D loss: 0.081827] [G loss: 3.553426]\n",
            "[Epoch 144/200] [Batch 350/469] [D loss: 0.062484] [G loss: 3.352431]\n",
            "[Epoch 144/200] [Batch 400/469] [D loss: 0.275828] [G loss: 0.588778]\n",
            "[Epoch 144/200] [Batch 450/469] [D loss: 0.321133] [G loss: 2.709227]\n",
            "[Epoch 145/200] [Batch 0/469] [D loss: 0.240509] [G loss: 1.435925]\n",
            "[Epoch 145/200] [Batch 50/469] [D loss: 0.079225] [G loss: 1.143579]\n",
            "[Epoch 145/200] [Batch 100/469] [D loss: 0.289658] [G loss: 2.582334]\n",
            "[Epoch 145/200] [Batch 150/469] [D loss: 0.048083] [G loss: 1.885332]\n",
            "[Epoch 145/200] [Batch 200/469] [D loss: 0.565054] [G loss: 0.388134]\n",
            "[Epoch 145/200] [Batch 250/469] [D loss: 0.039708] [G loss: 2.391299]\n",
            "[Epoch 145/200] [Batch 300/469] [D loss: 0.023852] [G loss: 4.849546]\n",
            "[Epoch 145/200] [Batch 350/469] [D loss: 0.666564] [G loss: 0.211670]\n",
            "[Epoch 145/200] [Batch 400/469] [D loss: 0.936426] [G loss: 1.788416]\n",
            "[Epoch 145/200] [Batch 450/469] [D loss: 0.199365] [G loss: 1.255579]\n",
            "[Epoch 146/200] [Batch 0/469] [D loss: 0.853180] [G loss: 1.374265]\n",
            "[Epoch 146/200] [Batch 50/469] [D loss: 0.600050] [G loss: 0.185543]\n",
            "[Epoch 146/200] [Batch 100/469] [D loss: 0.149135] [G loss: 1.353098]\n",
            "[Epoch 146/200] [Batch 150/469] [D loss: 0.623819] [G loss: 5.945890]\n",
            "[Epoch 146/200] [Batch 200/469] [D loss: 0.039967] [G loss: 3.514664]\n",
            "[Epoch 146/200] [Batch 250/469] [D loss: 0.019964] [G loss: 2.393129]\n",
            "[Epoch 146/200] [Batch 300/469] [D loss: 0.447852] [G loss: 3.147270]\n",
            "[Epoch 146/200] [Batch 350/469] [D loss: 0.349827] [G loss: 1.977257]\n",
            "[Epoch 146/200] [Batch 400/469] [D loss: 0.199197] [G loss: 2.896458]\n",
            "[Epoch 146/200] [Batch 450/469] [D loss: 0.338293] [G loss: 1.348942]\n",
            "[Epoch 147/200] [Batch 0/469] [D loss: 0.188012] [G loss: 2.479993]\n",
            "[Epoch 147/200] [Batch 50/469] [D loss: 0.467530] [G loss: 2.529130]\n",
            "[Epoch 147/200] [Batch 100/469] [D loss: 0.139863] [G loss: 2.681899]\n",
            "[Epoch 147/200] [Batch 150/469] [D loss: 0.085149] [G loss: 1.067943]\n",
            "[Epoch 147/200] [Batch 200/469] [D loss: 0.354591] [G loss: 1.829053]\n",
            "[Epoch 147/200] [Batch 250/469] [D loss: 0.791907] [G loss: 0.039174]\n",
            "[Epoch 147/200] [Batch 300/469] [D loss: 0.199868] [G loss: 1.156335]\n",
            "[Epoch 147/200] [Batch 350/469] [D loss: 0.234047] [G loss: 0.841536]\n",
            "[Epoch 147/200] [Batch 400/469] [D loss: 0.240169] [G loss: 1.990637]\n",
            "[Epoch 147/200] [Batch 450/469] [D loss: 0.400807] [G loss: 1.997445]\n",
            "[Epoch 148/200] [Batch 0/469] [D loss: 1.904499] [G loss: 0.018845]\n",
            "[Epoch 148/200] [Batch 50/469] [D loss: 0.034143] [G loss: 2.996809]\n",
            "[Epoch 148/200] [Batch 100/469] [D loss: 0.609642] [G loss: 3.651240]\n",
            "[Epoch 148/200] [Batch 150/469] [D loss: 0.064408] [G loss: 2.327655]\n",
            "[Epoch 148/200] [Batch 200/469] [D loss: 0.040716] [G loss: 1.625067]\n",
            "[Epoch 148/200] [Batch 250/469] [D loss: 1.418786] [G loss: 3.486920]\n",
            "[Epoch 148/200] [Batch 300/469] [D loss: 0.143205] [G loss: 2.083052]\n",
            "[Epoch 148/200] [Batch 350/469] [D loss: 0.332310] [G loss: 2.054886]\n",
            "[Epoch 148/200] [Batch 400/469] [D loss: 0.056211] [G loss: 2.355006]\n",
            "[Epoch 148/200] [Batch 450/469] [D loss: 0.164542] [G loss: 3.628082]\n",
            "[Epoch 149/200] [Batch 0/469] [D loss: 0.450245] [G loss: 0.505077]\n",
            "[Epoch 149/200] [Batch 50/469] [D loss: 0.860387] [G loss: 0.963977]\n",
            "[Epoch 149/200] [Batch 100/469] [D loss: 0.626572] [G loss: 0.450985]\n",
            "[Epoch 149/200] [Batch 150/469] [D loss: 0.026235] [G loss: 3.891357]\n",
            "[Epoch 149/200] [Batch 200/469] [D loss: 0.070121] [G loss: 1.264390]\n",
            "[Epoch 149/200] [Batch 250/469] [D loss: 0.077012] [G loss: 0.638682]\n",
            "[Epoch 149/200] [Batch 300/469] [D loss: 0.323286] [G loss: 1.382302]\n",
            "[Epoch 149/200] [Batch 350/469] [D loss: 0.012268] [G loss: 5.212064]\n",
            "[Epoch 149/200] [Batch 400/469] [D loss: 0.038324] [G loss: 3.785420]\n",
            "[Epoch 149/200] [Batch 450/469] [D loss: 0.725132] [G loss: 0.060832]\n",
            "[Epoch 150/200] [Batch 0/469] [D loss: 0.152916] [G loss: 1.743140]\n",
            "[Epoch 150/200] [Batch 50/469] [D loss: 0.107778] [G loss: 2.755846]\n",
            "[Epoch 150/200] [Batch 100/469] [D loss: 0.089183] [G loss: 2.880502]\n",
            "[Epoch 150/200] [Batch 150/469] [D loss: 0.697129] [G loss: 0.625430]\n",
            "[Epoch 150/200] [Batch 200/469] [D loss: 0.288564] [G loss: 0.855754]\n",
            "[Epoch 150/200] [Batch 250/469] [D loss: 0.108880] [G loss: 1.785061]\n",
            "[Epoch 150/200] [Batch 300/469] [D loss: 0.446340] [G loss: 2.462747]\n",
            "[Epoch 150/200] [Batch 350/469] [D loss: 0.429796] [G loss: 1.927637]\n",
            "[Epoch 150/200] [Batch 400/469] [D loss: 0.032514] [G loss: 1.928242]\n",
            "[Epoch 150/200] [Batch 450/469] [D loss: 1.106029] [G loss: 3.445017]\n",
            "[Epoch 151/200] [Batch 0/469] [D loss: 0.194184] [G loss: 2.818841]\n",
            "[Epoch 151/200] [Batch 50/469] [D loss: 0.351267] [G loss: 1.528889]\n",
            "[Epoch 151/200] [Batch 100/469] [D loss: 0.042870] [G loss: 2.513292]\n",
            "[Epoch 151/200] [Batch 150/469] [D loss: 0.136784] [G loss: 1.908723]\n",
            "[Epoch 151/200] [Batch 200/469] [D loss: 0.381457] [G loss: 1.597531]\n",
            "[Epoch 151/200] [Batch 250/469] [D loss: 0.784027] [G loss: 1.481502]\n",
            "[Epoch 151/200] [Batch 300/469] [D loss: 0.069754] [G loss: 3.927765]\n",
            "[Epoch 151/200] [Batch 350/469] [D loss: 0.494810] [G loss: 4.462986]\n",
            "[Epoch 151/200] [Batch 400/469] [D loss: 0.059332] [G loss: 3.638218]\n",
            "[Epoch 151/200] [Batch 450/469] [D loss: 0.658591] [G loss: 1.681085]\n",
            "[Epoch 152/200] [Batch 0/469] [D loss: 0.393959] [G loss: 1.501706]\n",
            "[Epoch 152/200] [Batch 50/469] [D loss: 0.065285] [G loss: 1.985638]\n",
            "[Epoch 152/200] [Batch 100/469] [D loss: 0.421653] [G loss: 3.117619]\n",
            "[Epoch 152/200] [Batch 150/469] [D loss: 0.156157] [G loss: 3.998698]\n",
            "[Epoch 152/200] [Batch 200/469] [D loss: 0.354255] [G loss: 4.231027]\n",
            "[Epoch 152/200] [Batch 250/469] [D loss: 0.240664] [G loss: 0.792738]\n",
            "[Epoch 152/200] [Batch 300/469] [D loss: 0.081604] [G loss: 2.888437]\n",
            "[Epoch 152/200] [Batch 350/469] [D loss: 0.082894] [G loss: 2.607065]\n",
            "[Epoch 152/200] [Batch 400/469] [D loss: 0.188575] [G loss: 2.983039]\n",
            "[Epoch 152/200] [Batch 450/469] [D loss: 0.587106] [G loss: 3.163880]\n",
            "[Epoch 153/200] [Batch 0/469] [D loss: 0.177643] [G loss: 3.084032]\n",
            "[Epoch 153/200] [Batch 50/469] [D loss: 0.622028] [G loss: 0.621368]\n",
            "[Epoch 153/200] [Batch 100/469] [D loss: 0.079478] [G loss: 2.781552]\n",
            "[Epoch 153/200] [Batch 150/469] [D loss: 0.127948] [G loss: 2.018688]\n",
            "[Epoch 153/200] [Batch 200/469] [D loss: 0.164741] [G loss: 0.500394]\n",
            "[Epoch 153/200] [Batch 250/469] [D loss: 0.141722] [G loss: 0.649225]\n",
            "[Epoch 153/200] [Batch 300/469] [D loss: 0.155561] [G loss: 4.746923]\n",
            "[Epoch 153/200] [Batch 350/469] [D loss: 0.666535] [G loss: 5.135346]\n",
            "[Epoch 153/200] [Batch 400/469] [D loss: 0.039791] [G loss: 1.714081]\n",
            "[Epoch 153/200] [Batch 450/469] [D loss: 0.081128] [G loss: 3.308486]\n",
            "[Epoch 154/200] [Batch 0/469] [D loss: 0.157397] [G loss: 1.225791]\n",
            "[Epoch 154/200] [Batch 50/469] [D loss: 0.080476] [G loss: 2.160536]\n",
            "[Epoch 154/200] [Batch 100/469] [D loss: 0.202407] [G loss: 2.346390]\n",
            "[Epoch 154/200] [Batch 150/469] [D loss: 0.461994] [G loss: 0.974144]\n",
            "[Epoch 154/200] [Batch 200/469] [D loss: 0.426408] [G loss: 2.600368]\n",
            "[Epoch 154/200] [Batch 250/469] [D loss: 0.152084] [G loss: 6.493304]\n",
            "[Epoch 154/200] [Batch 300/469] [D loss: 0.085456] [G loss: 1.685497]\n",
            "[Epoch 154/200] [Batch 350/469] [D loss: 0.114909] [G loss: 2.566697]\n",
            "[Epoch 154/200] [Batch 400/469] [D loss: 0.147192] [G loss: 2.249222]\n",
            "[Epoch 154/200] [Batch 450/469] [D loss: 1.241504] [G loss: 3.109045]\n",
            "[Epoch 155/200] [Batch 0/469] [D loss: 0.141817] [G loss: 1.806744]\n",
            "[Epoch 155/200] [Batch 50/469] [D loss: 0.049950] [G loss: 4.641318]\n",
            "[Epoch 155/200] [Batch 100/469] [D loss: 0.216387] [G loss: 0.818878]\n",
            "[Epoch 155/200] [Batch 150/469] [D loss: 0.667417] [G loss: 0.741326]\n",
            "[Epoch 155/200] [Batch 200/469] [D loss: 0.462475] [G loss: 2.736696]\n",
            "[Epoch 155/200] [Batch 250/469] [D loss: 0.423738] [G loss: 0.720418]\n",
            "[Epoch 155/200] [Batch 300/469] [D loss: 0.049425] [G loss: 2.028586]\n",
            "[Epoch 155/200] [Batch 350/469] [D loss: 1.019303] [G loss: 1.167952]\n",
            "[Epoch 155/200] [Batch 400/469] [D loss: 0.051693] [G loss: 2.420012]\n",
            "[Epoch 155/200] [Batch 450/469] [D loss: 0.283615] [G loss: 3.638500]\n",
            "[Epoch 156/200] [Batch 0/469] [D loss: 0.350263] [G loss: 1.878215]\n",
            "[Epoch 156/200] [Batch 50/469] [D loss: 0.697680] [G loss: 0.158817]\n",
            "[Epoch 156/200] [Batch 100/469] [D loss: 0.047838] [G loss: 3.136981]\n",
            "[Epoch 156/200] [Batch 150/469] [D loss: 0.283646] [G loss: 1.578480]\n",
            "[Epoch 156/200] [Batch 200/469] [D loss: 0.413647] [G loss: 0.970619]\n",
            "[Epoch 156/200] [Batch 250/469] [D loss: 0.138395] [G loss: 3.941221]\n",
            "[Epoch 156/200] [Batch 300/469] [D loss: 0.579325] [G loss: 0.332612]\n",
            "[Epoch 156/200] [Batch 350/469] [D loss: 0.092408] [G loss: 3.308280]\n",
            "[Epoch 156/200] [Batch 400/469] [D loss: 0.186887] [G loss: 1.656833]\n",
            "[Epoch 156/200] [Batch 450/469] [D loss: 0.226506] [G loss: 0.591082]\n",
            "[Epoch 157/200] [Batch 0/469] [D loss: 0.296614] [G loss: 1.666759]\n",
            "[Epoch 157/200] [Batch 50/469] [D loss: 0.266712] [G loss: 2.708544]\n",
            "[Epoch 157/200] [Batch 100/469] [D loss: 0.033566] [G loss: 4.237853]\n",
            "[Epoch 157/200] [Batch 150/469] [D loss: 0.995685] [G loss: 0.459089]\n",
            "[Epoch 157/200] [Batch 200/469] [D loss: 0.327297] [G loss: 2.118932]\n",
            "[Epoch 157/200] [Batch 250/469] [D loss: 0.170058] [G loss: 1.401231]\n",
            "[Epoch 157/200] [Batch 300/469] [D loss: 0.162955] [G loss: 4.182941]\n",
            "[Epoch 157/200] [Batch 350/469] [D loss: 1.120817] [G loss: 4.569274]\n",
            "[Epoch 157/200] [Batch 400/469] [D loss: 0.784619] [G loss: 0.276211]\n",
            "[Epoch 157/200] [Batch 450/469] [D loss: 0.755060] [G loss: 1.959919]\n",
            "[Epoch 158/200] [Batch 0/469] [D loss: 0.189328] [G loss: 2.202732]\n",
            "[Epoch 158/200] [Batch 50/469] [D loss: 0.013052] [G loss: 4.522324]\n",
            "[Epoch 158/200] [Batch 100/469] [D loss: 0.068132] [G loss: 2.131603]\n",
            "[Epoch 158/200] [Batch 150/469] [D loss: 0.093439] [G loss: 1.532253]\n",
            "[Epoch 158/200] [Batch 200/469] [D loss: 0.460245] [G loss: 0.741929]\n",
            "[Epoch 158/200] [Batch 250/469] [D loss: 1.094995] [G loss: 0.066385]\n",
            "[Epoch 158/200] [Batch 300/469] [D loss: 0.242407] [G loss: 1.067005]\n",
            "[Epoch 158/200] [Batch 350/469] [D loss: 0.089574] [G loss: 2.699670]\n",
            "[Epoch 158/200] [Batch 400/469] [D loss: 0.559327] [G loss: 0.485566]\n",
            "[Epoch 158/200] [Batch 450/469] [D loss: 0.031793] [G loss: 2.731969]\n",
            "[Epoch 159/200] [Batch 0/469] [D loss: 0.135054] [G loss: 1.022653]\n",
            "[Epoch 159/200] [Batch 50/469] [D loss: 0.396130] [G loss: 1.853791]\n",
            "[Epoch 159/200] [Batch 100/469] [D loss: 0.369088] [G loss: 0.502684]\n",
            "[Epoch 159/200] [Batch 150/469] [D loss: 0.341196] [G loss: 1.487657]\n",
            "[Epoch 159/200] [Batch 200/469] [D loss: 0.198117] [G loss: 2.339061]\n",
            "[Epoch 159/200] [Batch 250/469] [D loss: 0.228292] [G loss: 4.480200]\n",
            "[Epoch 159/200] [Batch 300/469] [D loss: 0.232278] [G loss: 0.317888]\n",
            "[Epoch 159/200] [Batch 350/469] [D loss: 0.027270] [G loss: 2.064673]\n",
            "[Epoch 159/200] [Batch 400/469] [D loss: 0.506057] [G loss: 0.515398]\n",
            "[Epoch 159/200] [Batch 450/469] [D loss: 0.044078] [G loss: 2.456190]\n",
            "[Epoch 160/200] [Batch 0/469] [D loss: 0.231760] [G loss: 1.347969]\n",
            "[Epoch 160/200] [Batch 50/469] [D loss: 0.139220] [G loss: 1.564653]\n",
            "[Epoch 160/200] [Batch 100/469] [D loss: 0.040023] [G loss: 4.480270]\n",
            "[Epoch 160/200] [Batch 150/469] [D loss: 0.139516] [G loss: 2.177666]\n",
            "[Epoch 160/200] [Batch 200/469] [D loss: 0.161790] [G loss: 2.115610]\n",
            "[Epoch 160/200] [Batch 250/469] [D loss: 0.077509] [G loss: 1.500026]\n",
            "[Epoch 160/200] [Batch 300/469] [D loss: 0.207747] [G loss: 1.217381]\n",
            "[Epoch 160/200] [Batch 350/469] [D loss: 0.041498] [G loss: 1.704042]\n",
            "[Epoch 160/200] [Batch 400/469] [D loss: 0.369134] [G loss: 0.054753]\n",
            "[Epoch 160/200] [Batch 450/469] [D loss: 0.047622] [G loss: 5.123051]\n",
            "[Epoch 161/200] [Batch 0/469] [D loss: 0.156362] [G loss: 0.853457]\n",
            "[Epoch 161/200] [Batch 50/469] [D loss: 0.357364] [G loss: 4.035096]\n",
            "[Epoch 161/200] [Batch 100/469] [D loss: 0.274569] [G loss: 2.294662]\n",
            "[Epoch 161/200] [Batch 150/469] [D loss: 0.274141] [G loss: 2.651862]\n",
            "[Epoch 161/200] [Batch 200/469] [D loss: 0.037608] [G loss: 1.020288]\n",
            "[Epoch 161/200] [Batch 250/469] [D loss: 0.233690] [G loss: 3.466154]\n",
            "[Epoch 161/200] [Batch 300/469] [D loss: 0.727103] [G loss: 0.647219]\n",
            "[Epoch 161/200] [Batch 350/469] [D loss: 0.166329] [G loss: 3.470886]\n",
            "[Epoch 161/200] [Batch 400/469] [D loss: 0.298206] [G loss: 1.814230]\n",
            "[Epoch 161/200] [Batch 450/469] [D loss: 0.514076] [G loss: 3.676136]\n",
            "[Epoch 162/200] [Batch 0/469] [D loss: 0.275097] [G loss: 2.910367]\n",
            "[Epoch 162/200] [Batch 50/469] [D loss: 0.032312] [G loss: 1.631662]\n",
            "[Epoch 162/200] [Batch 100/469] [D loss: 0.710621] [G loss: 4.142898]\n",
            "[Epoch 162/200] [Batch 150/469] [D loss: 0.211295] [G loss: 3.753052]\n",
            "[Epoch 162/200] [Batch 200/469] [D loss: 0.109554] [G loss: 3.279255]\n",
            "[Epoch 162/200] [Batch 250/469] [D loss: 0.453410] [G loss: 3.884687]\n",
            "[Epoch 162/200] [Batch 300/469] [D loss: 0.178399] [G loss: 1.668353]\n",
            "[Epoch 162/200] [Batch 350/469] [D loss: 0.219712] [G loss: 0.583110]\n",
            "[Epoch 162/200] [Batch 400/469] [D loss: 0.115249] [G loss: 4.671975]\n",
            "[Epoch 162/200] [Batch 450/469] [D loss: 0.743066] [G loss: 0.248103]\n",
            "[Epoch 163/200] [Batch 0/469] [D loss: 0.199774] [G loss: 0.876652]\n",
            "[Epoch 163/200] [Batch 50/469] [D loss: 0.264822] [G loss: 2.159533]\n",
            "[Epoch 163/200] [Batch 100/469] [D loss: 0.583846] [G loss: 1.404575]\n",
            "[Epoch 163/200] [Batch 150/469] [D loss: 0.156301] [G loss: 1.146619]\n",
            "[Epoch 163/200] [Batch 200/469] [D loss: 0.304324] [G loss: 0.832612]\n",
            "[Epoch 163/200] [Batch 250/469] [D loss: 0.236052] [G loss: 3.253877]\n",
            "[Epoch 163/200] [Batch 300/469] [D loss: 1.477851] [G loss: 0.253683]\n",
            "[Epoch 163/200] [Batch 350/469] [D loss: 0.106726] [G loss: 0.548971]\n",
            "[Epoch 163/200] [Batch 400/469] [D loss: 0.047042] [G loss: 1.280190]\n",
            "[Epoch 163/200] [Batch 450/469] [D loss: 1.142235] [G loss: 2.227266]\n",
            "[Epoch 164/200] [Batch 0/469] [D loss: 0.029986] [G loss: 2.511256]\n",
            "[Epoch 164/200] [Batch 50/469] [D loss: 0.155163] [G loss: 2.683370]\n",
            "[Epoch 164/200] [Batch 100/469] [D loss: 0.741519] [G loss: 6.649178]\n",
            "[Epoch 164/200] [Batch 150/469] [D loss: 0.182814] [G loss: 3.921849]\n",
            "[Epoch 164/200] [Batch 200/469] [D loss: 0.086086] [G loss: 5.661067]\n",
            "[Epoch 164/200] [Batch 250/469] [D loss: 0.669227] [G loss: 3.053800]\n",
            "[Epoch 164/200] [Batch 300/469] [D loss: 0.459496] [G loss: 0.516781]\n",
            "[Epoch 164/200] [Batch 350/469] [D loss: 0.240337] [G loss: 0.488091]\n",
            "[Epoch 164/200] [Batch 400/469] [D loss: 0.022949] [G loss: 2.504471]\n",
            "[Epoch 164/200] [Batch 450/469] [D loss: 0.250719] [G loss: 2.194419]\n",
            "[Epoch 165/200] [Batch 0/469] [D loss: 0.064830] [G loss: 0.807471]\n",
            "[Epoch 165/200] [Batch 50/469] [D loss: 0.243218] [G loss: 1.291297]\n",
            "[Epoch 165/200] [Batch 100/469] [D loss: 0.109834] [G loss: 1.969337]\n",
            "[Epoch 165/200] [Batch 150/469] [D loss: 0.054153] [G loss: 2.852409]\n",
            "[Epoch 165/200] [Batch 200/469] [D loss: 0.131065] [G loss: 2.694108]\n",
            "[Epoch 165/200] [Batch 250/469] [D loss: 0.054466] [G loss: 2.903064]\n",
            "[Epoch 165/200] [Batch 300/469] [D loss: 0.036737] [G loss: 3.788337]\n",
            "[Epoch 165/200] [Batch 350/469] [D loss: 0.479854] [G loss: 4.430816]\n",
            "[Epoch 165/200] [Batch 400/469] [D loss: 0.204380] [G loss: 1.803348]\n",
            "[Epoch 165/200] [Batch 450/469] [D loss: 0.427854] [G loss: 3.140206]\n",
            "[Epoch 166/200] [Batch 0/469] [D loss: 0.134958] [G loss: 1.977688]\n",
            "[Epoch 166/200] [Batch 50/469] [D loss: 0.092145] [G loss: 2.187940]\n",
            "[Epoch 166/200] [Batch 100/469] [D loss: 0.102611] [G loss: 1.274185]\n",
            "[Epoch 166/200] [Batch 150/469] [D loss: 0.025766] [G loss: 3.987573]\n",
            "[Epoch 166/200] [Batch 200/469] [D loss: 1.156215] [G loss: 3.332823]\n",
            "[Epoch 166/200] [Batch 250/469] [D loss: 0.537896] [G loss: 4.713962]\n",
            "[Epoch 166/200] [Batch 300/469] [D loss: 0.078357] [G loss: 1.315083]\n",
            "[Epoch 166/200] [Batch 350/469] [D loss: 0.202601] [G loss: 0.229555]\n",
            "[Epoch 166/200] [Batch 400/469] [D loss: 0.584809] [G loss: 1.894826]\n",
            "[Epoch 166/200] [Batch 450/469] [D loss: 0.054007] [G loss: 0.729439]\n",
            "[Epoch 167/200] [Batch 0/469] [D loss: 0.178616] [G loss: 2.117788]\n",
            "[Epoch 167/200] [Batch 50/469] [D loss: 0.128211] [G loss: 2.547918]\n",
            "[Epoch 167/200] [Batch 100/469] [D loss: 0.123295] [G loss: 2.160282]\n",
            "[Epoch 167/200] [Batch 150/469] [D loss: 0.177588] [G loss: 4.054036]\n",
            "[Epoch 167/200] [Batch 200/469] [D loss: 0.109697] [G loss: 2.051694]\n",
            "[Epoch 167/200] [Batch 250/469] [D loss: 0.286160] [G loss: 0.797241]\n",
            "[Epoch 167/200] [Batch 300/469] [D loss: 0.225499] [G loss: 3.026829]\n",
            "[Epoch 167/200] [Batch 350/469] [D loss: 0.032923] [G loss: 1.914091]\n",
            "[Epoch 167/200] [Batch 400/469] [D loss: 0.029020] [G loss: 2.863931]\n",
            "[Epoch 167/200] [Batch 450/469] [D loss: 0.284007] [G loss: 1.341447]\n",
            "[Epoch 168/200] [Batch 0/469] [D loss: 0.650853] [G loss: 4.095531]\n",
            "[Epoch 168/200] [Batch 50/469] [D loss: 0.052009] [G loss: 4.003017]\n",
            "[Epoch 168/200] [Batch 100/469] [D loss: 0.228823] [G loss: 1.376102]\n",
            "[Epoch 168/200] [Batch 150/469] [D loss: 0.229341] [G loss: 2.694035]\n",
            "[Epoch 168/200] [Batch 200/469] [D loss: 0.107370] [G loss: 3.000621]\n",
            "[Epoch 168/200] [Batch 250/469] [D loss: 0.554809] [G loss: 1.068933]\n",
            "[Epoch 168/200] [Batch 300/469] [D loss: 0.180926] [G loss: 1.377296]\n",
            "[Epoch 168/200] [Batch 350/469] [D loss: 0.829207] [G loss: 0.298139]\n",
            "[Epoch 168/200] [Batch 400/469] [D loss: 0.027799] [G loss: 2.410933]\n",
            "[Epoch 168/200] [Batch 450/469] [D loss: 0.122278] [G loss: 4.614931]\n",
            "[Epoch 169/200] [Batch 0/469] [D loss: 0.564396] [G loss: 3.517309]\n",
            "[Epoch 169/200] [Batch 50/469] [D loss: 1.462001] [G loss: 4.285933]\n",
            "[Epoch 169/200] [Batch 100/469] [D loss: 0.012793] [G loss: 3.438725]\n",
            "[Epoch 169/200] [Batch 150/469] [D loss: 0.261315] [G loss: 1.555668]\n",
            "[Epoch 169/200] [Batch 200/469] [D loss: 0.156304] [G loss: 1.605862]\n",
            "[Epoch 169/200] [Batch 250/469] [D loss: 0.370782] [G loss: 2.230139]\n",
            "[Epoch 169/200] [Batch 300/469] [D loss: 0.276877] [G loss: 1.664568]\n",
            "[Epoch 169/200] [Batch 350/469] [D loss: 0.060022] [G loss: 0.931056]\n",
            "[Epoch 169/200] [Batch 400/469] [D loss: 0.349548] [G loss: 0.895084]\n",
            "[Epoch 169/200] [Batch 450/469] [D loss: 0.875316] [G loss: 0.445050]\n",
            "[Epoch 170/200] [Batch 0/469] [D loss: 0.047928] [G loss: 3.895925]\n",
            "[Epoch 170/200] [Batch 50/469] [D loss: 0.370857] [G loss: 0.709588]\n",
            "[Epoch 170/200] [Batch 100/469] [D loss: 0.097302] [G loss: 0.634331]\n",
            "[Epoch 170/200] [Batch 150/469] [D loss: 0.760965] [G loss: 2.280277]\n",
            "[Epoch 170/200] [Batch 200/469] [D loss: 0.028694] [G loss: 2.488272]\n",
            "[Epoch 170/200] [Batch 250/469] [D loss: 0.065799] [G loss: 1.054073]\n",
            "[Epoch 170/200] [Batch 300/469] [D loss: 0.069029] [G loss: 0.306244]\n",
            "[Epoch 170/200] [Batch 350/469] [D loss: 0.268732] [G loss: 3.997819]\n",
            "[Epoch 170/200] [Batch 400/469] [D loss: 0.195097] [G loss: 2.510677]\n",
            "[Epoch 170/200] [Batch 450/469] [D loss: 0.177784] [G loss: 2.690563]\n",
            "[Epoch 171/200] [Batch 0/469] [D loss: 0.251287] [G loss: 3.562395]\n",
            "[Epoch 171/200] [Batch 50/469] [D loss: 0.138838] [G loss: 1.969785]\n",
            "[Epoch 171/200] [Batch 100/469] [D loss: 0.260301] [G loss: 1.884632]\n",
            "[Epoch 171/200] [Batch 150/469] [D loss: 0.181167] [G loss: 3.066960]\n",
            "[Epoch 171/200] [Batch 200/469] [D loss: 0.130223] [G loss: 0.468109]\n",
            "[Epoch 171/200] [Batch 250/469] [D loss: 0.188149] [G loss: 1.311475]\n",
            "[Epoch 171/200] [Batch 300/469] [D loss: 0.085274] [G loss: 3.740348]\n",
            "[Epoch 171/200] [Batch 350/469] [D loss: 0.177553] [G loss: 3.045573]\n",
            "[Epoch 171/200] [Batch 400/469] [D loss: 0.808184] [G loss: 3.637868]\n",
            "[Epoch 171/200] [Batch 450/469] [D loss: 0.174071] [G loss: 1.895184]\n",
            "[Epoch 172/200] [Batch 0/469] [D loss: 0.333177] [G loss: 3.641044]\n",
            "[Epoch 172/200] [Batch 50/469] [D loss: 0.093579] [G loss: 2.054907]\n",
            "[Epoch 172/200] [Batch 100/469] [D loss: 0.029307] [G loss: 6.910844]\n",
            "[Epoch 172/200] [Batch 150/469] [D loss: 0.056267] [G loss: 1.275891]\n",
            "[Epoch 172/200] [Batch 200/469] [D loss: 0.254623] [G loss: 1.297201]\n",
            "[Epoch 172/200] [Batch 250/469] [D loss: 0.701400] [G loss: 0.228043]\n",
            "[Epoch 172/200] [Batch 300/469] [D loss: 0.060233] [G loss: 2.384388]\n",
            "[Epoch 172/200] [Batch 350/469] [D loss: 0.093334] [G loss: 0.859129]\n",
            "[Epoch 172/200] [Batch 400/469] [D loss: 0.515604] [G loss: 3.824845]\n",
            "[Epoch 172/200] [Batch 450/469] [D loss: 1.378505] [G loss: 0.186550]\n",
            "[Epoch 173/200] [Batch 0/469] [D loss: 0.058652] [G loss: 3.374139]\n",
            "[Epoch 173/200] [Batch 50/469] [D loss: 0.215746] [G loss: 2.613546]\n",
            "[Epoch 173/200] [Batch 100/469] [D loss: 0.452676] [G loss: 2.761498]\n",
            "[Epoch 173/200] [Batch 150/469] [D loss: 0.447224] [G loss: 4.545763]\n",
            "[Epoch 173/200] [Batch 200/469] [D loss: 1.015862] [G loss: 2.531219]\n",
            "[Epoch 173/200] [Batch 250/469] [D loss: 0.368535] [G loss: 1.610200]\n",
            "[Epoch 173/200] [Batch 300/469] [D loss: 0.920222] [G loss: 0.196332]\n",
            "[Epoch 173/200] [Batch 350/469] [D loss: 0.201532] [G loss: 3.776641]\n",
            "[Epoch 173/200] [Batch 400/469] [D loss: 0.268041] [G loss: 4.431966]\n",
            "[Epoch 173/200] [Batch 450/469] [D loss: 0.217053] [G loss: 3.200058]\n",
            "[Epoch 174/200] [Batch 0/469] [D loss: 0.089107] [G loss: 2.287071]\n",
            "[Epoch 174/200] [Batch 50/469] [D loss: 0.356660] [G loss: 0.467045]\n",
            "[Epoch 174/200] [Batch 100/469] [D loss: 0.034128] [G loss: 2.471415]\n",
            "[Epoch 174/200] [Batch 150/469] [D loss: 0.246336] [G loss: 2.147862]\n",
            "[Epoch 174/200] [Batch 200/469] [D loss: 0.664830] [G loss: 1.578986]\n",
            "[Epoch 174/200] [Batch 250/469] [D loss: 0.069386] [G loss: 4.088706]\n",
            "[Epoch 174/200] [Batch 300/469] [D loss: 0.449887] [G loss: 0.245937]\n",
            "[Epoch 174/200] [Batch 350/469] [D loss: 0.032036] [G loss: 0.664499]\n",
            "[Epoch 174/200] [Batch 400/469] [D loss: 0.125790] [G loss: 2.010795]\n",
            "[Epoch 174/200] [Batch 450/469] [D loss: 0.049567] [G loss: 2.188457]\n",
            "[Epoch 175/200] [Batch 0/469] [D loss: 0.020475] [G loss: 2.285585]\n",
            "[Epoch 175/200] [Batch 50/469] [D loss: 0.164453] [G loss: 5.348267]\n",
            "[Epoch 175/200] [Batch 100/469] [D loss: 0.038870] [G loss: 2.883728]\n",
            "[Epoch 175/200] [Batch 150/469] [D loss: 0.221060] [G loss: 5.193051]\n",
            "[Epoch 175/200] [Batch 200/469] [D loss: 0.210766] [G loss: 0.244845]\n",
            "[Epoch 175/200] [Batch 250/469] [D loss: 0.196441] [G loss: 1.217866]\n",
            "[Epoch 175/200] [Batch 300/469] [D loss: 0.225567] [G loss: 3.769087]\n",
            "[Epoch 175/200] [Batch 350/469] [D loss: 0.325011] [G loss: 1.125098]\n",
            "[Epoch 175/200] [Batch 400/469] [D loss: 1.234747] [G loss: 0.094206]\n",
            "[Epoch 175/200] [Batch 450/469] [D loss: 0.056471] [G loss: 6.028909]\n",
            "[Epoch 176/200] [Batch 0/469] [D loss: 0.434308] [G loss: 2.423023]\n",
            "[Epoch 176/200] [Batch 50/469] [D loss: 0.029682] [G loss: 2.397397]\n",
            "[Epoch 176/200] [Batch 100/469] [D loss: 0.060964] [G loss: 4.309402]\n",
            "[Epoch 176/200] [Batch 150/469] [D loss: 0.457968] [G loss: 1.272295]\n",
            "[Epoch 176/200] [Batch 200/469] [D loss: 0.935626] [G loss: 0.132996]\n",
            "[Epoch 176/200] [Batch 250/469] [D loss: 0.224207] [G loss: 2.155089]\n",
            "[Epoch 176/200] [Batch 300/469] [D loss: 0.029406] [G loss: 0.758659]\n",
            "[Epoch 176/200] [Batch 350/469] [D loss: 0.396685] [G loss: 4.533244]\n",
            "[Epoch 176/200] [Batch 400/469] [D loss: 0.484893] [G loss: 1.566876]\n",
            "[Epoch 176/200] [Batch 450/469] [D loss: 1.270880] [G loss: 0.759654]\n",
            "[Epoch 177/200] [Batch 0/469] [D loss: 0.308276] [G loss: 3.475893]\n",
            "[Epoch 177/200] [Batch 50/469] [D loss: 0.090956] [G loss: 2.490241]\n",
            "[Epoch 177/200] [Batch 100/469] [D loss: 0.030033] [G loss: 5.754448]\n",
            "[Epoch 177/200] [Batch 150/469] [D loss: 0.051887] [G loss: 4.722764]\n",
            "[Epoch 177/200] [Batch 200/469] [D loss: 0.134768] [G loss: 1.229348]\n",
            "[Epoch 177/200] [Batch 250/469] [D loss: 0.062447] [G loss: 3.439059]\n",
            "[Epoch 177/200] [Batch 300/469] [D loss: 0.076339] [G loss: 3.920894]\n",
            "[Epoch 177/200] [Batch 350/469] [D loss: 0.036240] [G loss: 0.822644]\n",
            "[Epoch 177/200] [Batch 400/469] [D loss: 0.120358] [G loss: 2.112006]\n",
            "[Epoch 177/200] [Batch 450/469] [D loss: 0.013846] [G loss: 5.302445]\n",
            "[Epoch 178/200] [Batch 0/469] [D loss: 0.074794] [G loss: 3.423008]\n",
            "[Epoch 178/200] [Batch 50/469] [D loss: 0.832849] [G loss: 2.204492]\n",
            "[Epoch 178/200] [Batch 100/469] [D loss: 0.163679] [G loss: 0.997732]\n",
            "[Epoch 178/200] [Batch 150/469] [D loss: 0.745874] [G loss: 1.129216]\n",
            "[Epoch 178/200] [Batch 200/469] [D loss: 0.014149] [G loss: 5.693375]\n",
            "[Epoch 178/200] [Batch 250/469] [D loss: 0.071338] [G loss: 2.032219]\n",
            "[Epoch 178/200] [Batch 300/469] [D loss: 0.532452] [G loss: 1.925792]\n",
            "[Epoch 178/200] [Batch 350/469] [D loss: 0.219567] [G loss: 6.337689]\n",
            "[Epoch 178/200] [Batch 400/469] [D loss: 1.014961] [G loss: 0.203522]\n",
            "[Epoch 178/200] [Batch 450/469] [D loss: 0.475727] [G loss: 5.217032]\n",
            "[Epoch 179/200] [Batch 0/469] [D loss: 0.527948] [G loss: 1.232428]\n",
            "[Epoch 179/200] [Batch 50/469] [D loss: 1.183784] [G loss: 3.366158]\n",
            "[Epoch 179/200] [Batch 100/469] [D loss: 0.773129] [G loss: 5.478214]\n",
            "[Epoch 179/200] [Batch 150/469] [D loss: 0.310490] [G loss: 0.733462]\n",
            "[Epoch 179/200] [Batch 200/469] [D loss: 0.154768] [G loss: 3.653154]\n",
            "[Epoch 179/200] [Batch 250/469] [D loss: 0.682689] [G loss: 0.279919]\n",
            "[Epoch 179/200] [Batch 300/469] [D loss: 0.084142] [G loss: 4.973015]\n",
            "[Epoch 179/200] [Batch 350/469] [D loss: 0.106680] [G loss: 3.110543]\n",
            "[Epoch 179/200] [Batch 400/469] [D loss: 0.585922] [G loss: 1.622955]\n",
            "[Epoch 179/200] [Batch 450/469] [D loss: 0.399936] [G loss: 2.000059]\n",
            "[Epoch 180/200] [Batch 0/469] [D loss: 0.313439] [G loss: 1.190556]\n",
            "[Epoch 180/200] [Batch 50/469] [D loss: 0.446072] [G loss: 1.729382]\n",
            "[Epoch 180/200] [Batch 100/469] [D loss: 0.525755] [G loss: 4.239507]\n",
            "[Epoch 180/200] [Batch 150/469] [D loss: 0.063397] [G loss: 4.413162]\n",
            "[Epoch 180/200] [Batch 200/469] [D loss: 0.438922] [G loss: 5.442546]\n",
            "[Epoch 180/200] [Batch 250/469] [D loss: 0.184011] [G loss: 0.285732]\n",
            "[Epoch 180/200] [Batch 300/469] [D loss: 0.051712] [G loss: 1.222129]\n",
            "[Epoch 180/200] [Batch 350/469] [D loss: 0.507059] [G loss: 2.588443]\n",
            "[Epoch 180/200] [Batch 400/469] [D loss: 0.279422] [G loss: 2.649914]\n",
            "[Epoch 180/200] [Batch 450/469] [D loss: 0.295159] [G loss: 4.072026]\n",
            "[Epoch 181/200] [Batch 0/469] [D loss: 1.050477] [G loss: 0.063709]\n",
            "[Epoch 181/200] [Batch 50/469] [D loss: 0.446966] [G loss: 0.226277]\n",
            "[Epoch 181/200] [Batch 100/469] [D loss: 0.043850] [G loss: 0.463553]\n",
            "[Epoch 181/200] [Batch 150/469] [D loss: 0.137891] [G loss: 2.145713]\n",
            "[Epoch 181/200] [Batch 200/469] [D loss: 0.077818] [G loss: 4.645772]\n",
            "[Epoch 181/200] [Batch 250/469] [D loss: 0.026958] [G loss: 3.071843]\n",
            "[Epoch 181/200] [Batch 300/469] [D loss: 0.014386] [G loss: 2.213636]\n",
            "[Epoch 181/200] [Batch 350/469] [D loss: 0.212399] [G loss: 2.453835]\n",
            "[Epoch 181/200] [Batch 400/469] [D loss: 2.235835] [G loss: 0.112784]\n",
            "[Epoch 181/200] [Batch 450/469] [D loss: 0.334424] [G loss: 2.912117]\n",
            "[Epoch 182/200] [Batch 0/469] [D loss: 0.460249] [G loss: 3.439842]\n",
            "[Epoch 182/200] [Batch 50/469] [D loss: 0.133193] [G loss: 2.169929]\n",
            "[Epoch 182/200] [Batch 100/469] [D loss: 1.263942] [G loss: 5.007975]\n",
            "[Epoch 182/200] [Batch 150/469] [D loss: 0.183295] [G loss: 3.791438]\n",
            "[Epoch 182/200] [Batch 200/469] [D loss: 0.020460] [G loss: 2.445719]\n",
            "[Epoch 182/200] [Batch 250/469] [D loss: 0.232020] [G loss: 1.961923]\n",
            "[Epoch 182/200] [Batch 300/469] [D loss: 0.320552] [G loss: 5.664374]\n",
            "[Epoch 182/200] [Batch 350/469] [D loss: 0.038947] [G loss: 4.133233]\n",
            "[Epoch 182/200] [Batch 400/469] [D loss: 0.142729] [G loss: 1.275552]\n",
            "[Epoch 182/200] [Batch 450/469] [D loss: 0.051039] [G loss: 3.126618]\n",
            "[Epoch 183/200] [Batch 0/469] [D loss: 0.173273] [G loss: 4.448312]\n",
            "[Epoch 183/200] [Batch 50/469] [D loss: 0.044046] [G loss: 4.238812]\n",
            "[Epoch 183/200] [Batch 100/469] [D loss: 0.189083] [G loss: 4.060568]\n",
            "[Epoch 183/200] [Batch 150/469] [D loss: 0.278330] [G loss: 2.493884]\n",
            "[Epoch 183/200] [Batch 200/469] [D loss: 0.168005] [G loss: 2.000616]\n",
            "[Epoch 183/200] [Batch 250/469] [D loss: 0.045507] [G loss: 4.835535]\n",
            "[Epoch 183/200] [Batch 300/469] [D loss: 0.086428] [G loss: 5.984680]\n",
            "[Epoch 183/200] [Batch 350/469] [D loss: 0.338403] [G loss: 4.083719]\n",
            "[Epoch 183/200] [Batch 400/469] [D loss: 0.182251] [G loss: 3.716803]\n",
            "[Epoch 183/200] [Batch 450/469] [D loss: 0.445410] [G loss: 3.874102]\n",
            "[Epoch 184/200] [Batch 0/469] [D loss: 0.055823] [G loss: 3.516089]\n",
            "[Epoch 184/200] [Batch 50/469] [D loss: 0.282925] [G loss: 0.143487]\n",
            "[Epoch 184/200] [Batch 100/469] [D loss: 0.106146] [G loss: 3.751509]\n",
            "[Epoch 184/200] [Batch 150/469] [D loss: 0.007590] [G loss: 6.861161]\n",
            "[Epoch 184/200] [Batch 200/469] [D loss: 0.230157] [G loss: 3.481145]\n",
            "[Epoch 184/200] [Batch 250/469] [D loss: 0.260153] [G loss: 4.135906]\n",
            "[Epoch 184/200] [Batch 300/469] [D loss: 0.539831] [G loss: 6.121974]\n",
            "[Epoch 184/200] [Batch 350/469] [D loss: 1.174814] [G loss: 0.404525]\n",
            "[Epoch 184/200] [Batch 400/469] [D loss: 0.028033] [G loss: 3.218721]\n",
            "[Epoch 184/200] [Batch 450/469] [D loss: 0.131798] [G loss: 2.386338]\n",
            "[Epoch 185/200] [Batch 0/469] [D loss: 0.345483] [G loss: 2.734643]\n",
            "[Epoch 185/200] [Batch 50/469] [D loss: 0.414425] [G loss: 2.326302]\n",
            "[Epoch 185/200] [Batch 100/469] [D loss: 0.160604] [G loss: 1.203278]\n",
            "[Epoch 185/200] [Batch 150/469] [D loss: 0.232752] [G loss: 0.883317]\n",
            "[Epoch 185/200] [Batch 200/469] [D loss: 0.125852] [G loss: 2.903551]\n",
            "[Epoch 185/200] [Batch 250/469] [D loss: 0.011985] [G loss: 3.212343]\n",
            "[Epoch 185/200] [Batch 300/469] [D loss: 0.159559] [G loss: 2.251596]\n",
            "[Epoch 185/200] [Batch 350/469] [D loss: 0.024407] [G loss: 2.902752]\n",
            "[Epoch 185/200] [Batch 400/469] [D loss: 0.577452] [G loss: 0.235885]\n",
            "[Epoch 185/200] [Batch 450/469] [D loss: 0.330090] [G loss: 6.972560]\n",
            "[Epoch 186/200] [Batch 0/469] [D loss: 0.140707] [G loss: 1.690507]\n",
            "[Epoch 186/200] [Batch 50/469] [D loss: 0.224849] [G loss: 2.717213]\n",
            "[Epoch 186/200] [Batch 100/469] [D loss: 0.021703] [G loss: 2.571887]\n",
            "[Epoch 186/200] [Batch 150/469] [D loss: 0.240719] [G loss: 2.632896]\n",
            "[Epoch 186/200] [Batch 200/469] [D loss: 0.187682] [G loss: 1.447027]\n",
            "[Epoch 186/200] [Batch 250/469] [D loss: 0.104065] [G loss: 2.101477]\n",
            "[Epoch 186/200] [Batch 300/469] [D loss: 0.050671] [G loss: 4.306252]\n",
            "[Epoch 186/200] [Batch 350/469] [D loss: 0.119894] [G loss: 2.943892]\n",
            "[Epoch 186/200] [Batch 400/469] [D loss: 0.069559] [G loss: 2.855309]\n",
            "[Epoch 186/200] [Batch 450/469] [D loss: 0.757047] [G loss: 0.952289]\n",
            "[Epoch 187/200] [Batch 0/469] [D loss: 0.052700] [G loss: 1.903337]\n",
            "[Epoch 187/200] [Batch 50/469] [D loss: 0.075104] [G loss: 3.359379]\n",
            "[Epoch 187/200] [Batch 100/469] [D loss: 0.214688] [G loss: 1.883461]\n",
            "[Epoch 187/200] [Batch 150/469] [D loss: 0.902333] [G loss: 3.154552]\n",
            "[Epoch 187/200] [Batch 200/469] [D loss: 0.141821] [G loss: 4.782276]\n",
            "[Epoch 187/200] [Batch 250/469] [D loss: 0.052035] [G loss: 1.118271]\n",
            "[Epoch 187/200] [Batch 300/469] [D loss: 0.060030] [G loss: 3.663502]\n",
            "[Epoch 187/200] [Batch 350/469] [D loss: 0.631703] [G loss: 0.273536]\n",
            "[Epoch 187/200] [Batch 400/469] [D loss: 0.661413] [G loss: 1.488507]\n",
            "[Epoch 187/200] [Batch 450/469] [D loss: 0.332763] [G loss: 0.160088]\n",
            "[Epoch 188/200] [Batch 0/469] [D loss: 0.354045] [G loss: 4.937010]\n",
            "[Epoch 188/200] [Batch 50/469] [D loss: 0.009692] [G loss: 3.475223]\n",
            "[Epoch 188/200] [Batch 100/469] [D loss: 0.124615] [G loss: 2.775572]\n",
            "[Epoch 188/200] [Batch 150/469] [D loss: 0.206452] [G loss: 1.177206]\n",
            "[Epoch 188/200] [Batch 200/469] [D loss: 0.292609] [G loss: 1.495691]\n",
            "[Epoch 188/200] [Batch 250/469] [D loss: 0.057829] [G loss: 4.169646]\n",
            "[Epoch 188/200] [Batch 300/469] [D loss: 0.023539] [G loss: 3.210971]\n",
            "[Epoch 188/200] [Batch 350/469] [D loss: 0.814736] [G loss: 0.518925]\n",
            "[Epoch 188/200] [Batch 400/469] [D loss: 0.305969] [G loss: 1.839599]\n",
            "[Epoch 188/200] [Batch 450/469] [D loss: 0.410224] [G loss: 2.964302]\n",
            "[Epoch 189/200] [Batch 0/469] [D loss: 0.033169] [G loss: 1.649863]\n",
            "[Epoch 189/200] [Batch 50/469] [D loss: 0.080968] [G loss: 3.768535]\n",
            "[Epoch 189/200] [Batch 100/469] [D loss: 0.104460] [G loss: 0.489161]\n",
            "[Epoch 189/200] [Batch 150/469] [D loss: 0.042969] [G loss: 3.426991]\n",
            "[Epoch 189/200] [Batch 200/469] [D loss: 0.031790] [G loss: 4.397279]\n",
            "[Epoch 189/200] [Batch 250/469] [D loss: 0.081503] [G loss: 4.506164]\n",
            "[Epoch 189/200] [Batch 300/469] [D loss: 1.177438] [G loss: 0.160756]\n",
            "[Epoch 189/200] [Batch 350/469] [D loss: 0.130250] [G loss: 2.150718]\n",
            "[Epoch 189/200] [Batch 400/469] [D loss: 0.677355] [G loss: 1.250338]\n",
            "[Epoch 189/200] [Batch 450/469] [D loss: 0.707440] [G loss: 1.338979]\n",
            "[Epoch 190/200] [Batch 0/469] [D loss: 0.178561] [G loss: 2.759501]\n",
            "[Epoch 190/200] [Batch 50/469] [D loss: 0.015100] [G loss: 4.637496]\n",
            "[Epoch 190/200] [Batch 100/469] [D loss: 0.158463] [G loss: 3.733239]\n",
            "[Epoch 190/200] [Batch 150/469] [D loss: 0.024169] [G loss: 4.560228]\n",
            "[Epoch 190/200] [Batch 200/469] [D loss: 0.161247] [G loss: 3.109543]\n",
            "[Epoch 190/200] [Batch 250/469] [D loss: 0.132676] [G loss: 2.712404]\n",
            "[Epoch 190/200] [Batch 300/469] [D loss: 0.270938] [G loss: 4.068634]\n",
            "[Epoch 190/200] [Batch 350/469] [D loss: 0.057933] [G loss: 1.928693]\n",
            "[Epoch 190/200] [Batch 400/469] [D loss: 0.022687] [G loss: 5.789659]\n",
            "[Epoch 190/200] [Batch 450/469] [D loss: 0.385865] [G loss: 4.210572]\n",
            "[Epoch 191/200] [Batch 0/469] [D loss: 0.144726] [G loss: 2.082170]\n",
            "[Epoch 191/200] [Batch 50/469] [D loss: 0.075688] [G loss: 2.827614]\n",
            "[Epoch 191/200] [Batch 100/469] [D loss: 0.207475] [G loss: 6.698853]\n",
            "[Epoch 191/200] [Batch 150/469] [D loss: 0.197181] [G loss: 7.801119]\n",
            "[Epoch 191/200] [Batch 200/469] [D loss: 0.010347] [G loss: 4.841843]\n",
            "[Epoch 191/200] [Batch 250/469] [D loss: 0.130233] [G loss: 2.983768]\n",
            "[Epoch 191/200] [Batch 300/469] [D loss: 0.037352] [G loss: 5.431681]\n",
            "[Epoch 191/200] [Batch 350/469] [D loss: 0.045405] [G loss: 2.170294]\n",
            "[Epoch 191/200] [Batch 400/469] [D loss: 0.042348] [G loss: 5.578685]\n",
            "[Epoch 191/200] [Batch 450/469] [D loss: 0.419103] [G loss: 0.968326]\n",
            "[Epoch 192/200] [Batch 0/469] [D loss: 0.306084] [G loss: 2.109288]\n",
            "[Epoch 192/200] [Batch 50/469] [D loss: 0.038270] [G loss: 4.564490]\n",
            "[Epoch 192/200] [Batch 100/469] [D loss: 0.179002] [G loss: 4.782671]\n",
            "[Epoch 192/200] [Batch 150/469] [D loss: 0.143103] [G loss: 1.803216]\n",
            "[Epoch 192/200] [Batch 200/469] [D loss: 0.133891] [G loss: 4.156054]\n",
            "[Epoch 192/200] [Batch 250/469] [D loss: 0.312823] [G loss: 1.275318]\n",
            "[Epoch 192/200] [Batch 300/469] [D loss: 0.694073] [G loss: 1.527710]\n",
            "[Epoch 192/200] [Batch 350/469] [D loss: 0.043259] [G loss: 2.338820]\n",
            "[Epoch 192/200] [Batch 400/469] [D loss: 0.065333] [G loss: 1.734441]\n",
            "[Epoch 192/200] [Batch 450/469] [D loss: 0.075305] [G loss: 3.107322]\n",
            "[Epoch 193/200] [Batch 0/469] [D loss: 0.039165] [G loss: 1.364363]\n",
            "[Epoch 193/200] [Batch 50/469] [D loss: 0.113923] [G loss: 4.209628]\n",
            "[Epoch 193/200] [Batch 100/469] [D loss: 0.081739] [G loss: 4.589670]\n",
            "[Epoch 193/200] [Batch 150/469] [D loss: 0.015799] [G loss: 2.962121]\n",
            "[Epoch 193/200] [Batch 200/469] [D loss: 0.386334] [G loss: 0.854421]\n",
            "[Epoch 193/200] [Batch 250/469] [D loss: 0.176500] [G loss: 0.717151]\n",
            "[Epoch 193/200] [Batch 300/469] [D loss: 0.051370] [G loss: 2.511873]\n",
            "[Epoch 193/200] [Batch 350/469] [D loss: 0.033482] [G loss: 3.101122]\n",
            "[Epoch 193/200] [Batch 400/469] [D loss: 0.141826] [G loss: 1.339739]\n",
            "[Epoch 193/200] [Batch 450/469] [D loss: 0.180954] [G loss: 1.191903]\n",
            "[Epoch 194/200] [Batch 0/469] [D loss: 0.133322] [G loss: 1.965340]\n",
            "[Epoch 194/200] [Batch 50/469] [D loss: 0.985587] [G loss: 0.578205]\n",
            "[Epoch 194/200] [Batch 100/469] [D loss: 1.572130] [G loss: 4.914713]\n",
            "[Epoch 194/200] [Batch 150/469] [D loss: 0.642429] [G loss: 3.152187]\n",
            "[Epoch 194/200] [Batch 200/469] [D loss: 0.094238] [G loss: 5.112324]\n",
            "[Epoch 194/200] [Batch 250/469] [D loss: 0.047583] [G loss: 2.979437]\n",
            "[Epoch 194/200] [Batch 300/469] [D loss: 0.944852] [G loss: 4.779544]\n",
            "[Epoch 194/200] [Batch 350/469] [D loss: 0.307731] [G loss: 1.378431]\n",
            "[Epoch 194/200] [Batch 400/469] [D loss: 0.153925] [G loss: 4.366567]\n",
            "[Epoch 194/200] [Batch 450/469] [D loss: 0.143232] [G loss: 5.288455]\n",
            "[Epoch 195/200] [Batch 0/469] [D loss: 0.278300] [G loss: 1.889300]\n",
            "[Epoch 195/200] [Batch 50/469] [D loss: 0.132091] [G loss: 0.974932]\n",
            "[Epoch 195/200] [Batch 100/469] [D loss: 0.111174] [G loss: 2.422232]\n",
            "[Epoch 195/200] [Batch 150/469] [D loss: 0.041259] [G loss: 2.911123]\n",
            "[Epoch 195/200] [Batch 200/469] [D loss: 0.039231] [G loss: 1.888702]\n",
            "[Epoch 195/200] [Batch 250/469] [D loss: 0.112380] [G loss: 3.770153]\n",
            "[Epoch 195/200] [Batch 300/469] [D loss: 0.433462] [G loss: 4.972746]\n",
            "[Epoch 195/200] [Batch 350/469] [D loss: 0.237874] [G loss: 3.586837]\n",
            "[Epoch 195/200] [Batch 400/469] [D loss: 0.295249] [G loss: 1.139605]\n",
            "[Epoch 195/200] [Batch 450/469] [D loss: 1.037982] [G loss: 2.910714]\n",
            "[Epoch 196/200] [Batch 0/469] [D loss: 0.328778] [G loss: 0.080511]\n",
            "[Epoch 196/200] [Batch 50/469] [D loss: 0.271973] [G loss: 2.666122]\n",
            "[Epoch 196/200] [Batch 100/469] [D loss: 0.336930] [G loss: 4.650824]\n",
            "[Epoch 196/200] [Batch 150/469] [D loss: 0.424995] [G loss: 0.175880]\n",
            "[Epoch 196/200] [Batch 200/469] [D loss: 0.257135] [G loss: 1.223373]\n",
            "[Epoch 196/200] [Batch 250/469] [D loss: 0.182978] [G loss: 3.487431]\n",
            "[Epoch 196/200] [Batch 300/469] [D loss: 0.236827] [G loss: 2.146467]\n",
            "[Epoch 196/200] [Batch 350/469] [D loss: 0.010188] [G loss: 5.060992]\n",
            "[Epoch 196/200] [Batch 400/469] [D loss: 0.037758] [G loss: 2.583548]\n",
            "[Epoch 196/200] [Batch 450/469] [D loss: 0.246811] [G loss: 1.600515]\n",
            "[Epoch 197/200] [Batch 0/469] [D loss: 0.075359] [G loss: 3.954736]\n",
            "[Epoch 197/200] [Batch 50/469] [D loss: 0.045723] [G loss: 1.242654]\n",
            "[Epoch 197/200] [Batch 100/469] [D loss: 0.086364] [G loss: 3.534478]\n",
            "[Epoch 197/200] [Batch 150/469] [D loss: 0.047186] [G loss: 4.017117]\n",
            "[Epoch 197/200] [Batch 200/469] [D loss: 0.069069] [G loss: 4.552742]\n",
            "[Epoch 197/200] [Batch 250/469] [D loss: 0.078381] [G loss: 0.314550]\n",
            "[Epoch 197/200] [Batch 300/469] [D loss: 1.555931] [G loss: 0.045614]\n",
            "[Epoch 197/200] [Batch 350/469] [D loss: 0.226570] [G loss: 0.857765]\n",
            "[Epoch 197/200] [Batch 400/469] [D loss: 0.719348] [G loss: 1.563287]\n",
            "[Epoch 197/200] [Batch 450/469] [D loss: 0.211142] [G loss: 1.818624]\n",
            "[Epoch 198/200] [Batch 0/469] [D loss: 0.341735] [G loss: 2.453496]\n",
            "[Epoch 198/200] [Batch 50/469] [D loss: 0.084074] [G loss: 3.827651]\n",
            "[Epoch 198/200] [Batch 100/469] [D loss: 0.012817] [G loss: 5.088922]\n",
            "[Epoch 198/200] [Batch 150/469] [D loss: 0.702101] [G loss: 0.590768]\n",
            "[Epoch 198/200] [Batch 200/469] [D loss: 0.917426] [G loss: 1.245775]\n",
            "[Epoch 198/200] [Batch 250/469] [D loss: 0.097483] [G loss: 1.446219]\n",
            "[Epoch 198/200] [Batch 300/469] [D loss: 0.119085] [G loss: 3.138433]\n",
            "[Epoch 198/200] [Batch 350/469] [D loss: 0.857862] [G loss: 0.162099]\n",
            "[Epoch 198/200] [Batch 400/469] [D loss: 0.045106] [G loss: 1.862050]\n",
            "[Epoch 198/200] [Batch 450/469] [D loss: 0.022421] [G loss: 4.782728]\n",
            "[Epoch 199/200] [Batch 0/469] [D loss: 0.964912] [G loss: 4.917725]\n",
            "[Epoch 199/200] [Batch 50/469] [D loss: 0.073691] [G loss: 4.874741]\n",
            "[Epoch 199/200] [Batch 100/469] [D loss: 0.554400] [G loss: 1.996064]\n",
            "[Epoch 199/200] [Batch 150/469] [D loss: 0.148764] [G loss: 4.345467]\n",
            "[Epoch 199/200] [Batch 200/469] [D loss: 0.129475] [G loss: 5.431253]\n",
            "[Epoch 199/200] [Batch 250/469] [D loss: 0.089133] [G loss: 1.897914]\n",
            "[Epoch 199/200] [Batch 300/469] [D loss: 0.205628] [G loss: 4.160645]\n",
            "[Epoch 199/200] [Batch 350/469] [D loss: 0.160099] [G loss: 3.244578]\n",
            "[Epoch 199/200] [Batch 400/469] [D loss: 0.374560] [G loss: 5.901088]\n",
            "[Epoch 199/200] [Batch 450/469] [D loss: 0.231838] [G loss: 4.032149]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJlsr1UrbWK9"
      },
      "outputs": [],
      "source": [
        "  # ----------\n",
        "#  Training GAN\n",
        "# ----------\n",
        "\"\"\"\n",
        "# Lists to keep track of progress\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "iters = 0\n",
        "\n",
        "for epoch in range(opt.n_epochs):\n",
        "    for i, (imgs, _) in enumerate(train_loader):\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = Variable(FloatTensor(imgs.shape[0], 1).fill_(1.0), requires_grad=False)\n",
        "        fake = Variable(FloatTensor(imgs.shape[0], 1).fill_(0.0), requires_grad=False)\n",
        "\n",
        "        # Configure input\n",
        "        real_imgs = Variable(imgs.type(FloatTensor))\n",
        "\n",
        "        # -----------------\n",
        "        #  Train Generator\n",
        "        # -----------------\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # Sample noise as generator input\n",
        "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim))))   # torch.Size([32, 100]\n",
        "\n",
        "        # Generate a batch of images\n",
        "        gen_imgs = generator(z)\n",
        "\n",
        "        # Loss measures generator's ability to fool the discriminator\n",
        "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
        "\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # Measure discriminator's ability to classify real from generated samples\n",
        "        real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
        "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # Output training stats\n",
        "        if i % 50 == 0:\n",
        "             print(\n",
        "              \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
        "              % (epoch, opt.n_epochs, i, len(train_loader), d_loss.item(), g_loss.item())\n",
        "              )\n",
        "\n",
        "        # Save Losses for plotting later\n",
        "        G_losses.append(g_loss.item())\n",
        "        D_losses.append(d_loss.item())\n",
        "\n",
        "        # Check how the generator is doing by saving G's output on fixed_noise\n",
        "        if (iters % 500 == 0) or ((epoch == opt.n_epochs-1) and (i == len(train_loader)-1)):\n",
        "            with torch.no_grad():\n",
        "                fake = generator(fixed_noise).detach().cpu()\n",
        "            img_list.append(make_grid(fake, padding=2, normalize=True)) #stored on every 500 epoch\n",
        "\n",
        "        iters += 1\n",
        "\n",
        "\n",
        "For a batch of 128\n",
        "  60,000/ 128 = 469 batches\n",
        "Gradient descent occurs\n",
        "  469 * number of epoches = 93,800\n",
        "img_list is updated on every 500 epoch\n",
        "  93,800 / 500 = 187 = len(img_list)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"CGAN Generator and Discriminator Loss During Training\")\n",
        "plt.plot(G_losses,label=\"G\")\n",
        "plt.plot(D_losses,label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "del G_losses\n",
        "del D_losses"
      ],
      "metadata": {
        "id": "6j40IWWyGES2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grab a batch of real images from the dataloader\n",
        "\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and 1 > 0) else \"cpu\")\n",
        "real_batch = next(iter(train_loader))\n",
        "\n",
        "# Plot the real images\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.subplot(1,2,1)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Real Images\")\n",
        "plt.imshow(np.transpose(make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))"
      ],
      "metadata": {
        "id": "5iOIi_LpGHS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = enumerate(train_loader)\n",
        "batch_idx, (example_data, example_targets) = next(examples)\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.subplot(1,2,1)\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(np.transpose(make_grid(example_data.to(device)[0:2], padding=5, normalize=True).cpu(),(1,2,0)))"
      ],
      "metadata": {
        "id": "-A8CU2IiNB2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ , axes = plt.subplots(1, 5, figsize=(20, 8))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "  image = img_list[89+i]\n",
        "  ax.imshow(np.transpose(make_grid(image),(1,2,0)))\n",
        "  ax.set_yticklabels([])\n",
        "  ax.set_xticklabels([])"
      ],
      "metadata": {
        "id": "WC7kwtIfySEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = Variable(FloatTensor(np.random.normal(0, 1, (10**2, opt.latent_dim))))\n",
        "labels = np.array([num for _ in range(10) for num in range(10)])\n",
        "labels = Variable(LongTensor(labels))\n",
        "images = generator(z, labels)\n",
        "grid = make_grid(images, nrow=10, normalize=True)\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "ax.imshow(grid.permute(1, 2, 0).data.cpu(), cmap='binary')\n",
        "ax.axis('off')"
      ],
      "metadata": {
        "id": "aVB67itZcAUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Generate 1024 image for each class \n",
        "def cgan_accuracy():\n",
        "  all_labels = []\n",
        "  all_pred = []\n",
        "  total = 0\n",
        "  transform_back = transforms.Resize(28)\n",
        "\n",
        "  for j in range(10):\n",
        "    for i in range(1, 33):\n",
        "      z = Variable(FloatTensor(np.random.normal(0, 1, (32, opt.latent_dim))))\n",
        "      labels = np.array([j for _ in range(32)])\n",
        "      #labels = np.array([num for _ in range(5) for num in range(10)])\n",
        "      labels = Variable(LongTensor(labels))\n",
        "      all_labels += labels.cpu().tolist()\n",
        "      images = generator(z, labels)\n",
        "      transformed_image = transform_back(images)\n",
        "      prediction = model(transformed_image)\n",
        "      pred = prediction.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "      all_pred += pred.squeeze(-1).cpu().tolist()\n",
        "      correct = pred.eq(labels.view_as(pred)).sum().item()\n",
        "      total += correct\n",
        "  return all_labels, all_pred, total"
      ],
      "metadata": {
        "id": "J8hchew1kZl1"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels, test_pred, test_acc = model_accuracy(model)\n",
        "test_labels_freq = Counter(test_labels).items()\n",
        "test_labels_freq = sorted(test_labels_freq)\n",
        "test_labels_freq = [x[1] for x in test_labels_freq]\n",
        "test_labels_prop = [x/(len(test_labels)) for x in test_labels_freq]\n",
        "\n",
        "test_pred_freq = Counter(test_pred).items()\n",
        "test_pred_freq = sorted(test_pred_freq)\n",
        "test_pred_freq = [x[1] for x in test_pred_freq]\n",
        "test_pred_prop = [x/(len(test_pred)) for x in test_pred_freq]\n",
        "print(f\"Our CNN model accuracy: {test_acc/100}%\")"
      ],
      "metadata": {
        "id": "mYs6berD39dM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig2 = go.Figure()\n",
        "fig2.add_trace(go.Bar(name='True labels', x=np.arange(10), y=test_labels_prop, marker_color='rgb(33, 75, 99)'))\n",
        "fig2.add_trace(go.Bar(name='Predicted labels CNN', x=np.arange(10), y=test_pred_prop, marker_color='rgb(79, 129, 102)'))\n",
        "\n",
        "\n",
        "fig2.update_layout(\n",
        "    barmode='group',\n",
        "    title=\"Pre-trained CNN model\",\n",
        "    width=1200,\n",
        "    height=500,\n",
        "    xaxis = dict(\n",
        "        tickmode = 'array',\n",
        "        tickvals = [x for x in range(10)],\n",
        "        ticktext = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "    )\n",
        ")\n",
        "fig2.show()"
      ],
      "metadata": {
        "id": "GHowY0LZ4Blw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cgan_generated_labels, cgan_generated_pred, cgan_generated_acc = cgan_accuracy()\n",
        "\n",
        "cgan_generated_freq = Counter(cgan_generated_labels).items()\n",
        "cgan_generated_freq = sorted(cgan_generated_freq)\n",
        "cgan_generated_freq = [x[1] for x in cgan_generated_freq]\n",
        "cgan_generated_prop = [x/(len(cgan_generated_labels)) for x in cgan_generated_freq]\n",
        "\n",
        "cgan_generated_pred_freq = Counter(cgan_generated_pred).items()\n",
        "cgan_generated_pred_freq = sorted(cgan_generated_pred_freq)\n",
        "cgan_generated_pred_freq = [x[1] for x in cgan_generated_pred_freq]\n",
        "cgan_generated_pred_prop = [x/(len(cgan_generated_pred)) for x in cgan_generated_pred_freq]\n",
        "\n",
        "print(f\"Our CNN model accuracy on generated image: {cgan_generated_acc/100}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rc68KzLasSvl",
        "outputId": "88440c0c-35d2-4f89-8449-65a6b062abe0"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our CNN model accuracy: 29.75%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig3 = go.Figure()\n",
        "fig3.add_trace(go.Bar(name='Assigned labels', x=np.arange(10), y=cgan_generated_prop, marker_color='rgb(33, 75, 99)'))\n",
        "fig3.add_trace(go.Bar(name='Predicted labels CNN', x=np.arange(10), y=cgan_generated_pred_prop, marker_color='rgb(79, 129, 102)'))\n",
        "\n",
        "\n",
        "fig3.update_layout(\n",
        "    barmode='group',\n",
        "    title=\"CGAN Generated\",\n",
        "    width=1200,\n",
        "    height=500,\n",
        "    xaxis = dict(\n",
        "        tickmode = 'array',\n",
        "        tickvals = [x for x in range(10)],\n",
        "        ticktext = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "    )\n",
        ")\n",
        "fig3.show()"
      ],
      "metadata": {
        "id": "2N2-AQgdwmCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Generate 1024 image for each class \n",
        "def cgan_10000(size):\n",
        "  cgan_loader = []\n",
        "  transform_back = transforms.Resize(28)\n",
        "  for i in range(size):\n",
        "    z = Variable(FloatTensor(np.random.normal(0, 1, (args.batch_size, opt.latent_dim))))\n",
        "    labels = np.random.randint(0, 10, args.batch_size)\n",
        "    labels = Variable(LongTensor(labels))\n",
        "    images = generator(z, labels)\n",
        "    transformed_image = transform_back(images)\n",
        "    cgan_loader.append((transformed_image, labels))\n",
        "  return cgan_loader"
      ],
      "metadata": {
        "id": "8Ww-WfePCtwx"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "del fig4\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsI0e9Gh1JTU",
        "outputId": "46e26975-b034-4f62-bb83-7d8f0cc4dee7"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "percent = 100\n",
        "cgan_loader = cgan_10000(20)\n",
        "# train_loader_new = cgan_loader + random.sample(list(train_loader_), int((percent/100)*(len(train_loader_))))\n",
        "# random.shuffle(train_loader_new)"
      ],
      "metadata": {
        "id": "4ROhjRMmJKhN"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train new CNN with generated + percentage of trian data\n",
        "model_new = Net().to(device)\n",
        "optimizer = torch.optim.Adadelta(model_new.parameters(), lr=args.lr)\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    train(args, model_new, device, train_loader_new, optimizer, epoch)\n",
        "    test(model_new, device, test_loader_)\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yffrAJ8dLm9H",
        "outputId": "8a39cb50-6c4a-4111-fcd6-318dd6c2459d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/756 (0%)]\tLoss: 2.323990\n",
            "Train Epoch: 1 [640/756 (1%)]\tLoss: 1.234098\n",
            "Train Epoch: 1 [1280/756 (3%)]\tLoss: 0.633919\n",
            "Train Epoch: 1 [1920/756 (4%)]\tLoss: 0.437264\n",
            "Train Epoch: 1 [2560/756 (5%)]\tLoss: 0.256480\n",
            "Train Epoch: 1 [3200/756 (7%)]\tLoss: 0.213225\n",
            "Train Epoch: 1 [3840/756 (8%)]\tLoss: 0.266988\n",
            "Train Epoch: 1 [4480/756 (9%)]\tLoss: 0.216118\n",
            "Train Epoch: 1 [5120/756 (11%)]\tLoss: 0.228111\n",
            "Train Epoch: 1 [5760/756 (12%)]\tLoss: 0.232914\n",
            "Train Epoch: 1 [6400/756 (13%)]\tLoss: 0.995842\n",
            "Train Epoch: 1 [7040/756 (15%)]\tLoss: 0.227178\n",
            "Train Epoch: 1 [7680/756 (16%)]\tLoss: 0.293530\n",
            "Train Epoch: 1 [8320/756 (17%)]\tLoss: 0.159719\n",
            "Train Epoch: 1 [8960/756 (19%)]\tLoss: 0.317077\n",
            "Train Epoch: 1 [9600/756 (20%)]\tLoss: 0.272201\n",
            "Train Epoch: 1 [10240/756 (21%)]\tLoss: 0.214379\n",
            "Train Epoch: 1 [10880/756 (22%)]\tLoss: 0.107959\n",
            "Train Epoch: 1 [11520/756 (24%)]\tLoss: 0.112849\n",
            "Train Epoch: 1 [12160/756 (25%)]\tLoss: 0.200184\n",
            "Train Epoch: 1 [12800/756 (26%)]\tLoss: 0.214550\n",
            "Train Epoch: 1 [13440/756 (28%)]\tLoss: 0.227016\n",
            "Train Epoch: 1 [14080/756 (29%)]\tLoss: 0.120680\n",
            "Train Epoch: 1 [14720/756 (30%)]\tLoss: 0.176509\n",
            "Train Epoch: 1 [15360/756 (32%)]\tLoss: 0.145690\n",
            "Train Epoch: 1 [16000/756 (33%)]\tLoss: 0.129261\n",
            "Train Epoch: 1 [16640/756 (34%)]\tLoss: 0.092802\n",
            "Train Epoch: 1 [17280/756 (36%)]\tLoss: 0.184264\n",
            "Train Epoch: 1 [17920/756 (37%)]\tLoss: 0.115342\n",
            "Train Epoch: 1 [18560/756 (38%)]\tLoss: 0.160263\n",
            "Train Epoch: 1 [19200/756 (40%)]\tLoss: 0.097017\n",
            "Train Epoch: 1 [19840/756 (41%)]\tLoss: 0.101349\n",
            "Train Epoch: 1 [20480/756 (42%)]\tLoss: 0.249889\n",
            "Train Epoch: 1 [21120/756 (44%)]\tLoss: 0.201261\n",
            "Train Epoch: 1 [21760/756 (45%)]\tLoss: 0.058458\n",
            "Train Epoch: 1 [22400/756 (46%)]\tLoss: 0.111188\n",
            "Train Epoch: 1 [23040/756 (48%)]\tLoss: 0.093878\n",
            "Train Epoch: 1 [23680/756 (49%)]\tLoss: 0.181406\n",
            "Train Epoch: 1 [24320/756 (50%)]\tLoss: 0.024713\n",
            "Train Epoch: 1 [24960/756 (52%)]\tLoss: 0.053789\n",
            "Train Epoch: 1 [25600/756 (53%)]\tLoss: 0.245609\n",
            "Train Epoch: 1 [26240/756 (54%)]\tLoss: 0.121271\n",
            "Train Epoch: 1 [26880/756 (56%)]\tLoss: 0.112954\n",
            "Train Epoch: 1 [27520/756 (57%)]\tLoss: 0.040733\n",
            "Train Epoch: 1 [28160/756 (58%)]\tLoss: 0.063151\n",
            "Train Epoch: 1 [28800/756 (60%)]\tLoss: 0.191179\n",
            "Train Epoch: 1 [29440/756 (61%)]\tLoss: 0.092087\n",
            "Train Epoch: 1 [30080/756 (62%)]\tLoss: 0.072903\n",
            "Train Epoch: 1 [30720/756 (63%)]\tLoss: 0.154724\n",
            "Train Epoch: 1 [31360/756 (65%)]\tLoss: 0.088337\n",
            "Train Epoch: 1 [32000/756 (66%)]\tLoss: 0.119187\n",
            "Train Epoch: 1 [32640/756 (67%)]\tLoss: 0.187738\n",
            "Train Epoch: 1 [33280/756 (69%)]\tLoss: 0.132627\n",
            "Train Epoch: 1 [33920/756 (70%)]\tLoss: 0.061924\n",
            "Train Epoch: 1 [34560/756 (71%)]\tLoss: 0.076593\n",
            "Train Epoch: 1 [35200/756 (73%)]\tLoss: 0.091764\n",
            "Train Epoch: 1 [35840/756 (74%)]\tLoss: 0.052899\n",
            "Train Epoch: 1 [36480/756 (75%)]\tLoss: 0.143208\n",
            "Train Epoch: 1 [37120/756 (77%)]\tLoss: 0.055058\n",
            "Train Epoch: 1 [37760/756 (78%)]\tLoss: 0.032149\n",
            "Train Epoch: 1 [38400/756 (79%)]\tLoss: 0.098328\n",
            "Train Epoch: 1 [39040/756 (81%)]\tLoss: 0.080329\n",
            "Train Epoch: 1 [39680/756 (82%)]\tLoss: 0.037842\n",
            "Train Epoch: 1 [40320/756 (83%)]\tLoss: 0.074512\n",
            "Train Epoch: 1 [40960/756 (85%)]\tLoss: 0.028784\n",
            "Train Epoch: 1 [41600/756 (86%)]\tLoss: 0.022118\n",
            "Train Epoch: 1 [42240/756 (87%)]\tLoss: 0.246301\n",
            "Train Epoch: 1 [42880/756 (89%)]\tLoss: 0.110863\n",
            "Train Epoch: 1 [43520/756 (90%)]\tLoss: 0.088979\n",
            "Train Epoch: 1 [44160/756 (91%)]\tLoss: 0.136267\n",
            "Train Epoch: 1 [44800/756 (93%)]\tLoss: 0.262887\n",
            "Train Epoch: 1 [45440/756 (94%)]\tLoss: 0.193012\n",
            "Train Epoch: 1 [46080/756 (95%)]\tLoss: 0.063995\n",
            "Train Epoch: 1 [46720/756 (97%)]\tLoss: 0.051015\n",
            "Train Epoch: 1 [47360/756 (98%)]\tLoss: 0.066779\n",
            "Train Epoch: 1 [48000/756 (99%)]\tLoss: 0.150330\n",
            "\n",
            "Test set: Average loss: 0.0609, Accuracy: 9823/10000 (98%)\n",
            "\n",
            "Train Epoch: 2 [0/756 (0%)]\tLoss: 0.112992\n",
            "Train Epoch: 2 [640/756 (1%)]\tLoss: 0.053903\n",
            "Train Epoch: 2 [1280/756 (3%)]\tLoss: 0.041621\n",
            "Train Epoch: 2 [1920/756 (4%)]\tLoss: 0.120980\n",
            "Train Epoch: 2 [2560/756 (5%)]\tLoss: 0.025602\n",
            "Train Epoch: 2 [3200/756 (7%)]\tLoss: 0.050878\n",
            "Train Epoch: 2 [3840/756 (8%)]\tLoss: 0.059179\n",
            "Train Epoch: 2 [4480/756 (9%)]\tLoss: 0.009615\n",
            "Train Epoch: 2 [5120/756 (11%)]\tLoss: 0.007028\n",
            "Train Epoch: 2 [5760/756 (12%)]\tLoss: 0.109228\n",
            "Train Epoch: 2 [6400/756 (13%)]\tLoss: 0.023307\n",
            "Train Epoch: 2 [7040/756 (15%)]\tLoss: 0.332214\n",
            "Train Epoch: 2 [7680/756 (16%)]\tLoss: 0.114720\n",
            "Train Epoch: 2 [8320/756 (17%)]\tLoss: 0.007002\n",
            "Train Epoch: 2 [8960/756 (19%)]\tLoss: 0.042615\n",
            "Train Epoch: 2 [9600/756 (20%)]\tLoss: 0.170018\n",
            "Train Epoch: 2 [10240/756 (21%)]\tLoss: 0.097332\n",
            "Train Epoch: 2 [10880/756 (22%)]\tLoss: 0.051292\n",
            "Train Epoch: 2 [11520/756 (24%)]\tLoss: 0.009591\n",
            "Train Epoch: 2 [12160/756 (25%)]\tLoss: 0.041187\n",
            "Train Epoch: 2 [12800/756 (26%)]\tLoss: 0.077560\n",
            "Train Epoch: 2 [13440/756 (28%)]\tLoss: 0.033277\n",
            "Train Epoch: 2 [14080/756 (29%)]\tLoss: 0.036606\n",
            "Train Epoch: 2 [14720/756 (30%)]\tLoss: 0.172032\n",
            "Train Epoch: 2 [15360/756 (32%)]\tLoss: 0.042408\n",
            "Train Epoch: 2 [16000/756 (33%)]\tLoss: 0.090543\n",
            "Train Epoch: 2 [16640/756 (34%)]\tLoss: 0.036986\n",
            "Train Epoch: 2 [17280/756 (36%)]\tLoss: 0.016445\n",
            "Train Epoch: 2 [17920/756 (37%)]\tLoss: 0.036524\n",
            "Train Epoch: 2 [18560/756 (38%)]\tLoss: 0.058378\n",
            "Train Epoch: 2 [19200/756 (40%)]\tLoss: 0.022984\n",
            "Train Epoch: 2 [19840/756 (41%)]\tLoss: 0.067874\n",
            "Train Epoch: 2 [20480/756 (42%)]\tLoss: 0.066534\n",
            "Train Epoch: 2 [21120/756 (44%)]\tLoss: 0.084922\n",
            "Train Epoch: 2 [21760/756 (45%)]\tLoss: 0.042764\n",
            "Train Epoch: 2 [22400/756 (46%)]\tLoss: 0.102003\n",
            "Train Epoch: 2 [23040/756 (48%)]\tLoss: 0.212856\n",
            "Train Epoch: 2 [23680/756 (49%)]\tLoss: 0.163213\n",
            "Train Epoch: 2 [24320/756 (50%)]\tLoss: 0.021810\n",
            "Train Epoch: 2 [24960/756 (52%)]\tLoss: 0.018372\n",
            "Train Epoch: 2 [25600/756 (53%)]\tLoss: 0.221748\n",
            "Train Epoch: 2 [26240/756 (54%)]\tLoss: 0.041607\n",
            "Train Epoch: 2 [26880/756 (56%)]\tLoss: 0.041972\n",
            "Train Epoch: 2 [27520/756 (57%)]\tLoss: 0.009211\n",
            "Train Epoch: 2 [28160/756 (58%)]\tLoss: 0.039498\n",
            "Train Epoch: 2 [28800/756 (60%)]\tLoss: 0.075659\n",
            "Train Epoch: 2 [29440/756 (61%)]\tLoss: 0.140215\n",
            "Train Epoch: 2 [30080/756 (62%)]\tLoss: 0.040991\n",
            "Train Epoch: 2 [30720/756 (63%)]\tLoss: 0.053973\n",
            "Train Epoch: 2 [31360/756 (65%)]\tLoss: 0.096796\n",
            "Train Epoch: 2 [32000/756 (66%)]\tLoss: 0.060509\n",
            "Train Epoch: 2 [32640/756 (67%)]\tLoss: 0.150658\n",
            "Train Epoch: 2 [33280/756 (69%)]\tLoss: 0.125287\n",
            "Train Epoch: 2 [33920/756 (70%)]\tLoss: 0.074378\n",
            "Train Epoch: 2 [34560/756 (71%)]\tLoss: 0.074534\n",
            "Train Epoch: 2 [35200/756 (73%)]\tLoss: 0.063629\n",
            "Train Epoch: 2 [35840/756 (74%)]\tLoss: 0.015022\n",
            "Train Epoch: 2 [36480/756 (75%)]\tLoss: 0.110829\n",
            "Train Epoch: 2 [37120/756 (77%)]\tLoss: 0.023358\n",
            "Train Epoch: 2 [37760/756 (78%)]\tLoss: 0.022991\n",
            "Train Epoch: 2 [38400/756 (79%)]\tLoss: 0.073913\n",
            "Train Epoch: 2 [39040/756 (81%)]\tLoss: 0.131039\n",
            "Train Epoch: 2 [39680/756 (82%)]\tLoss: 0.069621\n",
            "Train Epoch: 2 [40320/756 (83%)]\tLoss: 0.039430\n",
            "Train Epoch: 2 [40960/756 (85%)]\tLoss: 0.008153\n",
            "Train Epoch: 2 [41600/756 (86%)]\tLoss: 0.016852\n",
            "Train Epoch: 2 [42240/756 (87%)]\tLoss: 0.092462\n",
            "Train Epoch: 2 [42880/756 (89%)]\tLoss: 0.060650\n",
            "Train Epoch: 2 [43520/756 (90%)]\tLoss: 0.166197\n",
            "Train Epoch: 2 [44160/756 (91%)]\tLoss: 0.003360\n",
            "Train Epoch: 2 [44800/756 (93%)]\tLoss: 0.136704\n",
            "Train Epoch: 2 [45440/756 (94%)]\tLoss: 0.127877\n",
            "Train Epoch: 2 [46080/756 (95%)]\tLoss: 0.042441\n",
            "Train Epoch: 2 [46720/756 (97%)]\tLoss: 0.002526\n",
            "Train Epoch: 2 [47360/756 (98%)]\tLoss: 0.040137\n",
            "Train Epoch: 2 [48000/756 (99%)]\tLoss: 0.051662\n",
            "\n",
            "Test set: Average loss: 0.0466, Accuracy: 9861/10000 (99%)\n",
            "\n",
            "Train Epoch: 3 [0/756 (0%)]\tLoss: 0.041287\n",
            "Train Epoch: 3 [640/756 (1%)]\tLoss: 0.032913\n",
            "Train Epoch: 3 [1280/756 (3%)]\tLoss: 0.014608\n",
            "Train Epoch: 3 [1920/756 (4%)]\tLoss: 0.041493\n",
            "Train Epoch: 3 [2560/756 (5%)]\tLoss: 0.073877\n",
            "Train Epoch: 3 [3200/756 (7%)]\tLoss: 0.049904\n",
            "Train Epoch: 3 [3840/756 (8%)]\tLoss: 0.057615\n",
            "Train Epoch: 3 [4480/756 (9%)]\tLoss: 0.017576\n",
            "Train Epoch: 3 [5120/756 (11%)]\tLoss: 0.043788\n",
            "Train Epoch: 3 [5760/756 (12%)]\tLoss: 0.071099\n",
            "Train Epoch: 3 [6400/756 (13%)]\tLoss: 0.013293\n",
            "Train Epoch: 3 [7040/756 (15%)]\tLoss: 0.075674\n",
            "Train Epoch: 3 [7680/756 (16%)]\tLoss: 0.128277\n",
            "Train Epoch: 3 [8320/756 (17%)]\tLoss: 0.001215\n",
            "Train Epoch: 3 [8960/756 (19%)]\tLoss: 0.065954\n",
            "Train Epoch: 3 [9600/756 (20%)]\tLoss: 0.121975\n",
            "Train Epoch: 3 [10240/756 (21%)]\tLoss: 0.167652\n",
            "Train Epoch: 3 [10880/756 (22%)]\tLoss: 0.006694\n",
            "Train Epoch: 3 [11520/756 (24%)]\tLoss: 0.017832\n",
            "Train Epoch: 3 [12160/756 (25%)]\tLoss: 0.022816\n",
            "Train Epoch: 3 [12800/756 (26%)]\tLoss: 0.061774\n",
            "Train Epoch: 3 [13440/756 (28%)]\tLoss: 0.000884\n",
            "Train Epoch: 3 [14080/756 (29%)]\tLoss: 0.039384\n",
            "Train Epoch: 3 [14720/756 (30%)]\tLoss: 0.142795\n",
            "Train Epoch: 3 [15360/756 (32%)]\tLoss: 0.103720\n",
            "Train Epoch: 3 [16000/756 (33%)]\tLoss: 0.011564\n",
            "Train Epoch: 3 [16640/756 (34%)]\tLoss: 0.003199\n",
            "Train Epoch: 3 [17280/756 (36%)]\tLoss: 0.020661\n",
            "Train Epoch: 3 [17920/756 (37%)]\tLoss: 0.006993\n",
            "Train Epoch: 3 [18560/756 (38%)]\tLoss: 0.080211\n",
            "Train Epoch: 3 [19200/756 (40%)]\tLoss: 0.050259\n",
            "Train Epoch: 3 [19840/756 (41%)]\tLoss: 0.019826\n",
            "Train Epoch: 3 [20480/756 (42%)]\tLoss: 0.043709\n",
            "Train Epoch: 3 [21120/756 (44%)]\tLoss: 0.108835\n",
            "Train Epoch: 3 [21760/756 (45%)]\tLoss: 0.009447\n",
            "Train Epoch: 3 [22400/756 (46%)]\tLoss: 0.018351\n",
            "Train Epoch: 3 [23040/756 (48%)]\tLoss: 0.073036\n",
            "Train Epoch: 3 [23680/756 (49%)]\tLoss: 0.139392\n",
            "Train Epoch: 3 [24320/756 (50%)]\tLoss: 0.016994\n",
            "Train Epoch: 3 [24960/756 (52%)]\tLoss: 0.035047\n",
            "Train Epoch: 3 [25600/756 (53%)]\tLoss: 0.028805\n",
            "Train Epoch: 3 [26240/756 (54%)]\tLoss: 0.073298\n",
            "Train Epoch: 3 [26880/756 (56%)]\tLoss: 0.037923\n",
            "Train Epoch: 3 [27520/756 (57%)]\tLoss: 0.026293\n",
            "Train Epoch: 3 [28160/756 (58%)]\tLoss: 0.013801\n",
            "Train Epoch: 3 [28800/756 (60%)]\tLoss: 0.049926\n",
            "Train Epoch: 3 [29440/756 (61%)]\tLoss: 0.054315\n",
            "Train Epoch: 3 [30080/756 (62%)]\tLoss: 0.072182\n",
            "Train Epoch: 3 [30720/756 (63%)]\tLoss: 0.042755\n",
            "Train Epoch: 3 [31360/756 (65%)]\tLoss: 0.064754\n",
            "Train Epoch: 3 [32000/756 (66%)]\tLoss: 0.052219\n",
            "Train Epoch: 3 [32640/756 (67%)]\tLoss: 0.039902\n",
            "Train Epoch: 3 [33280/756 (69%)]\tLoss: 0.088881\n",
            "Train Epoch: 3 [33920/756 (70%)]\tLoss: 0.029425\n",
            "Train Epoch: 3 [34560/756 (71%)]\tLoss: 0.017134\n",
            "Train Epoch: 3 [35200/756 (73%)]\tLoss: 0.016732\n",
            "Train Epoch: 3 [35840/756 (74%)]\tLoss: 0.004492\n",
            "Train Epoch: 3 [36480/756 (75%)]\tLoss: 0.013336\n",
            "Train Epoch: 3 [37120/756 (77%)]\tLoss: 0.025012\n",
            "Train Epoch: 3 [37760/756 (78%)]\tLoss: 0.013528\n",
            "Train Epoch: 3 [38400/756 (79%)]\tLoss: 0.010460\n",
            "Train Epoch: 3 [39040/756 (81%)]\tLoss: 0.071201\n",
            "Train Epoch: 3 [39680/756 (82%)]\tLoss: 0.052359\n",
            "Train Epoch: 3 [40320/756 (83%)]\tLoss: 0.009040\n",
            "Train Epoch: 3 [40960/756 (85%)]\tLoss: 0.010302\n",
            "Train Epoch: 3 [41600/756 (86%)]\tLoss: 0.006955\n",
            "Train Epoch: 3 [42240/756 (87%)]\tLoss: 0.164243\n",
            "Train Epoch: 3 [42880/756 (89%)]\tLoss: 0.029580\n",
            "Train Epoch: 3 [43520/756 (90%)]\tLoss: 0.104119\n",
            "Train Epoch: 3 [44160/756 (91%)]\tLoss: 0.008102\n",
            "Train Epoch: 3 [44800/756 (93%)]\tLoss: 0.216441\n",
            "Train Epoch: 3 [45440/756 (94%)]\tLoss: 0.149642\n",
            "Train Epoch: 3 [46080/756 (95%)]\tLoss: 0.008281\n",
            "Train Epoch: 3 [46720/756 (97%)]\tLoss: 0.002130\n",
            "Train Epoch: 3 [47360/756 (98%)]\tLoss: 0.008162\n",
            "Train Epoch: 3 [48000/756 (99%)]\tLoss: 0.061980\n",
            "\n",
            "Test set: Average loss: 0.0411, Accuracy: 9870/10000 (99%)\n",
            "\n",
            "Train Epoch: 4 [0/756 (0%)]\tLoss: 0.026636\n",
            "Train Epoch: 4 [640/756 (1%)]\tLoss: 0.028107\n",
            "Train Epoch: 4 [1280/756 (3%)]\tLoss: 0.007350\n",
            "Train Epoch: 4 [1920/756 (4%)]\tLoss: 0.011878\n",
            "Train Epoch: 4 [2560/756 (5%)]\tLoss: 0.009051\n",
            "Train Epoch: 4 [3200/756 (7%)]\tLoss: 0.027009\n",
            "Train Epoch: 4 [3840/756 (8%)]\tLoss: 0.008009\n",
            "Train Epoch: 4 [4480/756 (9%)]\tLoss: 0.138191\n",
            "Train Epoch: 4 [5120/756 (11%)]\tLoss: 0.018268\n",
            "Train Epoch: 4 [5760/756 (12%)]\tLoss: 0.061536\n",
            "Train Epoch: 4 [6400/756 (13%)]\tLoss: 0.001684\n",
            "Train Epoch: 4 [7040/756 (15%)]\tLoss: 0.066472\n",
            "Train Epoch: 4 [7680/756 (16%)]\tLoss: 0.081939\n",
            "Train Epoch: 4 [8320/756 (17%)]\tLoss: 0.027101\n",
            "Train Epoch: 4 [8960/756 (19%)]\tLoss: 0.018009\n",
            "Train Epoch: 4 [9600/756 (20%)]\tLoss: 0.064780\n",
            "Train Epoch: 4 [10240/756 (21%)]\tLoss: 0.105099\n",
            "Train Epoch: 4 [10880/756 (22%)]\tLoss: 0.014217\n",
            "Train Epoch: 4 [11520/756 (24%)]\tLoss: 0.030127\n",
            "Train Epoch: 4 [12160/756 (25%)]\tLoss: 0.017703\n",
            "Train Epoch: 4 [12800/756 (26%)]\tLoss: 0.004273\n",
            "Train Epoch: 4 [13440/756 (28%)]\tLoss: 0.007080\n",
            "Train Epoch: 4 [14080/756 (29%)]\tLoss: 0.005688\n",
            "Train Epoch: 4 [14720/756 (30%)]\tLoss: 0.123503\n",
            "Train Epoch: 4 [15360/756 (32%)]\tLoss: 0.005189\n",
            "Train Epoch: 4 [16000/756 (33%)]\tLoss: 0.106343\n",
            "Train Epoch: 4 [16640/756 (34%)]\tLoss: 0.033675\n",
            "Train Epoch: 4 [17280/756 (36%)]\tLoss: 0.013068\n",
            "Train Epoch: 4 [17920/756 (37%)]\tLoss: 0.012709\n",
            "Train Epoch: 4 [18560/756 (38%)]\tLoss: 0.018560\n",
            "Train Epoch: 4 [19200/756 (40%)]\tLoss: 0.026650\n",
            "Train Epoch: 4 [19840/756 (41%)]\tLoss: 0.022834\n",
            "Train Epoch: 4 [20480/756 (42%)]\tLoss: 0.014628\n",
            "Train Epoch: 4 [21120/756 (44%)]\tLoss: 0.028311\n",
            "Train Epoch: 4 [21760/756 (45%)]\tLoss: 0.007230\n",
            "Train Epoch: 4 [22400/756 (46%)]\tLoss: 0.045478\n",
            "Train Epoch: 4 [23040/756 (48%)]\tLoss: 0.002311\n",
            "Train Epoch: 4 [23680/756 (49%)]\tLoss: 0.155605\n",
            "Train Epoch: 4 [24320/756 (50%)]\tLoss: 0.001893\n",
            "Train Epoch: 4 [24960/756 (52%)]\tLoss: 0.024043\n",
            "Train Epoch: 4 [25600/756 (53%)]\tLoss: 0.051745\n",
            "Train Epoch: 4 [26240/756 (54%)]\tLoss: 0.063226\n",
            "Train Epoch: 4 [26880/756 (56%)]\tLoss: 0.032295\n",
            "Train Epoch: 4 [27520/756 (57%)]\tLoss: 0.007384\n",
            "Train Epoch: 4 [28160/756 (58%)]\tLoss: 0.037214\n",
            "Train Epoch: 4 [28800/756 (60%)]\tLoss: 0.189650\n",
            "Train Epoch: 4 [29440/756 (61%)]\tLoss: 0.131114\n",
            "Train Epoch: 4 [30080/756 (62%)]\tLoss: 0.029409\n",
            "Train Epoch: 4 [30720/756 (63%)]\tLoss: 0.003987\n",
            "Train Epoch: 4 [31360/756 (65%)]\tLoss: 0.066175\n",
            "Train Epoch: 4 [32000/756 (66%)]\tLoss: 0.036771\n",
            "Train Epoch: 4 [32640/756 (67%)]\tLoss: 0.126616\n",
            "Train Epoch: 4 [33280/756 (69%)]\tLoss: 0.128188\n",
            "Train Epoch: 4 [33920/756 (70%)]\tLoss: 0.038306\n",
            "Train Epoch: 4 [34560/756 (71%)]\tLoss: 0.031509\n",
            "Train Epoch: 4 [35200/756 (73%)]\tLoss: 0.006627\n",
            "Train Epoch: 4 [35840/756 (74%)]\tLoss: 0.003390\n",
            "Train Epoch: 4 [36480/756 (75%)]\tLoss: 0.014819\n",
            "Train Epoch: 4 [37120/756 (77%)]\tLoss: 0.053023\n",
            "Train Epoch: 4 [37760/756 (78%)]\tLoss: 0.028342\n",
            "Train Epoch: 4 [38400/756 (79%)]\tLoss: 0.036700\n",
            "Train Epoch: 4 [39040/756 (81%)]\tLoss: 0.085595\n",
            "Train Epoch: 4 [39680/756 (82%)]\tLoss: 0.013103\n",
            "Train Epoch: 4 [40320/756 (83%)]\tLoss: 0.002556\n",
            "Train Epoch: 4 [40960/756 (85%)]\tLoss: 0.018300\n",
            "Train Epoch: 4 [41600/756 (86%)]\tLoss: 0.002936\n",
            "Train Epoch: 4 [42240/756 (87%)]\tLoss: 0.036519\n",
            "Train Epoch: 4 [42880/756 (89%)]\tLoss: 0.027843\n",
            "Train Epoch: 4 [43520/756 (90%)]\tLoss: 0.195085\n",
            "Train Epoch: 4 [44160/756 (91%)]\tLoss: 0.009119\n",
            "Train Epoch: 4 [44800/756 (93%)]\tLoss: 0.140195\n",
            "Train Epoch: 4 [45440/756 (94%)]\tLoss: 0.138513\n",
            "Train Epoch: 4 [46080/756 (95%)]\tLoss: 0.005354\n",
            "Train Epoch: 4 [46720/756 (97%)]\tLoss: 0.003163\n",
            "Train Epoch: 4 [47360/756 (98%)]\tLoss: 0.019171\n",
            "Train Epoch: 4 [48000/756 (99%)]\tLoss: 0.014007\n",
            "\n",
            "Test set: Average loss: 0.0334, Accuracy: 9890/10000 (99%)\n",
            "\n",
            "Train Epoch: 5 [0/756 (0%)]\tLoss: 0.018380\n",
            "Train Epoch: 5 [640/756 (1%)]\tLoss: 0.033535\n",
            "Train Epoch: 5 [1280/756 (3%)]\tLoss: 0.009349\n",
            "Train Epoch: 5 [1920/756 (4%)]\tLoss: 0.003170\n",
            "Train Epoch: 5 [2560/756 (5%)]\tLoss: 0.009093\n",
            "Train Epoch: 5 [3200/756 (7%)]\tLoss: 0.044584\n",
            "Train Epoch: 5 [3840/756 (8%)]\tLoss: 0.010657\n",
            "Train Epoch: 5 [4480/756 (9%)]\tLoss: 0.001564\n",
            "Train Epoch: 5 [5120/756 (11%)]\tLoss: 0.023369\n",
            "Train Epoch: 5 [5760/756 (12%)]\tLoss: 0.073101\n",
            "Train Epoch: 5 [6400/756 (13%)]\tLoss: 0.010783\n",
            "Train Epoch: 5 [7040/756 (15%)]\tLoss: 0.051478\n",
            "Train Epoch: 5 [7680/756 (16%)]\tLoss: 0.073186\n",
            "Train Epoch: 5 [8320/756 (17%)]\tLoss: 0.001390\n",
            "Train Epoch: 5 [8960/756 (19%)]\tLoss: 0.039116\n",
            "Train Epoch: 5 [9600/756 (20%)]\tLoss: 0.026789\n",
            "Train Epoch: 5 [10240/756 (21%)]\tLoss: 0.103654\n",
            "Train Epoch: 5 [10880/756 (22%)]\tLoss: 0.002688\n",
            "Train Epoch: 5 [11520/756 (24%)]\tLoss: 0.006548\n",
            "Train Epoch: 5 [12160/756 (25%)]\tLoss: 0.004980\n",
            "Train Epoch: 5 [12800/756 (26%)]\tLoss: 0.023784\n",
            "Train Epoch: 5 [13440/756 (28%)]\tLoss: 0.003786\n",
            "Train Epoch: 5 [14080/756 (29%)]\tLoss: 0.001037\n",
            "Train Epoch: 5 [14720/756 (30%)]\tLoss: 0.164196\n",
            "Train Epoch: 5 [15360/756 (32%)]\tLoss: 0.007417\n",
            "Train Epoch: 5 [16000/756 (33%)]\tLoss: 0.069515\n",
            "Train Epoch: 5 [16640/756 (34%)]\tLoss: 0.001250\n",
            "Train Epoch: 5 [17280/756 (36%)]\tLoss: 0.039743\n",
            "Train Epoch: 5 [17920/756 (37%)]\tLoss: 0.007575\n",
            "Train Epoch: 5 [18560/756 (38%)]\tLoss: 0.098834\n",
            "Train Epoch: 5 [19200/756 (40%)]\tLoss: 0.001779\n",
            "Train Epoch: 5 [19840/756 (41%)]\tLoss: 0.066058\n",
            "Train Epoch: 5 [20480/756 (42%)]\tLoss: 0.028303\n",
            "Train Epoch: 5 [21120/756 (44%)]\tLoss: 0.028839\n",
            "Train Epoch: 5 [21760/756 (45%)]\tLoss: 0.027520\n",
            "Train Epoch: 5 [22400/756 (46%)]\tLoss: 0.061858\n",
            "Train Epoch: 5 [23040/756 (48%)]\tLoss: 0.008278\n",
            "Train Epoch: 5 [23680/756 (49%)]\tLoss: 0.071598\n",
            "Train Epoch: 5 [24320/756 (50%)]\tLoss: 0.027751\n",
            "Train Epoch: 5 [24960/756 (52%)]\tLoss: 0.003848\n",
            "Train Epoch: 5 [25600/756 (53%)]\tLoss: 0.014931\n",
            "Train Epoch: 5 [26240/756 (54%)]\tLoss: 0.013527\n",
            "Train Epoch: 5 [26880/756 (56%)]\tLoss: 0.069436\n",
            "Train Epoch: 5 [27520/756 (57%)]\tLoss: 0.001523\n",
            "Train Epoch: 5 [28160/756 (58%)]\tLoss: 0.051393\n",
            "Train Epoch: 5 [28800/756 (60%)]\tLoss: 0.030876\n",
            "Train Epoch: 5 [29440/756 (61%)]\tLoss: 0.055888\n",
            "Train Epoch: 5 [30080/756 (62%)]\tLoss: 0.016702\n",
            "Train Epoch: 5 [30720/756 (63%)]\tLoss: 0.003599\n",
            "Train Epoch: 5 [31360/756 (65%)]\tLoss: 0.064536\n",
            "Train Epoch: 5 [32000/756 (66%)]\tLoss: 0.012709\n",
            "Train Epoch: 5 [32640/756 (67%)]\tLoss: 0.065198\n",
            "Train Epoch: 5 [33280/756 (69%)]\tLoss: 0.064859\n",
            "Train Epoch: 5 [33920/756 (70%)]\tLoss: 0.057982\n",
            "Train Epoch: 5 [34560/756 (71%)]\tLoss: 0.014583\n",
            "Train Epoch: 5 [35200/756 (73%)]\tLoss: 0.004204\n",
            "Train Epoch: 5 [35840/756 (74%)]\tLoss: 0.005375\n",
            "Train Epoch: 5 [36480/756 (75%)]\tLoss: 0.138370\n",
            "Train Epoch: 5 [37120/756 (77%)]\tLoss: 0.015529\n",
            "Train Epoch: 5 [37760/756 (78%)]\tLoss: 0.012095\n",
            "Train Epoch: 5 [38400/756 (79%)]\tLoss: 0.018685\n",
            "Train Epoch: 5 [39040/756 (81%)]\tLoss: 0.058131\n",
            "Train Epoch: 5 [39680/756 (82%)]\tLoss: 0.001496\n",
            "Train Epoch: 5 [40320/756 (83%)]\tLoss: 0.012970\n",
            "Train Epoch: 5 [40960/756 (85%)]\tLoss: 0.002120\n",
            "Train Epoch: 5 [41600/756 (86%)]\tLoss: 0.006641\n",
            "Train Epoch: 5 [42240/756 (87%)]\tLoss: 0.056047\n",
            "Train Epoch: 5 [42880/756 (89%)]\tLoss: 0.008733\n",
            "Train Epoch: 5 [43520/756 (90%)]\tLoss: 0.169973\n",
            "Train Epoch: 5 [44160/756 (91%)]\tLoss: 0.008959\n",
            "Train Epoch: 5 [44800/756 (93%)]\tLoss: 0.100502\n",
            "Train Epoch: 5 [45440/756 (94%)]\tLoss: 0.125807\n",
            "Train Epoch: 5 [46080/756 (95%)]\tLoss: 0.026103\n",
            "Train Epoch: 5 [46720/756 (97%)]\tLoss: 0.004126\n",
            "Train Epoch: 5 [47360/756 (98%)]\tLoss: 0.005390\n",
            "Train Epoch: 5 [48000/756 (99%)]\tLoss: 0.007027\n",
            "\n",
            "Test set: Average loss: 0.0333, Accuracy: 9890/10000 (99%)\n",
            "\n",
            "Train Epoch: 6 [0/756 (0%)]\tLoss: 0.056608\n",
            "Train Epoch: 6 [640/756 (1%)]\tLoss: 0.020258\n",
            "Train Epoch: 6 [1280/756 (3%)]\tLoss: 0.009266\n",
            "Train Epoch: 6 [1920/756 (4%)]\tLoss: 0.005268\n",
            "Train Epoch: 6 [2560/756 (5%)]\tLoss: 0.012130\n",
            "Train Epoch: 6 [3200/756 (7%)]\tLoss: 0.027366\n",
            "Train Epoch: 6 [3840/756 (8%)]\tLoss: 0.021336\n",
            "Train Epoch: 6 [4480/756 (9%)]\tLoss: 0.042571\n",
            "Train Epoch: 6 [5120/756 (11%)]\tLoss: 0.046028\n",
            "Train Epoch: 6 [5760/756 (12%)]\tLoss: 0.068906\n",
            "Train Epoch: 6 [6400/756 (13%)]\tLoss: 0.001414\n",
            "Train Epoch: 6 [7040/756 (15%)]\tLoss: 0.090743\n",
            "Train Epoch: 6 [7680/756 (16%)]\tLoss: 0.077741\n",
            "Train Epoch: 6 [8320/756 (17%)]\tLoss: 0.003073\n",
            "Train Epoch: 6 [8960/756 (19%)]\tLoss: 0.001260\n",
            "Train Epoch: 6 [9600/756 (20%)]\tLoss: 0.061061\n",
            "Train Epoch: 6 [10240/756 (21%)]\tLoss: 0.114839\n",
            "Train Epoch: 6 [10880/756 (22%)]\tLoss: 0.024511\n",
            "Train Epoch: 6 [11520/756 (24%)]\tLoss: 0.001479\n",
            "Train Epoch: 6 [12160/756 (25%)]\tLoss: 0.004531\n",
            "Train Epoch: 6 [12800/756 (26%)]\tLoss: 0.002697\n",
            "Train Epoch: 6 [13440/756 (28%)]\tLoss: 0.001440\n",
            "Train Epoch: 6 [14080/756 (29%)]\tLoss: 0.002544\n",
            "Train Epoch: 6 [14720/756 (30%)]\tLoss: 0.112655\n",
            "Train Epoch: 6 [15360/756 (32%)]\tLoss: 0.003895\n",
            "Train Epoch: 6 [16000/756 (33%)]\tLoss: 0.015524\n",
            "Train Epoch: 6 [16640/756 (34%)]\tLoss: 0.017181\n",
            "Train Epoch: 6 [17280/756 (36%)]\tLoss: 0.005670\n",
            "Train Epoch: 6 [17920/756 (37%)]\tLoss: 0.003772\n",
            "Train Epoch: 6 [18560/756 (38%)]\tLoss: 0.066633\n",
            "Train Epoch: 6 [19200/756 (40%)]\tLoss: 0.005886\n",
            "Train Epoch: 6 [19840/756 (41%)]\tLoss: 0.006805\n",
            "Train Epoch: 6 [20480/756 (42%)]\tLoss: 0.021429\n",
            "Train Epoch: 6 [21120/756 (44%)]\tLoss: 0.016549\n",
            "Train Epoch: 6 [21760/756 (45%)]\tLoss: 0.004853\n",
            "Train Epoch: 6 [22400/756 (46%)]\tLoss: 0.036176\n",
            "Train Epoch: 6 [23040/756 (48%)]\tLoss: 0.013287\n",
            "Train Epoch: 6 [23680/756 (49%)]\tLoss: 0.047549\n",
            "Train Epoch: 6 [24320/756 (50%)]\tLoss: 0.003283\n",
            "Train Epoch: 6 [24960/756 (52%)]\tLoss: 0.000774\n",
            "Train Epoch: 6 [25600/756 (53%)]\tLoss: 0.027644\n",
            "Train Epoch: 6 [26240/756 (54%)]\tLoss: 0.002925\n",
            "Train Epoch: 6 [26880/756 (56%)]\tLoss: 0.006346\n",
            "Train Epoch: 6 [27520/756 (57%)]\tLoss: 0.015146\n",
            "Train Epoch: 6 [28160/756 (58%)]\tLoss: 0.019316\n",
            "Train Epoch: 6 [28800/756 (60%)]\tLoss: 0.058974\n",
            "Train Epoch: 6 [29440/756 (61%)]\tLoss: 0.017949\n",
            "Train Epoch: 6 [30080/756 (62%)]\tLoss: 0.029422\n",
            "Train Epoch: 6 [30720/756 (63%)]\tLoss: 0.011862\n",
            "Train Epoch: 6 [31360/756 (65%)]\tLoss: 0.006918\n",
            "Train Epoch: 6 [32000/756 (66%)]\tLoss: 0.004755\n",
            "Train Epoch: 6 [32640/756 (67%)]\tLoss: 0.021943\n",
            "Train Epoch: 6 [33280/756 (69%)]\tLoss: 0.083912\n",
            "Train Epoch: 6 [33920/756 (70%)]\tLoss: 0.051975\n",
            "Train Epoch: 6 [34560/756 (71%)]\tLoss: 0.001490\n",
            "Train Epoch: 6 [35200/756 (73%)]\tLoss: 0.007170\n",
            "Train Epoch: 6 [35840/756 (74%)]\tLoss: 0.002378\n",
            "Train Epoch: 6 [36480/756 (75%)]\tLoss: 0.018485\n",
            "Train Epoch: 6 [37120/756 (77%)]\tLoss: 0.006312\n",
            "Train Epoch: 6 [37760/756 (78%)]\tLoss: 0.002558\n",
            "Train Epoch: 6 [38400/756 (79%)]\tLoss: 0.007794\n",
            "Train Epoch: 6 [39040/756 (81%)]\tLoss: 0.059265\n",
            "Train Epoch: 6 [39680/756 (82%)]\tLoss: 0.008880\n",
            "Train Epoch: 6 [40320/756 (83%)]\tLoss: 0.005777\n",
            "Train Epoch: 6 [40960/756 (85%)]\tLoss: 0.007310\n",
            "Train Epoch: 6 [41600/756 (86%)]\tLoss: 0.003069\n",
            "Train Epoch: 6 [42240/756 (87%)]\tLoss: 0.027009\n",
            "Train Epoch: 6 [42880/756 (89%)]\tLoss: 0.081693\n",
            "Train Epoch: 6 [43520/756 (90%)]\tLoss: 0.197191\n",
            "Train Epoch: 6 [44160/756 (91%)]\tLoss: 0.003055\n",
            "Train Epoch: 6 [44800/756 (93%)]\tLoss: 0.141378\n",
            "Train Epoch: 6 [45440/756 (94%)]\tLoss: 0.151220\n",
            "Train Epoch: 6 [46080/756 (95%)]\tLoss: 0.004145\n",
            "Train Epoch: 6 [46720/756 (97%)]\tLoss: 0.004108\n",
            "Train Epoch: 6 [47360/756 (98%)]\tLoss: 0.003530\n",
            "Train Epoch: 6 [48000/756 (99%)]\tLoss: 0.011655\n",
            "\n",
            "Test set: Average loss: 0.0296, Accuracy: 9894/10000 (99%)\n",
            "\n",
            "Train Epoch: 7 [0/756 (0%)]\tLoss: 0.038623\n",
            "Train Epoch: 7 [640/756 (1%)]\tLoss: 0.035358\n",
            "Train Epoch: 7 [1280/756 (3%)]\tLoss: 0.005070\n",
            "Train Epoch: 7 [1920/756 (4%)]\tLoss: 0.023771\n",
            "Train Epoch: 7 [2560/756 (5%)]\tLoss: 0.001572\n",
            "Train Epoch: 7 [3200/756 (7%)]\tLoss: 0.013995\n",
            "Train Epoch: 7 [3840/756 (8%)]\tLoss: 0.005297\n",
            "Train Epoch: 7 [4480/756 (9%)]\tLoss: 0.052446\n",
            "Train Epoch: 7 [5120/756 (11%)]\tLoss: 0.022649\n",
            "Train Epoch: 7 [5760/756 (12%)]\tLoss: 0.029187\n",
            "Train Epoch: 7 [6400/756 (13%)]\tLoss: 0.000800\n",
            "Train Epoch: 7 [7040/756 (15%)]\tLoss: 0.042627\n",
            "Train Epoch: 7 [7680/756 (16%)]\tLoss: 0.045706\n",
            "Train Epoch: 7 [8320/756 (17%)]\tLoss: 0.000079\n",
            "Train Epoch: 7 [8960/756 (19%)]\tLoss: 0.017814\n",
            "Train Epoch: 7 [9600/756 (20%)]\tLoss: 0.130961\n",
            "Train Epoch: 7 [10240/756 (21%)]\tLoss: 0.071819\n",
            "Train Epoch: 7 [10880/756 (22%)]\tLoss: 0.004516\n",
            "Train Epoch: 7 [11520/756 (24%)]\tLoss: 0.023539\n",
            "Train Epoch: 7 [12160/756 (25%)]\tLoss: 0.029785\n",
            "Train Epoch: 7 [12800/756 (26%)]\tLoss: 0.031469\n",
            "Train Epoch: 7 [13440/756 (28%)]\tLoss: 0.002557\n",
            "Train Epoch: 7 [14080/756 (29%)]\tLoss: 0.003698\n",
            "Train Epoch: 7 [14720/756 (30%)]\tLoss: 0.169824\n",
            "Train Epoch: 7 [15360/756 (32%)]\tLoss: 0.002657\n",
            "Train Epoch: 7 [16000/756 (33%)]\tLoss: 0.023858\n",
            "Train Epoch: 7 [16640/756 (34%)]\tLoss: 0.006286\n",
            "Train Epoch: 7 [17280/756 (36%)]\tLoss: 0.007785\n",
            "Train Epoch: 7 [17920/756 (37%)]\tLoss: 0.007872\n",
            "Train Epoch: 7 [18560/756 (38%)]\tLoss: 0.095242\n",
            "Train Epoch: 7 [19200/756 (40%)]\tLoss: 0.004655\n",
            "Train Epoch: 7 [19840/756 (41%)]\tLoss: 0.003354\n",
            "Train Epoch: 7 [20480/756 (42%)]\tLoss: 0.051656\n",
            "Train Epoch: 7 [21120/756 (44%)]\tLoss: 0.031595\n",
            "Train Epoch: 7 [21760/756 (45%)]\tLoss: 0.002152\n",
            "Train Epoch: 7 [22400/756 (46%)]\tLoss: 0.010021\n",
            "Train Epoch: 7 [23040/756 (48%)]\tLoss: 0.016733\n",
            "Train Epoch: 7 [23680/756 (49%)]\tLoss: 0.014304\n",
            "Train Epoch: 7 [24320/756 (50%)]\tLoss: 0.027839\n",
            "Train Epoch: 7 [24960/756 (52%)]\tLoss: 0.005615\n",
            "Train Epoch: 7 [25600/756 (53%)]\tLoss: 0.030720\n",
            "Train Epoch: 7 [26240/756 (54%)]\tLoss: 0.061685\n",
            "Train Epoch: 7 [26880/756 (56%)]\tLoss: 0.016618\n",
            "Train Epoch: 7 [27520/756 (57%)]\tLoss: 0.000432\n",
            "Train Epoch: 7 [28160/756 (58%)]\tLoss: 0.010841\n",
            "Train Epoch: 7 [28800/756 (60%)]\tLoss: 0.043434\n",
            "Train Epoch: 7 [29440/756 (61%)]\tLoss: 0.021231\n",
            "Train Epoch: 7 [30080/756 (62%)]\tLoss: 0.001556\n",
            "Train Epoch: 7 [30720/756 (63%)]\tLoss: 0.005074\n",
            "Train Epoch: 7 [31360/756 (65%)]\tLoss: 0.018015\n",
            "Train Epoch: 7 [32000/756 (66%)]\tLoss: 0.035520\n",
            "Train Epoch: 7 [32640/756 (67%)]\tLoss: 0.016992\n",
            "Train Epoch: 7 [33280/756 (69%)]\tLoss: 0.070550\n",
            "Train Epoch: 7 [33920/756 (70%)]\tLoss: 0.024928\n",
            "Train Epoch: 7 [34560/756 (71%)]\tLoss: 0.030502\n",
            "Train Epoch: 7 [35200/756 (73%)]\tLoss: 0.008624\n",
            "Train Epoch: 7 [35840/756 (74%)]\tLoss: 0.003534\n",
            "Train Epoch: 7 [36480/756 (75%)]\tLoss: 0.076798\n",
            "Train Epoch: 7 [37120/756 (77%)]\tLoss: 0.011143\n",
            "Train Epoch: 7 [37760/756 (78%)]\tLoss: 0.009682\n",
            "Train Epoch: 7 [38400/756 (79%)]\tLoss: 0.017081\n",
            "Train Epoch: 7 [39040/756 (81%)]\tLoss: 0.075979\n",
            "Train Epoch: 7 [39680/756 (82%)]\tLoss: 0.001104\n",
            "Train Epoch: 7 [40320/756 (83%)]\tLoss: 0.003895\n",
            "Train Epoch: 7 [40960/756 (85%)]\tLoss: 0.024622\n",
            "Train Epoch: 7 [41600/756 (86%)]\tLoss: 0.004655\n",
            "Train Epoch: 7 [42240/756 (87%)]\tLoss: 0.009869\n",
            "Train Epoch: 7 [42880/756 (89%)]\tLoss: 0.015652\n",
            "Train Epoch: 7 [43520/756 (90%)]\tLoss: 0.258317\n",
            "Train Epoch: 7 [44160/756 (91%)]\tLoss: 0.007593\n",
            "Train Epoch: 7 [44800/756 (93%)]\tLoss: 0.202492\n",
            "Train Epoch: 7 [45440/756 (94%)]\tLoss: 0.107077\n",
            "Train Epoch: 7 [46080/756 (95%)]\tLoss: 0.005101\n",
            "Train Epoch: 7 [46720/756 (97%)]\tLoss: 0.001787\n",
            "Train Epoch: 7 [47360/756 (98%)]\tLoss: 0.038032\n",
            "Train Epoch: 7 [48000/756 (99%)]\tLoss: 0.008044\n",
            "\n",
            "Test set: Average loss: 0.0306, Accuracy: 9901/10000 (99%)\n",
            "\n",
            "Train Epoch: 8 [0/756 (0%)]\tLoss: 0.026712\n",
            "Train Epoch: 8 [640/756 (1%)]\tLoss: 0.010204\n",
            "Train Epoch: 8 [1280/756 (3%)]\tLoss: 0.006059\n",
            "Train Epoch: 8 [1920/756 (4%)]\tLoss: 0.003469\n",
            "Train Epoch: 8 [2560/756 (5%)]\tLoss: 0.003075\n",
            "Train Epoch: 8 [3200/756 (7%)]\tLoss: 0.027513\n",
            "Train Epoch: 8 [3840/756 (8%)]\tLoss: 0.004884\n",
            "Train Epoch: 8 [4480/756 (9%)]\tLoss: 0.015796\n",
            "Train Epoch: 8 [5120/756 (11%)]\tLoss: 0.007327\n",
            "Train Epoch: 8 [5760/756 (12%)]\tLoss: 0.015863\n",
            "Train Epoch: 8 [6400/756 (13%)]\tLoss: 0.004246\n",
            "Train Epoch: 8 [7040/756 (15%)]\tLoss: 0.081324\n",
            "Train Epoch: 8 [7680/756 (16%)]\tLoss: 0.037469\n",
            "Train Epoch: 8 [8320/756 (17%)]\tLoss: 0.000316\n",
            "Train Epoch: 8 [8960/756 (19%)]\tLoss: 0.002038\n",
            "Train Epoch: 8 [9600/756 (20%)]\tLoss: 0.037244\n",
            "Train Epoch: 8 [10240/756 (21%)]\tLoss: 0.006240\n",
            "Train Epoch: 8 [10880/756 (22%)]\tLoss: 0.000356\n",
            "Train Epoch: 8 [11520/756 (24%)]\tLoss: 0.017853\n",
            "Train Epoch: 8 [12160/756 (25%)]\tLoss: 0.004348\n",
            "Train Epoch: 8 [12800/756 (26%)]\tLoss: 0.066704\n",
            "Train Epoch: 8 [13440/756 (28%)]\tLoss: 0.001915\n",
            "Train Epoch: 8 [14080/756 (29%)]\tLoss: 0.004780\n",
            "Train Epoch: 8 [14720/756 (30%)]\tLoss: 0.150437\n",
            "Train Epoch: 8 [15360/756 (32%)]\tLoss: 0.001668\n",
            "Train Epoch: 8 [16000/756 (33%)]\tLoss: 0.079208\n",
            "Train Epoch: 8 [16640/756 (34%)]\tLoss: 0.000979\n",
            "Train Epoch: 8 [17280/756 (36%)]\tLoss: 0.004856\n",
            "Train Epoch: 8 [17920/756 (37%)]\tLoss: 0.004974\n",
            "Train Epoch: 8 [18560/756 (38%)]\tLoss: 0.101569\n",
            "Train Epoch: 8 [19200/756 (40%)]\tLoss: 0.021855\n",
            "Train Epoch: 8 [19840/756 (41%)]\tLoss: 0.009686\n",
            "Train Epoch: 8 [20480/756 (42%)]\tLoss: 0.012302\n",
            "Train Epoch: 8 [21120/756 (44%)]\tLoss: 0.005700\n",
            "Train Epoch: 8 [21760/756 (45%)]\tLoss: 0.002076\n",
            "Train Epoch: 8 [22400/756 (46%)]\tLoss: 0.003266\n",
            "Train Epoch: 8 [23040/756 (48%)]\tLoss: 0.037881\n",
            "Train Epoch: 8 [23680/756 (49%)]\tLoss: 0.038128\n",
            "Train Epoch: 8 [24320/756 (50%)]\tLoss: 0.002924\n",
            "Train Epoch: 8 [24960/756 (52%)]\tLoss: 0.003109\n",
            "Train Epoch: 8 [25600/756 (53%)]\tLoss: 0.018924\n",
            "Train Epoch: 8 [26240/756 (54%)]\tLoss: 0.004594\n",
            "Train Epoch: 8 [26880/756 (56%)]\tLoss: 0.030499\n",
            "Train Epoch: 8 [27520/756 (57%)]\tLoss: 0.001159\n",
            "Train Epoch: 8 [28160/756 (58%)]\tLoss: 0.011945\n",
            "Train Epoch: 8 [28800/756 (60%)]\tLoss: 0.018311\n",
            "Train Epoch: 8 [29440/756 (61%)]\tLoss: 0.029270\n",
            "Train Epoch: 8 [30080/756 (62%)]\tLoss: 0.005807\n",
            "Train Epoch: 8 [30720/756 (63%)]\tLoss: 0.004409\n",
            "Train Epoch: 8 [31360/756 (65%)]\tLoss: 0.009183\n",
            "Train Epoch: 8 [32000/756 (66%)]\tLoss: 0.011958\n",
            "Train Epoch: 8 [32640/756 (67%)]\tLoss: 0.050051\n",
            "Train Epoch: 8 [33280/756 (69%)]\tLoss: 0.153171\n",
            "Train Epoch: 8 [33920/756 (70%)]\tLoss: 0.026221\n",
            "Train Epoch: 8 [34560/756 (71%)]\tLoss: 0.001020\n",
            "Train Epoch: 8 [35200/756 (73%)]\tLoss: 0.004182\n",
            "Train Epoch: 8 [35840/756 (74%)]\tLoss: 0.013899\n",
            "Train Epoch: 8 [36480/756 (75%)]\tLoss: 0.040040\n",
            "Train Epoch: 8 [37120/756 (77%)]\tLoss: 0.064027\n",
            "Train Epoch: 8 [37760/756 (78%)]\tLoss: 0.003801\n",
            "Train Epoch: 8 [38400/756 (79%)]\tLoss: 0.015803\n",
            "Train Epoch: 8 [39040/756 (81%)]\tLoss: 0.011214\n",
            "Train Epoch: 8 [39680/756 (82%)]\tLoss: 0.003109\n",
            "Train Epoch: 8 [40320/756 (83%)]\tLoss: 0.002010\n",
            "Train Epoch: 8 [40960/756 (85%)]\tLoss: 0.001657\n",
            "Train Epoch: 8 [41600/756 (86%)]\tLoss: 0.001986\n",
            "Train Epoch: 8 [42240/756 (87%)]\tLoss: 0.024501\n",
            "Train Epoch: 8 [42880/756 (89%)]\tLoss: 0.015087\n",
            "Train Epoch: 8 [43520/756 (90%)]\tLoss: 0.215975\n",
            "Train Epoch: 8 [44160/756 (91%)]\tLoss: 0.009596\n",
            "Train Epoch: 8 [44800/756 (93%)]\tLoss: 0.156122\n",
            "Train Epoch: 8 [45440/756 (94%)]\tLoss: 0.110548\n",
            "Train Epoch: 8 [46080/756 (95%)]\tLoss: 0.038568\n",
            "Train Epoch: 8 [46720/756 (97%)]\tLoss: 0.001328\n",
            "Train Epoch: 8 [47360/756 (98%)]\tLoss: 0.028887\n",
            "Train Epoch: 8 [48000/756 (99%)]\tLoss: 0.007924\n",
            "\n",
            "Test set: Average loss: 0.0287, Accuracy: 9899/10000 (99%)\n",
            "\n",
            "Train Epoch: 9 [0/756 (0%)]\tLoss: 0.033146\n",
            "Train Epoch: 9 [640/756 (1%)]\tLoss: 0.044383\n",
            "Train Epoch: 9 [1280/756 (3%)]\tLoss: 0.005442\n",
            "Train Epoch: 9 [1920/756 (4%)]\tLoss: 0.028671\n",
            "Train Epoch: 9 [2560/756 (5%)]\tLoss: 0.004152\n",
            "Train Epoch: 9 [3200/756 (7%)]\tLoss: 0.004823\n",
            "Train Epoch: 9 [3840/756 (8%)]\tLoss: 0.014266\n",
            "Train Epoch: 9 [4480/756 (9%)]\tLoss: 0.003961\n",
            "Train Epoch: 9 [5120/756 (11%)]\tLoss: 0.013083\n",
            "Train Epoch: 9 [5760/756 (12%)]\tLoss: 0.017984\n",
            "Train Epoch: 9 [6400/756 (13%)]\tLoss: 0.008148\n",
            "Train Epoch: 9 [7040/756 (15%)]\tLoss: 0.007415\n",
            "Train Epoch: 9 [7680/756 (16%)]\tLoss: 0.062034\n",
            "Train Epoch: 9 [8320/756 (17%)]\tLoss: 0.004981\n",
            "Train Epoch: 9 [8960/756 (19%)]\tLoss: 0.053887\n",
            "Train Epoch: 9 [9600/756 (20%)]\tLoss: 0.078485\n",
            "Train Epoch: 9 [10240/756 (21%)]\tLoss: 0.114749\n",
            "Train Epoch: 9 [10880/756 (22%)]\tLoss: 0.001836\n",
            "Train Epoch: 9 [11520/756 (24%)]\tLoss: 0.049633\n",
            "Train Epoch: 9 [12160/756 (25%)]\tLoss: 0.004466\n",
            "Train Epoch: 9 [12800/756 (26%)]\tLoss: 0.009542\n",
            "Train Epoch: 9 [13440/756 (28%)]\tLoss: 0.000457\n",
            "Train Epoch: 9 [14080/756 (29%)]\tLoss: 0.049555\n",
            "Train Epoch: 9 [14720/756 (30%)]\tLoss: 0.050058\n",
            "Train Epoch: 9 [15360/756 (32%)]\tLoss: 0.005104\n",
            "Train Epoch: 9 [16000/756 (33%)]\tLoss: 0.078955\n",
            "Train Epoch: 9 [16640/756 (34%)]\tLoss: 0.005239\n",
            "Train Epoch: 9 [17280/756 (36%)]\tLoss: 0.001291\n",
            "Train Epoch: 9 [17920/756 (37%)]\tLoss: 0.003321\n",
            "Train Epoch: 9 [18560/756 (38%)]\tLoss: 0.096458\n",
            "Train Epoch: 9 [19200/756 (40%)]\tLoss: 0.006628\n",
            "Train Epoch: 9 [19840/756 (41%)]\tLoss: 0.007050\n",
            "Train Epoch: 9 [20480/756 (42%)]\tLoss: 0.001811\n",
            "Train Epoch: 9 [21120/756 (44%)]\tLoss: 0.019180\n",
            "Train Epoch: 9 [21760/756 (45%)]\tLoss: 0.001336\n",
            "Train Epoch: 9 [22400/756 (46%)]\tLoss: 0.001408\n",
            "Train Epoch: 9 [23040/756 (48%)]\tLoss: 0.001342\n",
            "Train Epoch: 9 [23680/756 (49%)]\tLoss: 0.049420\n",
            "Train Epoch: 9 [24320/756 (50%)]\tLoss: 0.006278\n",
            "Train Epoch: 9 [24960/756 (52%)]\tLoss: 0.007172\n",
            "Train Epoch: 9 [25600/756 (53%)]\tLoss: 0.034031\n",
            "Train Epoch: 9 [26240/756 (54%)]\tLoss: 0.006365\n",
            "Train Epoch: 9 [26880/756 (56%)]\tLoss: 0.005625\n",
            "Train Epoch: 9 [27520/756 (57%)]\tLoss: 0.008387\n",
            "Train Epoch: 9 [28160/756 (58%)]\tLoss: 0.004977\n",
            "Train Epoch: 9 [28800/756 (60%)]\tLoss: 0.012905\n",
            "Train Epoch: 9 [29440/756 (61%)]\tLoss: 0.028982\n",
            "Train Epoch: 9 [30080/756 (62%)]\tLoss: 0.043892\n",
            "Train Epoch: 9 [30720/756 (63%)]\tLoss: 0.007685\n",
            "Train Epoch: 9 [31360/756 (65%)]\tLoss: 0.068964\n",
            "Train Epoch: 9 [32000/756 (66%)]\tLoss: 0.035052\n",
            "Train Epoch: 9 [32640/756 (67%)]\tLoss: 0.019007\n",
            "Train Epoch: 9 [33280/756 (69%)]\tLoss: 0.011689\n",
            "Train Epoch: 9 [33920/756 (70%)]\tLoss: 0.036648\n",
            "Train Epoch: 9 [34560/756 (71%)]\tLoss: 0.000783\n",
            "Train Epoch: 9 [35200/756 (73%)]\tLoss: 0.001384\n",
            "Train Epoch: 9 [35840/756 (74%)]\tLoss: 0.000681\n",
            "Train Epoch: 9 [36480/756 (75%)]\tLoss: 0.003208\n",
            "Train Epoch: 9 [37120/756 (77%)]\tLoss: 0.018800\n",
            "Train Epoch: 9 [37760/756 (78%)]\tLoss: 0.010638\n",
            "Train Epoch: 9 [38400/756 (79%)]\tLoss: 0.003154\n",
            "Train Epoch: 9 [39040/756 (81%)]\tLoss: 0.123444\n",
            "Train Epoch: 9 [39680/756 (82%)]\tLoss: 0.001619\n",
            "Train Epoch: 9 [40320/756 (83%)]\tLoss: 0.002160\n",
            "Train Epoch: 9 [40960/756 (85%)]\tLoss: 0.001191\n",
            "Train Epoch: 9 [41600/756 (86%)]\tLoss: 0.003295\n",
            "Train Epoch: 9 [42240/756 (87%)]\tLoss: 0.104357\n",
            "Train Epoch: 9 [42880/756 (89%)]\tLoss: 0.006537\n",
            "Train Epoch: 9 [43520/756 (90%)]\tLoss: 0.106410\n",
            "Train Epoch: 9 [44160/756 (91%)]\tLoss: 0.003160\n",
            "Train Epoch: 9 [44800/756 (93%)]\tLoss: 0.134791\n",
            "Train Epoch: 9 [45440/756 (94%)]\tLoss: 0.086988\n",
            "Train Epoch: 9 [46080/756 (95%)]\tLoss: 0.020074\n",
            "Train Epoch: 9 [46720/756 (97%)]\tLoss: 0.000157\n",
            "Train Epoch: 9 [47360/756 (98%)]\tLoss: 0.012883\n",
            "Train Epoch: 9 [48000/756 (99%)]\tLoss: 0.007333\n",
            "\n",
            "Test set: Average loss: 0.0295, Accuracy: 9897/10000 (99%)\n",
            "\n",
            "Train Epoch: 10 [0/756 (0%)]\tLoss: 0.006405\n",
            "Train Epoch: 10 [640/756 (1%)]\tLoss: 0.041816\n",
            "Train Epoch: 10 [1280/756 (3%)]\tLoss: 0.012161\n",
            "Train Epoch: 10 [1920/756 (4%)]\tLoss: 0.004853\n",
            "Train Epoch: 10 [2560/756 (5%)]\tLoss: 0.002880\n",
            "Train Epoch: 10 [3200/756 (7%)]\tLoss: 0.032597\n",
            "Train Epoch: 10 [3840/756 (8%)]\tLoss: 0.015966\n",
            "Train Epoch: 10 [4480/756 (9%)]\tLoss: 0.058255\n",
            "Train Epoch: 10 [5120/756 (11%)]\tLoss: 0.031614\n",
            "Train Epoch: 10 [5760/756 (12%)]\tLoss: 0.032298\n",
            "Train Epoch: 10 [6400/756 (13%)]\tLoss: 0.001485\n",
            "Train Epoch: 10 [7040/756 (15%)]\tLoss: 0.093341\n",
            "Train Epoch: 10 [7680/756 (16%)]\tLoss: 0.074785\n",
            "Train Epoch: 10 [8320/756 (17%)]\tLoss: 0.001387\n",
            "Train Epoch: 10 [8960/756 (19%)]\tLoss: 0.017580\n",
            "Train Epoch: 10 [9600/756 (20%)]\tLoss: 0.069120\n",
            "Train Epoch: 10 [10240/756 (21%)]\tLoss: 0.085698\n",
            "Train Epoch: 10 [10880/756 (22%)]\tLoss: 0.031026\n",
            "Train Epoch: 10 [11520/756 (24%)]\tLoss: 0.002647\n",
            "Train Epoch: 10 [12160/756 (25%)]\tLoss: 0.012474\n",
            "Train Epoch: 10 [12800/756 (26%)]\tLoss: 0.007142\n",
            "Train Epoch: 10 [13440/756 (28%)]\tLoss: 0.006482\n",
            "Train Epoch: 10 [14080/756 (29%)]\tLoss: 0.009499\n",
            "Train Epoch: 10 [14720/756 (30%)]\tLoss: 0.108915\n",
            "Train Epoch: 10 [15360/756 (32%)]\tLoss: 0.020094\n",
            "Train Epoch: 10 [16000/756 (33%)]\tLoss: 0.130986\n",
            "Train Epoch: 10 [16640/756 (34%)]\tLoss: 0.035889\n",
            "Train Epoch: 10 [17280/756 (36%)]\tLoss: 0.007810\n",
            "Train Epoch: 10 [17920/756 (37%)]\tLoss: 0.005352\n",
            "Train Epoch: 10 [18560/756 (38%)]\tLoss: 0.098123\n",
            "Train Epoch: 10 [19200/756 (40%)]\tLoss: 0.009237\n",
            "Train Epoch: 10 [19840/756 (41%)]\tLoss: 0.023722\n",
            "Train Epoch: 10 [20480/756 (42%)]\tLoss: 0.029793\n",
            "Train Epoch: 10 [21120/756 (44%)]\tLoss: 0.011119\n",
            "Train Epoch: 10 [21760/756 (45%)]\tLoss: 0.001138\n",
            "Train Epoch: 10 [22400/756 (46%)]\tLoss: 0.014283\n",
            "Train Epoch: 10 [23040/756 (48%)]\tLoss: 0.002445\n",
            "Train Epoch: 10 [23680/756 (49%)]\tLoss: 0.005920\n",
            "Train Epoch: 10 [24320/756 (50%)]\tLoss: 0.008777\n",
            "Train Epoch: 10 [24960/756 (52%)]\tLoss: 0.001930\n",
            "Train Epoch: 10 [25600/756 (53%)]\tLoss: 0.128773\n",
            "Train Epoch: 10 [26240/756 (54%)]\tLoss: 0.001726\n",
            "Train Epoch: 10 [26880/756 (56%)]\tLoss: 0.012302\n",
            "Train Epoch: 10 [27520/756 (57%)]\tLoss: 0.015392\n",
            "Train Epoch: 10 [28160/756 (58%)]\tLoss: 0.009705\n",
            "Train Epoch: 10 [28800/756 (60%)]\tLoss: 0.005211\n",
            "Train Epoch: 10 [29440/756 (61%)]\tLoss: 0.020225\n",
            "Train Epoch: 10 [30080/756 (62%)]\tLoss: 0.006614\n",
            "Train Epoch: 10 [30720/756 (63%)]\tLoss: 0.003489\n",
            "Train Epoch: 10 [31360/756 (65%)]\tLoss: 0.027026\n",
            "Train Epoch: 10 [32000/756 (66%)]\tLoss: 0.001539\n",
            "Train Epoch: 10 [32640/756 (67%)]\tLoss: 0.021093\n",
            "Train Epoch: 10 [33280/756 (69%)]\tLoss: 0.023490\n",
            "Train Epoch: 10 [33920/756 (70%)]\tLoss: 0.045730\n",
            "Train Epoch: 10 [34560/756 (71%)]\tLoss: 0.002379\n",
            "Train Epoch: 10 [35200/756 (73%)]\tLoss: 0.005496\n",
            "Train Epoch: 10 [35840/756 (74%)]\tLoss: 0.008524\n",
            "Train Epoch: 10 [36480/756 (75%)]\tLoss: 0.108054\n",
            "Train Epoch: 10 [37120/756 (77%)]\tLoss: 0.034899\n",
            "Train Epoch: 10 [37760/756 (78%)]\tLoss: 0.002478\n",
            "Train Epoch: 10 [38400/756 (79%)]\tLoss: 0.020253\n",
            "Train Epoch: 10 [39040/756 (81%)]\tLoss: 0.016999\n",
            "Train Epoch: 10 [39680/756 (82%)]\tLoss: 0.032247\n",
            "Train Epoch: 10 [40320/756 (83%)]\tLoss: 0.003883\n",
            "Train Epoch: 10 [40960/756 (85%)]\tLoss: 0.000905\n",
            "Train Epoch: 10 [41600/756 (86%)]\tLoss: 0.001430\n",
            "Train Epoch: 10 [42240/756 (87%)]\tLoss: 0.112003\n",
            "Train Epoch: 10 [42880/756 (89%)]\tLoss: 0.076177\n",
            "Train Epoch: 10 [43520/756 (90%)]\tLoss: 0.220423\n",
            "Train Epoch: 10 [44160/756 (91%)]\tLoss: 0.002390\n",
            "Train Epoch: 10 [44800/756 (93%)]\tLoss: 0.086101\n",
            "Train Epoch: 10 [45440/756 (94%)]\tLoss: 0.083599\n",
            "Train Epoch: 10 [46080/756 (95%)]\tLoss: 0.007640\n",
            "Train Epoch: 10 [46720/756 (97%)]\tLoss: 0.002521\n",
            "Train Epoch: 10 [47360/756 (98%)]\tLoss: 0.004559\n",
            "Train Epoch: 10 [48000/756 (99%)]\tLoss: 0.003315\n",
            "\n",
            "Test set: Average loss: 0.0285, Accuracy: 9903/10000 (99%)\n",
            "\n",
            "Train Epoch: 11 [0/756 (0%)]\tLoss: 0.017264\n",
            "Train Epoch: 11 [640/756 (1%)]\tLoss: 0.063652\n",
            "Train Epoch: 11 [1280/756 (3%)]\tLoss: 0.008044\n",
            "Train Epoch: 11 [1920/756 (4%)]\tLoss: 0.008104\n",
            "Train Epoch: 11 [2560/756 (5%)]\tLoss: 0.001944\n",
            "Train Epoch: 11 [3200/756 (7%)]\tLoss: 0.018581\n",
            "Train Epoch: 11 [3840/756 (8%)]\tLoss: 0.008742\n",
            "Train Epoch: 11 [4480/756 (9%)]\tLoss: 0.044543\n",
            "Train Epoch: 11 [5120/756 (11%)]\tLoss: 0.008670\n",
            "Train Epoch: 11 [5760/756 (12%)]\tLoss: 0.014636\n",
            "Train Epoch: 11 [6400/756 (13%)]\tLoss: 0.001570\n",
            "Train Epoch: 11 [7040/756 (15%)]\tLoss: 0.085269\n",
            "Train Epoch: 11 [7680/756 (16%)]\tLoss: 0.139438\n",
            "Train Epoch: 11 [8320/756 (17%)]\tLoss: 0.002027\n",
            "Train Epoch: 11 [8960/756 (19%)]\tLoss: 0.001573\n",
            "Train Epoch: 11 [9600/756 (20%)]\tLoss: 0.114289\n",
            "Train Epoch: 11 [10240/756 (21%)]\tLoss: 0.089673\n",
            "Train Epoch: 11 [10880/756 (22%)]\tLoss: 0.000923\n",
            "Train Epoch: 11 [11520/756 (24%)]\tLoss: 0.003783\n",
            "Train Epoch: 11 [12160/756 (25%)]\tLoss: 0.005980\n",
            "Train Epoch: 11 [12800/756 (26%)]\tLoss: 0.004048\n",
            "Train Epoch: 11 [13440/756 (28%)]\tLoss: 0.003574\n",
            "Train Epoch: 11 [14080/756 (29%)]\tLoss: 0.001306\n",
            "Train Epoch: 11 [14720/756 (30%)]\tLoss: 0.206096\n",
            "Train Epoch: 11 [15360/756 (32%)]\tLoss: 0.005970\n",
            "Train Epoch: 11 [16000/756 (33%)]\tLoss: 0.002876\n",
            "Train Epoch: 11 [16640/756 (34%)]\tLoss: 0.000435\n",
            "Train Epoch: 11 [17280/756 (36%)]\tLoss: 0.003603\n",
            "Train Epoch: 11 [17920/756 (37%)]\tLoss: 0.017574\n",
            "Train Epoch: 11 [18560/756 (38%)]\tLoss: 0.047290\n",
            "Train Epoch: 11 [19200/756 (40%)]\tLoss: 0.006957\n",
            "Train Epoch: 11 [19840/756 (41%)]\tLoss: 0.004041\n",
            "Train Epoch: 11 [20480/756 (42%)]\tLoss: 0.021189\n",
            "Train Epoch: 11 [21120/756 (44%)]\tLoss: 0.014713\n",
            "Train Epoch: 11 [21760/756 (45%)]\tLoss: 0.000113\n",
            "Train Epoch: 11 [22400/756 (46%)]\tLoss: 0.000509\n",
            "Train Epoch: 11 [23040/756 (48%)]\tLoss: 0.000710\n",
            "Train Epoch: 11 [23680/756 (49%)]\tLoss: 0.025182\n",
            "Train Epoch: 11 [24320/756 (50%)]\tLoss: 0.007540\n",
            "Train Epoch: 11 [24960/756 (52%)]\tLoss: 0.009791\n",
            "Train Epoch: 11 [25600/756 (53%)]\tLoss: 0.003493\n",
            "Train Epoch: 11 [26240/756 (54%)]\tLoss: 0.008169\n",
            "Train Epoch: 11 [26880/756 (56%)]\tLoss: 0.006835\n",
            "Train Epoch: 11 [27520/756 (57%)]\tLoss: 0.004473\n",
            "Train Epoch: 11 [28160/756 (58%)]\tLoss: 0.060844\n",
            "Train Epoch: 11 [28800/756 (60%)]\tLoss: 0.019498\n",
            "Train Epoch: 11 [29440/756 (61%)]\tLoss: 0.021889\n",
            "Train Epoch: 11 [30080/756 (62%)]\tLoss: 0.009802\n",
            "Train Epoch: 11 [30720/756 (63%)]\tLoss: 0.033628\n",
            "Train Epoch: 11 [31360/756 (65%)]\tLoss: 0.043192\n",
            "Train Epoch: 11 [32000/756 (66%)]\tLoss: 0.038107\n",
            "Train Epoch: 11 [32640/756 (67%)]\tLoss: 0.004020\n",
            "Train Epoch: 11 [33280/756 (69%)]\tLoss: 0.038249\n",
            "Train Epoch: 11 [33920/756 (70%)]\tLoss: 0.012668\n",
            "Train Epoch: 11 [34560/756 (71%)]\tLoss: 0.000369\n",
            "Train Epoch: 11 [35200/756 (73%)]\tLoss: 0.023091\n",
            "Train Epoch: 11 [35840/756 (74%)]\tLoss: 0.000846\n",
            "Train Epoch: 11 [36480/756 (75%)]\tLoss: 0.014023\n",
            "Train Epoch: 11 [37120/756 (77%)]\tLoss: 0.026815\n",
            "Train Epoch: 11 [37760/756 (78%)]\tLoss: 0.000589\n",
            "Train Epoch: 11 [38400/756 (79%)]\tLoss: 0.007180\n",
            "Train Epoch: 11 [39040/756 (81%)]\tLoss: 0.058471\n",
            "Train Epoch: 11 [39680/756 (82%)]\tLoss: 0.001088\n",
            "Train Epoch: 11 [40320/756 (83%)]\tLoss: 0.004059\n",
            "Train Epoch: 11 [40960/756 (85%)]\tLoss: 0.001287\n",
            "Train Epoch: 11 [41600/756 (86%)]\tLoss: 0.002159\n",
            "Train Epoch: 11 [42240/756 (87%)]\tLoss: 0.024760\n",
            "Train Epoch: 11 [42880/756 (89%)]\tLoss: 0.009301\n",
            "Train Epoch: 11 [43520/756 (90%)]\tLoss: 0.250369\n",
            "Train Epoch: 11 [44160/756 (91%)]\tLoss: 0.003686\n",
            "Train Epoch: 11 [44800/756 (93%)]\tLoss: 0.128920\n",
            "Train Epoch: 11 [45440/756 (94%)]\tLoss: 0.063549\n",
            "Train Epoch: 11 [46080/756 (95%)]\tLoss: 0.003825\n",
            "Train Epoch: 11 [46720/756 (97%)]\tLoss: 0.001074\n",
            "Train Epoch: 11 [47360/756 (98%)]\tLoss: 0.009474\n",
            "Train Epoch: 11 [48000/756 (99%)]\tLoss: 0.021440\n",
            "\n",
            "Test set: Average loss: 0.0291, Accuracy: 9894/10000 (99%)\n",
            "\n",
            "Train Epoch: 12 [0/756 (0%)]\tLoss: 0.010700\n",
            "Train Epoch: 12 [640/756 (1%)]\tLoss: 0.036203\n",
            "Train Epoch: 12 [1280/756 (3%)]\tLoss: 0.004323\n",
            "Train Epoch: 12 [1920/756 (4%)]\tLoss: 0.006507\n",
            "Train Epoch: 12 [2560/756 (5%)]\tLoss: 0.005466\n",
            "Train Epoch: 12 [3200/756 (7%)]\tLoss: 0.023235\n",
            "Train Epoch: 12 [3840/756 (8%)]\tLoss: 0.058321\n",
            "Train Epoch: 12 [4480/756 (9%)]\tLoss: 0.007909\n",
            "Train Epoch: 12 [5120/756 (11%)]\tLoss: 0.052164\n",
            "Train Epoch: 12 [5760/756 (12%)]\tLoss: 0.030145\n",
            "Train Epoch: 12 [6400/756 (13%)]\tLoss: 0.005679\n",
            "Train Epoch: 12 [7040/756 (15%)]\tLoss: 0.047526\n",
            "Train Epoch: 12 [7680/756 (16%)]\tLoss: 0.058472\n",
            "Train Epoch: 12 [8320/756 (17%)]\tLoss: 0.001143\n",
            "Train Epoch: 12 [8960/756 (19%)]\tLoss: 0.001260\n",
            "Train Epoch: 12 [9600/756 (20%)]\tLoss: 0.060924\n",
            "Train Epoch: 12 [10240/756 (21%)]\tLoss: 0.108007\n",
            "Train Epoch: 12 [10880/756 (22%)]\tLoss: 0.041198\n",
            "Train Epoch: 12 [11520/756 (24%)]\tLoss: 0.017099\n",
            "Train Epoch: 12 [12160/756 (25%)]\tLoss: 0.015123\n",
            "Train Epoch: 12 [12800/756 (26%)]\tLoss: 0.013632\n",
            "Train Epoch: 12 [13440/756 (28%)]\tLoss: 0.007799\n",
            "Train Epoch: 12 [14080/756 (29%)]\tLoss: 0.014543\n",
            "Train Epoch: 12 [14720/756 (30%)]\tLoss: 0.327604\n",
            "Train Epoch: 12 [15360/756 (32%)]\tLoss: 0.011060\n",
            "Train Epoch: 12 [16000/756 (33%)]\tLoss: 0.012157\n",
            "Train Epoch: 12 [16640/756 (34%)]\tLoss: 0.002008\n",
            "Train Epoch: 12 [17280/756 (36%)]\tLoss: 0.028025\n",
            "Train Epoch: 12 [17920/756 (37%)]\tLoss: 0.000177\n",
            "Train Epoch: 12 [18560/756 (38%)]\tLoss: 0.068199\n",
            "Train Epoch: 12 [19200/756 (40%)]\tLoss: 0.038428\n",
            "Train Epoch: 12 [19840/756 (41%)]\tLoss: 0.007458\n",
            "Train Epoch: 12 [20480/756 (42%)]\tLoss: 0.014446\n",
            "Train Epoch: 12 [21120/756 (44%)]\tLoss: 0.005484\n",
            "Train Epoch: 12 [21760/756 (45%)]\tLoss: 0.005782\n",
            "Train Epoch: 12 [22400/756 (46%)]\tLoss: 0.001901\n",
            "Train Epoch: 12 [23040/756 (48%)]\tLoss: 0.000619\n",
            "Train Epoch: 12 [23680/756 (49%)]\tLoss: 0.040142\n",
            "Train Epoch: 12 [24320/756 (50%)]\tLoss: 0.002087\n",
            "Train Epoch: 12 [24960/756 (52%)]\tLoss: 0.001098\n",
            "Train Epoch: 12 [25600/756 (53%)]\tLoss: 0.023272\n",
            "Train Epoch: 12 [26240/756 (54%)]\tLoss: 0.009874\n",
            "Train Epoch: 12 [26880/756 (56%)]\tLoss: 0.023545\n",
            "Train Epoch: 12 [27520/756 (57%)]\tLoss: 0.017775\n",
            "Train Epoch: 12 [28160/756 (58%)]\tLoss: 0.023213\n",
            "Train Epoch: 12 [28800/756 (60%)]\tLoss: 0.101949\n",
            "Train Epoch: 12 [29440/756 (61%)]\tLoss: 0.008389\n",
            "Train Epoch: 12 [30080/756 (62%)]\tLoss: 0.002256\n",
            "Train Epoch: 12 [30720/756 (63%)]\tLoss: 0.031057\n",
            "Train Epoch: 12 [31360/756 (65%)]\tLoss: 0.020474\n",
            "Train Epoch: 12 [32000/756 (66%)]\tLoss: 0.006429\n",
            "Train Epoch: 12 [32640/756 (67%)]\tLoss: 0.002345\n",
            "Train Epoch: 12 [33280/756 (69%)]\tLoss: 0.023382\n",
            "Train Epoch: 12 [33920/756 (70%)]\tLoss: 0.006648\n",
            "Train Epoch: 12 [34560/756 (71%)]\tLoss: 0.006253\n",
            "Train Epoch: 12 [35200/756 (73%)]\tLoss: 0.009216\n",
            "Train Epoch: 12 [35840/756 (74%)]\tLoss: 0.001249\n",
            "Train Epoch: 12 [36480/756 (75%)]\tLoss: 0.005082\n",
            "Train Epoch: 12 [37120/756 (77%)]\tLoss: 0.025512\n",
            "Train Epoch: 12 [37760/756 (78%)]\tLoss: 0.010939\n",
            "Train Epoch: 12 [38400/756 (79%)]\tLoss: 0.009825\n",
            "Train Epoch: 12 [39040/756 (81%)]\tLoss: 0.040207\n",
            "Train Epoch: 12 [39680/756 (82%)]\tLoss: 0.002691\n",
            "Train Epoch: 12 [40320/756 (83%)]\tLoss: 0.015318\n",
            "Train Epoch: 12 [40960/756 (85%)]\tLoss: 0.002389\n",
            "Train Epoch: 12 [41600/756 (86%)]\tLoss: 0.001095\n",
            "Train Epoch: 12 [42240/756 (87%)]\tLoss: 0.022399\n",
            "Train Epoch: 12 [42880/756 (89%)]\tLoss: 0.024639\n",
            "Train Epoch: 12 [43520/756 (90%)]\tLoss: 0.190287\n",
            "Train Epoch: 12 [44160/756 (91%)]\tLoss: 0.008785\n",
            "Train Epoch: 12 [44800/756 (93%)]\tLoss: 0.133264\n",
            "Train Epoch: 12 [45440/756 (94%)]\tLoss: 0.055522\n",
            "Train Epoch: 12 [46080/756 (95%)]\tLoss: 0.006189\n",
            "Train Epoch: 12 [46720/756 (97%)]\tLoss: 0.000470\n",
            "Train Epoch: 12 [47360/756 (98%)]\tLoss: 0.002330\n",
            "Train Epoch: 12 [48000/756 (99%)]\tLoss: 0.001879\n",
            "\n",
            "Test set: Average loss: 0.0284, Accuracy: 9903/10000 (99%)\n",
            "\n",
            "Train Epoch: 13 [0/756 (0%)]\tLoss: 0.011778\n",
            "Train Epoch: 13 [640/756 (1%)]\tLoss: 0.036024\n",
            "Train Epoch: 13 [1280/756 (3%)]\tLoss: 0.013491\n",
            "Train Epoch: 13 [1920/756 (4%)]\tLoss: 0.006374\n",
            "Train Epoch: 13 [2560/756 (5%)]\tLoss: 0.003019\n",
            "Train Epoch: 13 [3200/756 (7%)]\tLoss: 0.023268\n",
            "Train Epoch: 13 [3840/756 (8%)]\tLoss: 0.006633\n",
            "Train Epoch: 13 [4480/756 (9%)]\tLoss: 0.032030\n",
            "Train Epoch: 13 [5120/756 (11%)]\tLoss: 0.007095\n",
            "Train Epoch: 13 [5760/756 (12%)]\tLoss: 0.028997\n",
            "Train Epoch: 13 [6400/756 (13%)]\tLoss: 0.002086\n",
            "Train Epoch: 13 [7040/756 (15%)]\tLoss: 0.005783\n",
            "Train Epoch: 13 [7680/756 (16%)]\tLoss: 0.028299\n",
            "Train Epoch: 13 [8320/756 (17%)]\tLoss: 0.000891\n",
            "Train Epoch: 13 [8960/756 (19%)]\tLoss: 0.023036\n",
            "Train Epoch: 13 [9600/756 (20%)]\tLoss: 0.118863\n",
            "Train Epoch: 13 [10240/756 (21%)]\tLoss: 0.062233\n",
            "Train Epoch: 13 [10880/756 (22%)]\tLoss: 0.002930\n",
            "Train Epoch: 13 [11520/756 (24%)]\tLoss: 0.001845\n",
            "Train Epoch: 13 [12160/756 (25%)]\tLoss: 0.004984\n",
            "Train Epoch: 13 [12800/756 (26%)]\tLoss: 0.004255\n",
            "Train Epoch: 13 [13440/756 (28%)]\tLoss: 0.024248\n",
            "Train Epoch: 13 [14080/756 (29%)]\tLoss: 0.019363\n",
            "Train Epoch: 13 [14720/756 (30%)]\tLoss: 0.033635\n",
            "Train Epoch: 13 [15360/756 (32%)]\tLoss: 0.001468\n",
            "Train Epoch: 13 [16000/756 (33%)]\tLoss: 0.074980\n",
            "Train Epoch: 13 [16640/756 (34%)]\tLoss: 0.000901\n",
            "Train Epoch: 13 [17280/756 (36%)]\tLoss: 0.018389\n",
            "Train Epoch: 13 [17920/756 (37%)]\tLoss: 0.006189\n",
            "Train Epoch: 13 [18560/756 (38%)]\tLoss: 0.058715\n",
            "Train Epoch: 13 [19200/756 (40%)]\tLoss: 0.008618\n",
            "Train Epoch: 13 [19840/756 (41%)]\tLoss: 0.018323\n",
            "Train Epoch: 13 [20480/756 (42%)]\tLoss: 0.013194\n",
            "Train Epoch: 13 [21120/756 (44%)]\tLoss: 0.016023\n",
            "Train Epoch: 13 [21760/756 (45%)]\tLoss: 0.044326\n",
            "Train Epoch: 13 [22400/756 (46%)]\tLoss: 0.004761\n",
            "Train Epoch: 13 [23040/756 (48%)]\tLoss: 0.004889\n",
            "Train Epoch: 13 [23680/756 (49%)]\tLoss: 0.026408\n",
            "Train Epoch: 13 [24320/756 (50%)]\tLoss: 0.000689\n",
            "Train Epoch: 13 [24960/756 (52%)]\tLoss: 0.004792\n",
            "Train Epoch: 13 [25600/756 (53%)]\tLoss: 0.012193\n",
            "Train Epoch: 13 [26240/756 (54%)]\tLoss: 0.005564\n",
            "Train Epoch: 13 [26880/756 (56%)]\tLoss: 0.039642\n",
            "Train Epoch: 13 [27520/756 (57%)]\tLoss: 0.002513\n",
            "Train Epoch: 13 [28160/756 (58%)]\tLoss: 0.008874\n",
            "Train Epoch: 13 [28800/756 (60%)]\tLoss: 0.023530\n",
            "Train Epoch: 13 [29440/756 (61%)]\tLoss: 0.029407\n",
            "Train Epoch: 13 [30080/756 (62%)]\tLoss: 0.004525\n",
            "Train Epoch: 13 [30720/756 (63%)]\tLoss: 0.004749\n",
            "Train Epoch: 13 [31360/756 (65%)]\tLoss: 0.047821\n",
            "Train Epoch: 13 [32000/756 (66%)]\tLoss: 0.070956\n",
            "Train Epoch: 13 [32640/756 (67%)]\tLoss: 0.016160\n",
            "Train Epoch: 13 [33280/756 (69%)]\tLoss: 0.011272\n",
            "Train Epoch: 13 [33920/756 (70%)]\tLoss: 0.030009\n",
            "Train Epoch: 13 [34560/756 (71%)]\tLoss: 0.020774\n",
            "Train Epoch: 13 [35200/756 (73%)]\tLoss: 0.001041\n",
            "Train Epoch: 13 [35840/756 (74%)]\tLoss: 0.000805\n",
            "Train Epoch: 13 [36480/756 (75%)]\tLoss: 0.011065\n",
            "Train Epoch: 13 [37120/756 (77%)]\tLoss: 0.052956\n",
            "Train Epoch: 13 [37760/756 (78%)]\tLoss: 0.001658\n",
            "Train Epoch: 13 [38400/756 (79%)]\tLoss: 0.006859\n",
            "Train Epoch: 13 [39040/756 (81%)]\tLoss: 0.098659\n",
            "Train Epoch: 13 [39680/756 (82%)]\tLoss: 0.001660\n",
            "Train Epoch: 13 [40320/756 (83%)]\tLoss: 0.010485\n",
            "Train Epoch: 13 [40960/756 (85%)]\tLoss: 0.000624\n",
            "Train Epoch: 13 [41600/756 (86%)]\tLoss: 0.003753\n",
            "Train Epoch: 13 [42240/756 (87%)]\tLoss: 0.018590\n",
            "Train Epoch: 13 [42880/756 (89%)]\tLoss: 0.037706\n",
            "Train Epoch: 13 [43520/756 (90%)]\tLoss: 0.364300\n",
            "Train Epoch: 13 [44160/756 (91%)]\tLoss: 0.000215\n",
            "Train Epoch: 13 [44800/756 (93%)]\tLoss: 0.052935\n",
            "Train Epoch: 13 [45440/756 (94%)]\tLoss: 0.109173\n",
            "Train Epoch: 13 [46080/756 (95%)]\tLoss: 0.026059\n",
            "Train Epoch: 13 [46720/756 (97%)]\tLoss: 0.003444\n",
            "Train Epoch: 13 [47360/756 (98%)]\tLoss: 0.038314\n",
            "Train Epoch: 13 [48000/756 (99%)]\tLoss: 0.005098\n",
            "\n",
            "Test set: Average loss: 0.0280, Accuracy: 9903/10000 (99%)\n",
            "\n",
            "Train Epoch: 14 [0/756 (0%)]\tLoss: 0.003429\n",
            "Train Epoch: 14 [640/756 (1%)]\tLoss: 0.012821\n",
            "Train Epoch: 14 [1280/756 (3%)]\tLoss: 0.005680\n",
            "Train Epoch: 14 [1920/756 (4%)]\tLoss: 0.005984\n",
            "Train Epoch: 14 [2560/756 (5%)]\tLoss: 0.007290\n",
            "Train Epoch: 14 [3200/756 (7%)]\tLoss: 0.014008\n",
            "Train Epoch: 14 [3840/756 (8%)]\tLoss: 0.033626\n",
            "Train Epoch: 14 [4480/756 (9%)]\tLoss: 0.024546\n",
            "Train Epoch: 14 [5120/756 (11%)]\tLoss: 0.047659\n",
            "Train Epoch: 14 [5760/756 (12%)]\tLoss: 0.069791\n",
            "Train Epoch: 14 [6400/756 (13%)]\tLoss: 0.004748\n",
            "Train Epoch: 14 [7040/756 (15%)]\tLoss: 0.061805\n",
            "Train Epoch: 14 [7680/756 (16%)]\tLoss: 0.037511\n",
            "Train Epoch: 14 [8320/756 (17%)]\tLoss: 0.000972\n",
            "Train Epoch: 14 [8960/756 (19%)]\tLoss: 0.024927\n",
            "Train Epoch: 14 [9600/756 (20%)]\tLoss: 0.073658\n",
            "Train Epoch: 14 [10240/756 (21%)]\tLoss: 0.022959\n",
            "Train Epoch: 14 [10880/756 (22%)]\tLoss: 0.037279\n",
            "Train Epoch: 14 [11520/756 (24%)]\tLoss: 0.006561\n",
            "Train Epoch: 14 [12160/756 (25%)]\tLoss: 0.014897\n",
            "Train Epoch: 14 [12800/756 (26%)]\tLoss: 0.045031\n",
            "Train Epoch: 14 [13440/756 (28%)]\tLoss: 0.005242\n",
            "Train Epoch: 14 [14080/756 (29%)]\tLoss: 0.002077\n",
            "Train Epoch: 14 [14720/756 (30%)]\tLoss: 0.188120\n",
            "Train Epoch: 14 [15360/756 (32%)]\tLoss: 0.018822\n",
            "Train Epoch: 14 [16000/756 (33%)]\tLoss: 0.010587\n",
            "Train Epoch: 14 [16640/756 (34%)]\tLoss: 0.000788\n",
            "Train Epoch: 14 [17280/756 (36%)]\tLoss: 0.023207\n",
            "Train Epoch: 14 [17920/756 (37%)]\tLoss: 0.001984\n",
            "Train Epoch: 14 [18560/756 (38%)]\tLoss: 0.046620\n",
            "Train Epoch: 14 [19200/756 (40%)]\tLoss: 0.005700\n",
            "Train Epoch: 14 [19840/756 (41%)]\tLoss: 0.052013\n",
            "Train Epoch: 14 [20480/756 (42%)]\tLoss: 0.015470\n",
            "Train Epoch: 14 [21120/756 (44%)]\tLoss: 0.036147\n",
            "Train Epoch: 14 [21760/756 (45%)]\tLoss: 0.000644\n",
            "Train Epoch: 14 [22400/756 (46%)]\tLoss: 0.003749\n",
            "Train Epoch: 14 [23040/756 (48%)]\tLoss: 0.022238\n",
            "Train Epoch: 14 [23680/756 (49%)]\tLoss: 0.107758\n",
            "Train Epoch: 14 [24320/756 (50%)]\tLoss: 0.000491\n",
            "Train Epoch: 14 [24960/756 (52%)]\tLoss: 0.006690\n",
            "Train Epoch: 14 [25600/756 (53%)]\tLoss: 0.005630\n",
            "Train Epoch: 14 [26240/756 (54%)]\tLoss: 0.001645\n",
            "Train Epoch: 14 [26880/756 (56%)]\tLoss: 0.023392\n",
            "Train Epoch: 14 [27520/756 (57%)]\tLoss: 0.000853\n",
            "Train Epoch: 14 [28160/756 (58%)]\tLoss: 0.007432\n",
            "Train Epoch: 14 [28800/756 (60%)]\tLoss: 0.035162\n",
            "Train Epoch: 14 [29440/756 (61%)]\tLoss: 0.030034\n",
            "Train Epoch: 14 [30080/756 (62%)]\tLoss: 0.006488\n",
            "Train Epoch: 14 [30720/756 (63%)]\tLoss: 0.002611\n",
            "Train Epoch: 14 [31360/756 (65%)]\tLoss: 0.013977\n",
            "Train Epoch: 14 [32000/756 (66%)]\tLoss: 0.005650\n",
            "Train Epoch: 14 [32640/756 (67%)]\tLoss: 0.011365\n",
            "Train Epoch: 14 [33280/756 (69%)]\tLoss: 0.028574\n",
            "Train Epoch: 14 [33920/756 (70%)]\tLoss: 0.004503\n",
            "Train Epoch: 14 [34560/756 (71%)]\tLoss: 0.026208\n",
            "Train Epoch: 14 [35200/756 (73%)]\tLoss: 0.004205\n",
            "Train Epoch: 14 [35840/756 (74%)]\tLoss: 0.000243\n",
            "Train Epoch: 14 [36480/756 (75%)]\tLoss: 0.032355\n",
            "Train Epoch: 14 [37120/756 (77%)]\tLoss: 0.005458\n",
            "Train Epoch: 14 [37760/756 (78%)]\tLoss: 0.012826\n",
            "Train Epoch: 14 [38400/756 (79%)]\tLoss: 0.020786\n",
            "Train Epoch: 14 [39040/756 (81%)]\tLoss: 0.075085\n",
            "Train Epoch: 14 [39680/756 (82%)]\tLoss: 0.012144\n",
            "Train Epoch: 14 [40320/756 (83%)]\tLoss: 0.007126\n",
            "Train Epoch: 14 [40960/756 (85%)]\tLoss: 0.001604\n",
            "Train Epoch: 14 [41600/756 (86%)]\tLoss: 0.001174\n",
            "Train Epoch: 14 [42240/756 (87%)]\tLoss: 0.124798\n",
            "Train Epoch: 14 [42880/756 (89%)]\tLoss: 0.016244\n",
            "Train Epoch: 14 [43520/756 (90%)]\tLoss: 0.121034\n",
            "Train Epoch: 14 [44160/756 (91%)]\tLoss: 0.015672\n",
            "Train Epoch: 14 [44800/756 (93%)]\tLoss: 0.199474\n",
            "Train Epoch: 14 [45440/756 (94%)]\tLoss: 0.080717\n",
            "Train Epoch: 14 [46080/756 (95%)]\tLoss: 0.005344\n",
            "Train Epoch: 14 [46720/756 (97%)]\tLoss: 0.000904\n",
            "Train Epoch: 14 [47360/756 (98%)]\tLoss: 0.002498\n",
            "Train Epoch: 14 [48000/756 (99%)]\tLoss: 0.005549\n",
            "\n",
            "Test set: Average loss: 0.0285, Accuracy: 9903/10000 (99%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To free memory\n",
        "del cgan_loader\n",
        "del train_loader_new\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92HNnbRWT2Of",
        "outputId": "e8a02b92-89a2-41bd-af27-ae1d1ca1ec44"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "252"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, test_pred_new, test_acc = model_accuracy(model_new)\n",
        "\n",
        "test_pred_new_freq = Counter(test_pred_new).items()\n",
        "test_pred_new_freq = sorted(test_pred_new_freq)\n",
        "test_pred_new_freq = [x[1] for x in test_pred_new_freq]\n",
        "test_pred_new_prop = [x/(len(test_pred_new)) for x in test_pred_new_freq]\n",
        "print(f\"Our CNN model accuracy with Real + Fake: {test_acc/100}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gdkx4Hyz9X_",
        "outputId": "51030b2b-fc53-40b4-cd50-394b7fea3769"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our CNN model accuracy with Real + Fake: 99.03%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = [95.27, 98.07, 98.61, 99.05, 99.03, 99.1]\n",
        "percent = [0, 10, 20, 50, 70, 100]"
      ],
      "metadata": {
        "id": "mRG7IKMx3ZVF"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig4 = go.Figure()\n",
        "fig4.add_trace(go.Scatter(x=percent, y=accuracy, mode=\"markers+lines\"))\n",
        "fig4.update_layout(title=\"6,400 Generated Images\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "-DWu07ii4e4c",
        "outputId": "2a5082f9-be78-48e1-c10e-6a4b73c4a9e6"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"b877da40-484a-4d9e-bea0-b16af1378a97\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"b877da40-484a-4d9e-bea0-b16af1378a97\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'b877da40-484a-4d9e-bea0-b16af1378a97',\n",
              "                        [{\"mode\": \"markers+lines\", \"type\": \"scatter\", \"x\": [0, 10, 20, 50, 70, 100], \"y\": [95.27, 98.07, 98.61, 99.05, 99.03, 99.1]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"6,400 Generated Images\"}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b877da40-484a-4d9e-bea0-b16af1378a97');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pick 100 images from each\n",
        "images_list = []\n",
        "labels_list = []\n",
        "for i in range(10):\n",
        "  images_l = []\n",
        "  labels_l = []\n",
        "  for batch_idx, (images, labels) in enumerate(train_loader_):\n",
        "    for j in range(labels.shape[0]):\n",
        "      if labels[j] == i:\n",
        "        images_l.append(images[j])\n",
        "        labels_l.append(i)\n",
        "        break\n",
        "    if len(images_l) == 10:\n",
        "      break\n",
        "  images_list += images_l\n",
        "  labels_list += labels_l\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "  images_l = []\n",
        "  labels_l = []\n",
        "  for batch_idx, (images, labels) in enumerate(cgan_loader):\n",
        "    for j in range(labels.shape[0]):\n",
        "      if labels[j] == i:\n",
        "        images_l.append(images[j])\n",
        "        labels_l.append(i)\n",
        "        break\n",
        "    if len(images_l) == 10:\n",
        "      break\n",
        "  images_list += images_l\n",
        "  labels_list += labels_l\n"
      ],
      "metadata": {
        "id": "3Lv6wU_390JU"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = [x.view(1,-1).cpu() for x in images_list]\n",
        "X = torch.cat(X)\n",
        "X = X.detach().numpy()\n",
        "from sklearn.manifold import TSNE\n",
        "X_embedded = TSNE(n_components=2, learning_rate='auto', init='random').fit_transform(X)\n"
      ],
      "metadata": {
        "id": "Mz8m_7FVBX9m"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_list2 = [int(x) for x in labels_list]\n",
        "print(Counter(labels_list2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbP3vjTFHbAn",
        "outputId": "b9d2d13e-dbcc-4514-dafa-f7f06ab63642"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({0: 20, 1: 20, 2: 20, 3: 20, 4: 20, 5: 20, 6: 20, 7: 20, 8: 20, 9: 20})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(X_embedded, columns=[\"dim1\", \"dim2\"])\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "70_NKwNCHHki",
        "outputId": "0700d6e4-79f8-464b-901c-79438ce0746d"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dim1</th>\n",
              "      <th>dim2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-8.666754</td>\n",
              "      <td>7.264682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-7.390353</td>\n",
              "      <td>5.807877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-7.232492</td>\n",
              "      <td>7.727518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-6.909755</td>\n",
              "      <td>8.057596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-8.954045</td>\n",
              "      <td>6.156674</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       dim1      dim2\n",
              "0 -8.666754  7.264682\n",
              "1 -7.390353  5.807877\n",
              "2 -7.232492  7.727518\n",
              "3 -6.909755  8.057596\n",
              "4 -8.954045  6.156674"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = [0 for x in range(100)]\n",
        "x += [1 for x in range(100)]\n",
        "len(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S98XqFtQIMV7",
        "outputId": "54192f70-6b49-4f55-8193-6496252c03e3"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"binary\"] = x"
      ],
      "metadata": {
        "id": "wl7Cf6LQJzeC"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "fig7 = px.scatter(df, x=\"dim1\", y=\"dim2\", color=\"binary\")\n",
        "fig7.update_layout(title=\"Embedded by tSNE\",template=\"plotly_dark\")\n",
        "fig7.update_xaxes(title_text='X')\n",
        "fig7.update_yaxes(title_text='Y')\n",
        "fig7.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "b9HUeqydISkE",
        "outputId": "5afb6c1a-0532-46e8-d58a-b9b0da7f5bdc"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"187cfadd-df29-4277-b31a-f4dc0e7a141b\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"187cfadd-df29-4277-b31a-f4dc0e7a141b\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '187cfadd-df29-4277-b31a-f4dc0e7a141b',\n",
              "                        [{\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"dim1=%{x}<br>dim2=%{y}<br>binary=%{marker.color}\", \"legendgroup\": \"\", \"marker\": {\"color\": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"coloraxis\": \"coloraxis\", \"symbol\": \"circle\"}, \"mode\": \"markers\", \"name\": \"\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [-8.666753768920898, -7.390353202819824, -7.232492446899414, -6.909754753112793, -8.954045295715332, -7.611145973205566, -9.564101219177246, -9.434149742126465, -7.295305252075195, -7.454127788543701, -10.524175643920898, -9.175257682800293, -8.81389331817627, -13.882057189941406, -11.4022798538208, -9.835463523864746, -10.255035400390625, -11.174118041992188, -10.019181251525879, -7.077816009521484, -3.3689839839935303, -13.595321655273438, -10.354828834533691, -5.267651081085205, -4.4605488777160645, -3.654745101928711, -5.2277302742004395, -11.67592716217041, -9.958425521850586, -13.570388793945312, -6.4294304847717285, -7.503538131713867, -7.477725505828857, -13.369513511657715, -12.759215354919434, -6.055011749267578, -2.3304224014282227, -8.269360542297363, -8.379834175109863, -7.924066066741943, -5.165909767150879, -14.921554565429688, -4.818414211273193, -2.650742769241333, -4.370608329772949, -5.509191989898682, -3.7326555252075195, -3.1649458408355713, -2.3055362701416016, -3.404996633529663, -13.167892456054688, -14.90971565246582, -14.667717933654785, -8.657421112060547, -11.834100723266602, -11.13168716430664, -10.323345184326172, -8.841290473937988, -12.762574195861816, -8.425579071044922, -10.458257675170898, -5.898021697998047, 1.0156488418579102, -7.699429988861084, -3.7619597911834717, -7.5743865966796875, -8.970476150512695, -4.047072410583496, -10.28831958770752, -5.853754043579102, -1.7032033205032349, -1.368870496749878, -3.0212512016296387, -0.04668177664279938, 14.753961563110352, 14.689090728759766, -0.6839391589164734, -1.1003984212875366, 0.29731786251068115, -2.045926570892334, -10.760149002075195, -8.187684059143066, -13.793596267700195, -7.694868564605713, -2.086745262145996, -6.687389850616455, -8.11231517791748, -7.651722431182861, -11.482454299926758, -8.688432693481445, -7.063141345977783, -3.0082640647888184, -5.353935718536377, -0.6564327478408813, -3.822953939437866, -6.029382705688477, -6.872069835662842, -6.002457618713379, -4.9180121421813965, -2.4154136180877686, 1.826939582824707, 0.32081785798072815, -1.6570698022842407, 0.07654646784067154, 2.3691282272338867, -2.5424273014068604, -1.5376445055007935, 3.254516839981079, 1.0872923135757446, -1.9256647825241089, 6.944561958312988, 6.853419780731201, 7.276249885559082, 7.536945819854736, 4.81335973739624, 7.9488301277160645, 5.65326452255249, 7.246654033660889, 6.549212455749512, 6.194728851318359, 3.6129651069641113, 5.104109287261963, 7.848895072937012, 6.0839056968688965, 4.232728004455566, 4.580990314483643, 6.947047710418701, 2.8119051456451416, 6.535282611846924, 4.924754619598389, -0.8263726234436035, -0.47654691338539124, -1.2056463956832886, 4.5722737312316895, 0.363577276468277, 0.22458219528198242, 1.209451675415039, 2.452565908432007, 2.278751850128174, 3.3807919025421143, 11.828825950622559, 10.407882690429688, 9.95229434967041, 11.227583885192871, 14.099621772766113, 10.31086254119873, 9.33802604675293, 10.49348258972168, 9.461309432983398, 9.687700271606445, 3.9277353286743164, 5.1982035636901855, 7.207079887390137, -0.48549962043762207, 3.9741334915161133, 3.9371817111968994, 3.5746188163757324, 7.167145729064941, 1.2872494459152222, 5.157453536987305, 10.612187385559082, 10.553351402282715, 5.961460590362549, 5.167293548583984, 11.242565155029297, 6.168613433837891, 8.456974029541016, 4.821167945861816, 10.174605369567871, 5.350918769836426, 8.9039306640625, 11.878921508789062, 12.538169860839844, 12.394264221191406, 7.698854446411133, 11.543376922607422, 13.724897384643555, 13.090991020202637, 10.10048770904541, 7.633097171783447, 0.9016110301017761, 3.937467575073242, 3.1217753887176514, 8.229145050048828, 1.9377704858779907, 8.782950401306152, 5.493292808532715, 2.51792311668396, 2.0062625408172607, -2.208369731903076, 11.74289608001709, 10.109640121459961, 10.232364654541016, 10.869876861572266, 8.11149787902832, 8.26683235168457, 10.671039581298828, 7.456775188446045, 11.18099308013916, 11.508612632751465], \"xaxis\": \"x\", \"y\": [7.264681816101074, 5.807877063751221, 7.727517604827881, 8.057596206665039, 6.156673908233643, 3.244288444519043, 4.07464599609375, 3.4128706455230713, 3.3523683547973633, 6.263034343719482, -10.054093360900879, -8.198526382446289, -7.500777244567871, -10.930821418762207, -10.20690631866455, -9.074949264526367, -10.909976959228516, -9.68440055847168, -9.494214057922363, -7.910766124725342, -16.516998291015625, -12.472373962402344, -13.209179878234863, -16.36385726928711, -16.663265228271484, -17.343935012817383, -13.354253768920898, -11.609295845031738, -13.873526573181152, -8.024694442749023, -13.753609657287598, -9.93817138671875, -10.931025505065918, -5.2726569175720215, -4.8635993003845215, -11.5253324508667, -6.924456596374512, -11.275145530700684, -12.173253059387207, -5.431277275085449, -8.555469512939453, -10.555597305297852, -8.443256378173828, -2.250816822052002, -2.4112021923065186, -6.791842937469482, -1.4087553024291992, -2.763108015060425, -4.918669700622559, -3.644624948501587, -1.7127777338027954, -2.1626033782958984, -2.115356206893921, -3.0656793117523193, -2.094081401824951, -2.633589744567871, -4.446250915527344, -6.912099361419678, -10.314401626586914, -9.087985038757324, 1.4238520860671997, 0.63385009765625, -5.77344274520874, -1.4384962320327759, 0.14814254641532898, 1.5169990062713623, 1.2088850736618042, -0.8404291272163391, 1.4832684993743896, 0.5651408433914185, -8.958890914916992, -9.375060081481934, -12.407668113708496, -11.258008003234863, 9.004074096679688, 9.170580863952637, -8.48234748840332, -8.948968887329102, -11.381901741027832, -10.703802108764648, -5.8160576820373535, -16.132354736328125, -5.495272636413574, -13.786676406860352, -13.405375480651855, -11.945568084716797, -16.003068923950195, -14.830660820007324, -6.254759311676025, -4.334231376647949, -5.052648067474365, -10.324292182922363, -9.669527053833008, -11.943428039550781, -10.730265617370605, -6.00434684753418, -3.902379035949707, -5.610803127288818, -10.262080192565918, -11.603297233581543, 10.624403953552246, 6.535733699798584, 9.994582176208496, 6.6733222007751465, 5.551545143127441, 9.316335678100586, 9.443439483642578, 5.578766822814941, 10.41903018951416, 9.917499542236328, 1.245772123336792, 2.898033618927002, 2.1699397563934326, 2.337589740753174, 0.7485826015472412, 1.5108007192611694, 1.7716450691223145, 0.31812700629234314, 1.2159614562988281, 1.772817611694336, 5.758336067199707, 8.378059387207031, 5.376923084259033, 5.779482841491699, 9.090036392211914, 9.350667953491211, 5.344487190246582, 6.913998126983643, 4.474686622619629, 7.53315544128418, 2.5353710651397705, 2.8713605403900146, 4.065507888793945, 11.871132850646973, 0.8852859735488892, 2.939175605773926, 2.5275895595550537, 2.4267168045043945, 2.295419216156006, 2.1365015506744385, 7.037607669830322, 9.407532691955566, 3.222893714904785, 8.126129150390625, 4.200157165527344, 6.060004234313965, 7.009416103363037, 7.154573917388916, 7.831035137176514, 4.153042793273926, 12.525464057922363, -0.6069868803024292, 9.147096633911133, 5.2566022872924805, 3.595477819442749, -3.445817708969116, 3.8217902183532715, 7.362274646759033, 3.6554620265960693, 2.8430569171905518, 12.415096282958984, 12.156596183776855, -3.8546688556671143, -3.168445348739624, 11.602741241455078, -3.937896966934204, 6.970733165740967, -4.21811580657959, 11.855892181396484, -4.536736488342285, 1.6310545206069946, 4.332589626312256, 5.542863368988037, 2.8399806022644043, 3.993774890899658, 4.124382972717285, 2.336970329284668, 2.891779661178589, 5.163149356842041, 10.058012008666992, -0.4583301842212677, -0.8182825446128845, -0.5886291861534119, -0.6488580107688904, 0.36106470227241516, -1.382481336593628, 4.373441219329834, -1.0365768671035767, -0.49732324481010437, 4.83381986618042, 2.3331589698791504, 1.4693182706832886, 2.0713000297546387, 0.7031139731407166, 4.484761714935303, 9.712238311767578, 5.1782450675964355, 10.637614250183105, 5.904417991638184, 0.5843496918678284], \"yaxis\": \"y\"}],\n",
              "                        {\"coloraxis\": {\"colorbar\": {\"title\": {\"text\": \"binary\"}}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#f2f5fa\"}, \"error_y\": {\"color\": \"#f2f5fa\"}, \"marker\": {\"line\": {\"color\": \"rgb(17,17,17)\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"rgb(17,17,17)\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#A2B1C6\", \"gridcolor\": \"#506784\", \"linecolor\": \"#506784\", \"minorgridcolor\": \"#506784\", \"startlinecolor\": \"#A2B1C6\"}, \"baxis\": {\"endlinecolor\": \"#A2B1C6\", \"gridcolor\": \"#506784\", \"linecolor\": \"#506784\", \"minorgridcolor\": \"#506784\", \"startlinecolor\": \"#A2B1C6\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"line\": {\"color\": \"#283442\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"line\": {\"color\": \"#283442\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#506784\"}, \"line\": {\"color\": \"rgb(17,17,17)\"}}, \"header\": {\"fill\": {\"color\": \"#2a3f5f\"}, \"line\": {\"color\": \"rgb(17,17,17)\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#f2f5fa\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#f2f5fa\"}, \"geo\": {\"bgcolor\": \"rgb(17,17,17)\", \"lakecolor\": \"rgb(17,17,17)\", \"landcolor\": \"rgb(17,17,17)\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"#506784\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"dark\"}, \"paper_bgcolor\": \"rgb(17,17,17)\", \"plot_bgcolor\": \"rgb(17,17,17)\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"#506784\", \"linecolor\": \"#506784\", \"ticks\": \"\"}, \"bgcolor\": \"rgb(17,17,17)\", \"radialaxis\": {\"gridcolor\": \"#506784\", \"linecolor\": \"#506784\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"rgb(17,17,17)\", \"gridcolor\": \"#506784\", \"gridwidth\": 2, \"linecolor\": \"#506784\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"#C8D4E3\"}, \"yaxis\": {\"backgroundcolor\": \"rgb(17,17,17)\", \"gridcolor\": \"#506784\", \"gridwidth\": 2, \"linecolor\": \"#506784\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"#C8D4E3\"}, \"zaxis\": {\"backgroundcolor\": \"rgb(17,17,17)\", \"gridcolor\": \"#506784\", \"gridwidth\": 2, \"linecolor\": \"#506784\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"#C8D4E3\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#f2f5fa\"}}, \"sliderdefaults\": {\"bgcolor\": \"#C8D4E3\", \"bordercolor\": \"rgb(17,17,17)\", \"borderwidth\": 1, \"tickwidth\": 0}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"#506784\", \"linecolor\": \"#506784\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"#506784\", \"linecolor\": \"#506784\", \"ticks\": \"\"}, \"bgcolor\": \"rgb(17,17,17)\", \"caxis\": {\"gridcolor\": \"#506784\", \"linecolor\": \"#506784\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"updatemenudefaults\": {\"bgcolor\": \"#506784\", \"borderwidth\": 0}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"#283442\", \"linecolor\": \"#506784\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"#283442\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"#283442\", \"linecolor\": \"#506784\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"#283442\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Embedded by tSNE\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"X\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Y\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('187cfadd-df29-4277-b31a-f4dc0e7a141b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Dfig4 = go.Figure()\n",
        "fig4.add_trace(go.Bar(name='True labels', x=np.arange(10), y=test_labels_prop, marker_color='rgb(33, 75, 99)'))\n",
        "fig4.add_trace(go.Bar(name='Predicted labels Real CNN', x=np.arange(10), y=test_pred_prop, marker_color='rgb(79, 129, 102)'))\n",
        "fig4.add_trace(go.Bar(name='Predicted labels Real + Fake CNN', x=np.arange(10), y=test_pred_new_prop, marker_color= 'rgb(214, 39, 40)'))\n",
        "\n",
        "\n",
        "fig4.update_layout(\n",
        "    barmode='group',\n",
        "    title=\"CNN model trained on Fake + 10% Real\",\n",
        "    width=1200,\n",
        "    height=500,\n",
        "    xaxis = dict(\n",
        "        tickmode = 'array',\n",
        "        tickvals = [x for x in range(10)],\n",
        "        ticktext = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "    )\n",
        ")\n",
        "fig4.show()"
      ],
      "metadata": {
        "id": "7zUgkWl3Es8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Used on DCGAN\n",
        "def label_generated(how_many): \n",
        "  generated_labels = []\n",
        "  transform_back = transforms.Resize(28)\n",
        "\n",
        "  for i in range(how_many):\n",
        "    noise = Variable(Tensor(np.random.normal(0, 1, (32, opt.latent_dim))))\n",
        "    fake = generator(noise).detach().cpu()\n",
        "    image = fake.to(device)\n",
        "    transformed_image = transform_back(image)\n",
        "    prediction = model(transformed_image)\n",
        "    pred = prediction.argmax(dim=1, keepdim=True)\n",
        "    generated_labels += pred.squeeze(-1).cpu().numpy().tolist()\n",
        "\n",
        "  return generated_labels"
      ],
      "metadata": {
        "id": "yJ4UgUNKIn0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate = 2**11\n",
        "generated_labels = label_generated(generate)\n",
        "generated_freq = Counter(generated_labels).items()\n",
        "generated_freq = sorted(generated_freq)\n",
        "generated_freq = [x[1] for x in generated_freq]\n",
        "generated_prop = [x/(len(generated_labels)) for x in generated_freq]"
      ],
      "metadata": {
        "id": "s1h_2vQ3AT_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig2 = go.Figure()\n",
        "fig2.add_trace(go.Bar(name='Train Data', x=np.arange(10), y=count_train_freq, marker_color='rgb(33, 75, 99)'))\n",
        "fig2.add_trace(go.Bar(name='Test Data', x=np.arange(10), y=count_test_freq, marker_color='rgb(79, 129, 102)'))\n",
        "fig2.add_trace(go.Bar(name='Generated Data', x=np.arange(10), y=generated_freq, marker_color= 'rgb(214, 39, 40)'))\n",
        "\n",
        "\n",
        "fig2.update_layout(\n",
        "    barmode='group',\n",
        "    title=\"Frequency\",\n",
        "    width=1200,\n",
        "    height=500,\n",
        "    xaxis = dict(\n",
        "        tickmode = 'array',\n",
        "        tickvals = [x for x in range(10)],\n",
        "        ticktext = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "    )\n",
        ")\n",
        "fig2.show()"
      ],
      "metadata": {
        "id": "aEuqmbC-WmaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig3 = go.Figure()\n",
        "fig3.add_trace(go.Bar(name='Train Data', x=np.arange(10), y=count_train_prop, marker_color='rgb(33, 75, 99)'))\n",
        "fig3.add_trace(go.Bar(name='Test Data', x=np.arange(10), y=count_test_prop, marker_color='rgb(79, 129, 102)'))\n",
        "fig3.add_trace(go.Bar(name='Generated Data', x=np.arange(10), y=generated_prop, marker_color= 'rgb(214, 39, 40)'))\n",
        "\n",
        "fig3.update_layout(\n",
        "    barmode='group',\n",
        "    title=\"Ratio\",\n",
        "    width=1200,\n",
        "    height=500,\n",
        "    xaxis = dict(\n",
        "        tickmode = 'array',\n",
        "        tickvals = [x for x in range(10)],\n",
        "        ticktext = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "    )\n",
        ")\n",
        "fig3.show()"
      ],
      "metadata": {
        "id": "jRSF2VmPA0D7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noise = Variable(Tensor(np.random.normal(0, 1, (32, opt.latent_dim))))\n",
        "fake = generator(noise).detach().cpu()\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.subplot(1,2,2)\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(np.transpose(make_grid(fake[:2]),(1,2,0)))\n",
        "plt.show()\n",
        "image = fake.to(device)\n",
        "image.shape"
      ],
      "metadata": {
        "id": "HjKiJO7YIoIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_back = transforms.Resize(28)\n",
        "transformed_image = transform_back(image)\n",
        "transformed_image.shape"
      ],
      "metadata": {
        "id": "AKvo-tQap_Qd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "prediction = model(transformed_image)\n",
        "pred = prediction.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "print(f\"Predcited labels: {pred.squeeze(-1).cpu().numpy()}\")"
      ],
      "metadata": {
        "id": "N89Ny4uPRj3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(pred.squeeze(-1).cpu().numpy())"
      ],
      "metadata": {
        "id": "oWAH_ICNU56O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = [] + pred.squeeze(-1).cpu().numpy().tolist() + [100]\n",
        "len(x)"
      ],
      "metadata": {
        "id": "NJxfUbaGVPiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-LPyC3cUVSyf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}