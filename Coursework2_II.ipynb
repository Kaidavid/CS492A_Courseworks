{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Coursework2_II.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMsbFjeIUdOVzmE3ZBDFqk/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kaidavid/CS492A_Courseworks/blob/master/Coursework2_II.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/gdrive')\n",
        "root = '/gdrive/My Drive/CS492A/Courserwork2'"
      ],
      "metadata": {
        "id": "Ea5RUYbkblqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import plotly.graph_objects as go\n",
        "import matplotlib.pyplot as plt \n",
        "import plotly.express as px\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "from plotly.subplots import make_subplots\n",
        "from collections import Counter\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import make_grid\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.utils.data import DataLoader\n",
        "from easydict import EasyDict as edict"
      ],
      "metadata": {
        "id": "00SdPZRayIp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(470)\n",
        "torch.cuda.manual_seed(470)\n",
        "\n",
        "opt = edict()\n",
        "\n",
        "opt.n_epochs = 200\n",
        "opt.batch_size = 128\n",
        "opt.lr = 0.0002\n",
        "opt.b1 = 0.5\n",
        "opt.b2 = 0.999\n",
        "opt.n_cpu = 8\n",
        "opt.latent_dim = 100\n",
        "opt.img_size = 32\n",
        "opt.channels = 1\n",
        "opt.sample_interval = 400\n",
        "\n",
        "cuda = True if torch.cuda.is_available() else False"
      ],
      "metadata": {
        "id": "I4f0j9jukVkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "                                transforms.Resize(opt.img_size),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize([0.5], [0.5])\n",
        "                                ])\n",
        "\n",
        "train_dataset = MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Configure data loader\n",
        "train_loader = DataLoader(train_dataset, batch_size=opt.batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=opt.batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "yUryVOWBk-5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = []\n",
        "for _, label in train_dataset:\n",
        "    train_labels.append(label)\n",
        "test_labels = []\n",
        "for _, label in test_dataset:\n",
        "    test_labels.append(label)\n",
        "\n",
        "count_train_freq = Counter(train_labels).items()\n",
        "count_train_freq = sorted(count_train_freq)\n",
        "count_train_freq = [x[1] for x in count_train_freq]\n",
        "count_train_prop = [x/(len(train_labels)) for x in count_train_freq]\n",
        "\n",
        "count_test_freq = Counter(test_labels).items()\n",
        "count_test_freq = sorted(count_test_freq)\n",
        "count_test_freq = [x[1] for x in count_test_freq]\n",
        "count_test_prop = [x/(len(test_labels)) for x in count_test_freq]"
      ],
      "metadata": {
        "id": "PAHv3_vXPb8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig1 = make_subplots(rows=1, cols=2)\n",
        "fig1.append_trace(go.Bar(name='Train Data', x=np.arange(10), y=count_train_freq, marker_color='rgb(33, 75, 99)'), 1, 1)\n",
        "fig1.append_trace(go.Bar(name='Test Data', x=np.arange(10), y=count_test_freq, marker_color='rgb(79, 129, 102)'), 1, 1)\n",
        "fig1.append_trace(go.Bar(name='Train Data', x=np.arange(10), y=count_train_prop, marker_color='rgb(33, 75, 99)'), 1, 2)\n",
        "fig1.append_trace(go.Bar(name='Test Data', x=np.arange(10), y=count_test_prop, marker_color='rgb(79, 129, 102)'), 1, 2)\n",
        "\n",
        "fig1.update_layout(\n",
        "    barmode='group',\n",
        "    width=1200,\n",
        "    height=500,\n",
        "    xaxis = dict(\n",
        "        tickmode = 'array',\n",
        "        tickvals = [x for x in range(10)],\n",
        "        ticktext = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "    )\n",
        ")\n",
        "fig1.show()"
      ],
      "metadata": {
        "id": "QvFQnYW1M3C4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CNN**"
      ],
      "metadata": {
        "id": "gTBEikxFvFa7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = edict()\n",
        "args.batch_size = 64\n",
        "args.test_batch_size = 1000\n",
        "args.epochs = 14\n",
        "args.lr = 1.0\n",
        "args.gamma = 0.7\n",
        "args.dry_run = False\n",
        "args.log_interval = 10\n",
        "args.save_model = False\n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
        "train_kwargs = {'batch_size': args.batch_size}\n",
        "test_kwargs = {'batch_size': args.test_batch_size}\n",
        "\n",
        "if cuda:\n",
        "    cuda_kwargs = {'num_workers': 1,\n",
        "                    'pin_memory': True,\n",
        "                    'shuffle': True}\n",
        "    train_kwargs.update(cuda_kwargs)\n",
        "    test_kwargs.update(cuda_kwargs)\n",
        "\n",
        "\n",
        "transform_ = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "train_dataset_ = MNIST('../data', train=True, download=True, transform=transform_)\n",
        "test_dataset_ = MNIST('../data', train=False, download=True, transform=transform_)\n",
        "\n",
        "train_loader_ = torch.utils.data.DataLoader(train_dataset_, **train_kwargs)\n",
        "test_loader_ = torch.utils.data.DataLoader(test_dataset_, **test_kwargs)"
      ],
      "metadata": {
        "id": "BJT2_V1oGlF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1)\n",
        "    self.dropout1 = nn.Dropout(0.25)\n",
        "    self.dropout2 = nn.Dropout(0.5)\n",
        "    self.fc1 = nn.Linear(in_features=9216, out_features=128)\n",
        "    self.fc2 = nn.Linear(in_features=128, out_features=10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.conv2(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.max_pool2d(x, 2)\n",
        "    x = self.dropout1(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.dropout2(x)\n",
        "    x = self.fc2(x)\n",
        "    output = F.log_softmax(x, dim=1)\n",
        "    return output"
      ],
      "metadata": {
        "id": "UnCZjnxxvKig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(args, model, device, train_loader, optimizer, epoch):\n",
        "  model.train()\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    loss = F.nll_loss(output, target)\n",
        "    loss.backward(retain_graph=True)\n",
        "    optimizer.step()\n",
        "    if batch_idx % args.log_interval == 0:\n",
        "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "          epoch, batch_idx * len(data), len(train_loader),\n",
        "          100. * batch_idx / len(train_loader), loss.item()))\n",
        "      if args.dry_run:\n",
        "        break\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      output = model(data)\n",
        "      test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "      pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "      correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "\n",
        "  print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "      test_loss, correct, len(test_loader.dataset),\n",
        "      100. * correct / len(test_loader.dataset)))"
      ],
      "metadata": {
        "id": "NYOP-__HKUts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weights_init_noise(m):\n",
        "  classname = m.__class__.__name__\n",
        "  if classname.find(\"Conv\") != -1:\n",
        "      torch.nn.init.normal_(m.weight.data, 0.0, 1.0)\n",
        "  elif classname.find(\"BatchNorm2d\") != -1:\n",
        "      torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "      torch.nn.init.constant_(m.bias.data, 0.0)"
      ],
      "metadata": {
        "id": "Jn2CKKD2oiyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net().to(device)\n",
        "optimizer = torch.optim.Adadelta(model.parameters(), lr=args.lr)\n",
        "#model.apply(weights_init_noise)\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    train(args, model, device, train_loader_, optimizer, epoch)\n",
        "    test(model, device, test_loader_)\n",
        "    scheduler.step()\n",
        "\n",
        "if args.save_model:\n",
        "    torch.save(model.state_dict(), \"mnist_cnn.pt\")"
      ],
      "metadata": {
        "id": "Ek7Wosu6xxWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_images(loader, batch_id, how_many):\n",
        "  for batch_idx, (image, label) in enumerate(loader):\n",
        "    if batch_idx == batch_id:\n",
        "      actual_label = label[:how_many].numpy()      \n",
        "      plt.figure(figsize=(15,10))\n",
        "      plt.subplot(1,2,2)\n",
        "      plt.axis(\"off\")\n",
        "      plt.imshow(np.transpose(make_grid(image[:how_many]),(1,2,0)))\n",
        "      plt.show()\n",
        "      \n",
        "      image = image.to(device)\n",
        "      print(f\"Actual labels: {actual_label}\")\n",
        "      prediction = model(image[:how_many,:,:,:])\n",
        "      pred = prediction.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "      print(f\"Predcited labels: {pred.squeeze(-1).cpu().numpy()}\")\n",
        "      correct = pred.eq(torch.from_numpy(actual_label).to(device).view_as(pred)).sum().item()\n",
        "      print(f\"Number of correct classes: {correct}\")\n",
        "      break\n",
        "\n",
        "check_images(test_loader_, 0, 8)"
      ],
      "metadata": {
        "id": "xjz1Lc5D9dHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_accuracy(my_model):\n",
        "  test_labels = []\n",
        "  test_pred = []\n",
        "  total = 0\n",
        "  for batch_idx, (image, label) in enumerate(test_loader_):\n",
        "    test_labels += label.tolist()\n",
        "    image = image.to(device)\n",
        "    prediction = my_model(image)\n",
        "    pred = prediction.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "    test_pred += pred.squeeze(-1).tolist()\n",
        "    correct = pred.eq(label.to(device).view_as(pred)).sum().item()\n",
        "    total += correct\n",
        "  return test_labels, test_pred, total"
      ],
      "metadata": {
        "id": "ml48JaroYHu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **GAN**"
      ],
      "metadata": {
        "id": "zqndvQFcQwpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find(\"Conv\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find(\"BatchNorm2d\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        torch.nn.init.constant_(m.bias.data, 0.0)"
      ],
      "metadata": {
        "id": "GdrV4mszkf7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class cGenerator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(cGenerator, self).__init__()\n",
        "        \n",
        "        self.label_embedding = nn.Embedding(10, 10)\n",
        "        self.init_size = opt.img_size // 4\n",
        "        self.l1 = nn.Sequential(nn.Linear(opt.latent_dim + 10, 128 * self.init_size ** 2)) # 110 -> 8192\n",
        "\n",
        "        self.conv_blocks = nn.Sequential(\n",
        "            \n",
        "            #state size 128, 8, 8\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            \n",
        "            #state size 128, 16, 16\n",
        "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),           \n",
        "            nn.Upsample(scale_factor=2),\n",
        "            \n",
        "            #state size 128, 32, 32\n",
        "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            #state size 64, 32, 32\n",
        "            nn.Conv2d(64, opt.channels, 3, stride=1, padding=1),\n",
        "\n",
        "            #state size 1, 32, 32\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, z, labels):\n",
        "        z = torch.cat((self.label_embedding(labels), z), -1) #110\n",
        "        out = self.l1(z)  # B -> 110 to 110 -> 8192 = B -> 8192\n",
        "        out = out.view(out.shape[0], 128, self.init_size, self.init_size) # [B, 128, 8, 8]\n",
        "        img = self.conv_blocks(out)\n",
        "        return img"
      ],
      "metadata": {
        "id": "ryAB6pXH0vE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.init_size = opt.img_size // 4\n",
        "        self.l1 = nn.Sequential(nn.Linear(opt.latent_dim, 128 * self.init_size ** 2)) # 100 -> 8192\n",
        "\n",
        "        self.conv_blocks = nn.Sequential(\n",
        "            \n",
        "            #state size 128, 8, 8\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            \n",
        "            #state size 128, 16, 16\n",
        "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),           \n",
        "            nn.Upsample(scale_factor=2),\n",
        "            \n",
        "            #state size 128, 32, 32\n",
        "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            #state size 64, 32, 32\n",
        "            nn.Conv2d(64, opt.channels, 3, stride=1, padding=1),\n",
        "\n",
        "            #state size 1, 32, 32\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        out = self.l1(z)  # 32 -> 100 to 100 -> 8192 = 32 -> 8192\n",
        "        out = out.view(out.shape[0], 128, self.init_size, self.init_size) # [32, 128, 8, 8]\n",
        "        img = self.conv_blocks(out)\n",
        "        return img"
      ],
      "metadata": {
        "id": "uSCVGgVske6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class cDiscriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(cDiscriminator, self).__init__()\n",
        "\n",
        "        def discriminator_block(in_filters, out_filters, bn=True):\n",
        "          block = [nn.Conv2d(in_channels=in_filters, out_channels=out_filters, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "                   nn.LeakyReLU(0.2, inplace=True),\n",
        "                   nn.Dropout2d(0.25)]\n",
        "          if bn:\n",
        "            block = [nn.Conv2d(in_channels=in_filters, out_channels=out_filters, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "                     nn.BatchNorm2d(out_filters, 0.8),\n",
        "                     nn.LeakyReLU(0.2, inplace=True),\n",
        "                     nn.Dropout2d(0.25)]\n",
        "          return block\n",
        "        \n",
        "        self.label_embedding = nn.Embedding(10, 10)\n",
        "        self.linear = nn.Linear(10 + opt.img_size**2, opt.img_size**2)\n",
        "        self.model = nn.Sequential(\n",
        "            *discriminator_block(opt.channels, 16, bn=False),\n",
        "            *discriminator_block(16, 32),\n",
        "            *discriminator_block(32, 64),\n",
        "            *discriminator_block(64, 128),\n",
        "        )\n",
        "\n",
        "        # The height and width of downsampled image\n",
        "        ds_size = opt.img_size // 2 ** 4\n",
        "        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1), nn.Sigmoid())\n",
        "\n",
        "    def forward(self, img, labels):\n",
        "\n",
        "        img = torch.cat((img.view(img.size(0), -1), self.label_embedding(labels)), -1) # B,1*32*32 + B,10 = B,1034\n",
        "        img = self.linear(img)  # B, 1034 -> B, 1024\n",
        "        img = img.view(img.shape[0], opt.channels, opt.img_size, opt.img_size) # [B, 1, 32, 32]\n",
        "        out = self.model(img)\n",
        "        out = out.view(out.shape[0], -1)\n",
        "        validity = self.adv_layer(out)\n",
        "\n",
        "        return validity"
      ],
      "metadata": {
        "id": "jlMDSiF242V_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        def discriminator_block(in_filters, out_filters, bn=True):\n",
        "            block = [nn.Conv2d(in_channels=in_filters, out_channels=out_filters, kernel_size=4, stride=2, padding=1, bias=False), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n",
        "            if bn:\n",
        "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
        "            return block\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *discriminator_block(opt.channels, 16, bn=False),\n",
        "            *discriminator_block(16, 32),\n",
        "            *discriminator_block(32, 64),\n",
        "            *discriminator_block(64, 128),\n",
        "        )\n",
        "\n",
        "        # The height and width of downsampled image\n",
        "        ds_size = opt.img_size // 2 ** 4\n",
        "        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1), nn.Sigmoid())\n",
        "\n",
        "    def forward(self, img):\n",
        "        out = self.model(img)\n",
        "        out = out.view(out.shape[0], -1)\n",
        "        validity = self.adv_layer(out)\n",
        "\n",
        "        return validity"
      ],
      "metadata": {
        "id": "63S2Mu2Nki5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function\n",
        "adversarial_loss = torch.nn.BCELoss()\n",
        "\n",
        "# Initialize generator and discriminator\n",
        "generator = cGenerator()\n",
        "discriminator = cDiscriminator()\n",
        "\n",
        "if cuda:\n",
        "    generator.cuda()\n",
        "    discriminator.cuda()\n",
        "    adversarial_loss.cuda()\n",
        "\n",
        "# Initialize weights\n",
        "generator.apply(weights_init_normal)\n",
        "discriminator.apply(weights_init_normal)"
      ],
      "metadata": {
        "id": "1Ztk1cK1kwhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "\n",
        "FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
        "LongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor\n",
        "\n",
        "fixed_noise = Variable(FloatTensor(np.random.normal(0, 1, (1, opt.latent_dim))))\n",
        "fixed_label = Variable(LongTensor(np.random.randint(0, 10, 1)))"
      ],
      "metadata": {
        "id": "cGBdzug8k3Wp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------\n",
        "#  Training CGAN\n",
        "# ----------\n",
        "\n",
        "# Lists to keep track of progress\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "iters = 0\n",
        "\n",
        "for epoch in range(opt.n_epochs):\n",
        "    for i, (imgs, labels) in enumerate(train_loader):\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = Variable(FloatTensor(imgs.shape[0], 1).fill_(1.0), requires_grad=False)\n",
        "        fake = Variable(FloatTensor(imgs.shape[0], 1).fill_(0.0), requires_grad=False)\n",
        "\n",
        "        # Configure input\n",
        "        real_imgs = Variable(imgs.type(FloatTensor))\n",
        "        labels = Variable(labels.type(LongTensor))\n",
        "\n",
        "        # -----------------\n",
        "        #  Train Generator\n",
        "        # -----------------\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # Sample noise as generator input\n",
        "        z = Variable(FloatTensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim))))   # torch.Size([32, 100]\n",
        "        g_labels = Variable(LongTensor(np.random.randint(0, 10, imgs.shape[0])))\n",
        "\n",
        "        # Generate a batch of images\n",
        "        gen_imgs = generator(z, g_labels)\n",
        "\n",
        "        # Loss measures generator's ability to fool the discriminator\n",
        "        g_loss = adversarial_loss(discriminator(gen_imgs, g_labels), valid)\n",
        "\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # Measure discriminator's ability to classify real from generated samples\n",
        "        real_loss = adversarial_loss(discriminator(real_imgs, labels), valid)\n",
        "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach(), g_labels), fake)\n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "\n",
        "\n",
        "        # Output training stats\n",
        "        if i % 50 == 0:\n",
        "             print(\n",
        "              \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
        "              % (epoch, opt.n_epochs, i, len(train_loader), d_loss.item(), g_loss.item())\n",
        "              )\n",
        "\n",
        "        # Save Losses for plotting later\n",
        "        G_losses.append(g_loss.item())\n",
        "        D_losses.append(d_loss.item())\n",
        "\n",
        "        # Check how the generator is doing by saving G's output on fixed_noise\n",
        "        if (iters % 500 == 0) or ((epoch == opt.n_epochs-1) and (i == len(train_loader)-1)):\n",
        "            with torch.no_grad():\n",
        "                fake = generator(fixed_noise, fixed_label).detach().cpu()\n",
        "            img_list.append(make_grid(fake, padding=2, normalize=True)) #stored on every 500 epoch\n",
        "\n",
        "        iters += 1"
      ],
      "metadata": {
        "id": "C1u2LxAmA9KM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJlsr1UrbWK9"
      },
      "outputs": [],
      "source": [
        "  # ----------\n",
        "#  Training GAN\n",
        "# ----------\n",
        "\"\"\"\n",
        "# Lists to keep track of progress\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "iters = 0\n",
        "\n",
        "for epoch in range(opt.n_epochs):\n",
        "    for i, (imgs, _) in enumerate(train_loader):\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = Variable(FloatTensor(imgs.shape[0], 1).fill_(1.0), requires_grad=False)\n",
        "        fake = Variable(FloatTensor(imgs.shape[0], 1).fill_(0.0), requires_grad=False)\n",
        "\n",
        "        # Configure input\n",
        "        real_imgs = Variable(imgs.type(FloatTensor))\n",
        "\n",
        "        # -----------------\n",
        "        #  Train Generator\n",
        "        # -----------------\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # Sample noise as generator input\n",
        "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim))))   # torch.Size([32, 100]\n",
        "\n",
        "        # Generate a batch of images\n",
        "        gen_imgs = generator(z)\n",
        "\n",
        "        # Loss measures generator's ability to fool the discriminator\n",
        "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
        "\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # Measure discriminator's ability to classify real from generated samples\n",
        "        real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
        "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # Output training stats\n",
        "        if i % 50 == 0:\n",
        "             print(\n",
        "              \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
        "              % (epoch, opt.n_epochs, i, len(train_loader), d_loss.item(), g_loss.item())\n",
        "              )\n",
        "\n",
        "        # Save Losses for plotting later\n",
        "        G_losses.append(g_loss.item())\n",
        "        D_losses.append(d_loss.item())\n",
        "\n",
        "        # Check how the generator is doing by saving G's output on fixed_noise\n",
        "        if (iters % 500 == 0) or ((epoch == opt.n_epochs-1) and (i == len(train_loader)-1)):\n",
        "            with torch.no_grad():\n",
        "                fake = generator(fixed_noise).detach().cpu()\n",
        "            img_list.append(make_grid(fake, padding=2, normalize=True)) #stored on every 500 epoch\n",
        "\n",
        "        iters += 1\n",
        "\n",
        "\n",
        "For a batch of 128\n",
        "  60,000/ 128 = 469 batches\n",
        "Gradient descent occurs\n",
        "  469 * number of epoches = 93,800\n",
        "img_list is updated on every 500 epoch\n",
        "  93,800 / 500 = 187 = len(img_list)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"CGAN Generator and Discriminator Loss During Training\")\n",
        "plt.plot(G_losses,label=\"G\")\n",
        "plt.plot(D_losses,label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6j40IWWyGES2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grab a batch of real images from the dataloader\n",
        "\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and 1 > 0) else \"cpu\")\n",
        "real_batch = next(iter(train_loader))\n",
        "\n",
        "# Plot the real images\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.subplot(1,2,1)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Real Images\")\n",
        "plt.imshow(np.transpose(make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))"
      ],
      "metadata": {
        "id": "5iOIi_LpGHS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = enumerate(train_loader)\n",
        "batch_idx, (example_data, example_targets) = next(examples)\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.subplot(1,2,1)\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(np.transpose(make_grid(example_data.to(device)[0:2], padding=5, normalize=True).cpu(),(1,2,0)))"
      ],
      "metadata": {
        "id": "-A8CU2IiNB2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ , axes = plt.subplots(1, 5, figsize=(20, 8))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "  image = img_list[89+i]\n",
        "  ax.imshow(np.transpose(make_grid(image),(1,2,0)))\n",
        "  ax.set_yticklabels([])\n",
        "  ax.set_xticklabels([])"
      ],
      "metadata": {
        "id": "WC7kwtIfySEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = Variable(FloatTensor(np.random.normal(0, 1, (10**2, opt.latent_dim))))\n",
        "labels = np.array([num for _ in range(10) for num in range(10)])\n",
        "labels = Variable(LongTensor(labels))\n",
        "images = generator(z, labels)\n",
        "grid = make_grid(images, nrow=10, normalize=True)\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "ax.imshow(grid.permute(1, 2, 0).data.cpu(), cmap='binary')\n",
        "ax.axis('off')"
      ],
      "metadata": {
        "id": "aVB67itZcAUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Generate 1024 image for each class \n",
        "def cgan_accuracy():\n",
        "  all_labels = []\n",
        "  all_pred = []\n",
        "  total = 0\n",
        "  transform_back = transforms.Resize(28)\n",
        "\n",
        "  for j in range(10):\n",
        "    for i in range(1, 33):\n",
        "      z = Variable(FloatTensor(np.random.normal(0, 1, (32, opt.latent_dim))))\n",
        "      labels = np.array([j for _ in range(32)])\n",
        "      #labels = np.array([num for _ in range(5) for num in range(10)])\n",
        "      labels = Variable(LongTensor(labels))\n",
        "      all_labels += labels.cpu().tolist()\n",
        "      images = generator(z, labels)\n",
        "      transformed_image = transform_back(images)\n",
        "      prediction = model(transformed_image)\n",
        "      pred = prediction.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "      all_pred += pred.squeeze(-1).cpu().tolist()\n",
        "      correct = pred.eq(labels.view_as(pred)).sum().item()\n",
        "      total += correct\n",
        "  return all_labels, all_pred, total"
      ],
      "metadata": {
        "id": "J8hchew1kZl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels, test_pred, test_acc = model_accuracy(model)\n",
        "test_labels_freq = Counter(test_labels).items()\n",
        "test_labels_freq = sorted(test_labels_freq)\n",
        "test_labels_freq = [x[1] for x in test_labels_freq]\n",
        "test_labels_prop = [x/(len(test_labels)) for x in test_labels_freq]\n",
        "\n",
        "test_pred_freq = Counter(test_pred).items()\n",
        "test_pred_freq = sorted(test_pred_freq)\n",
        "test_pred_freq = [x[1] for x in test_pred_freq]\n",
        "test_pred_prop = [x/(len(test_pred)) for x in test_pred_freq]\n",
        "print(f\"Our CNN model accuracy: {test_acc/100}%\")"
      ],
      "metadata": {
        "id": "mYs6berD39dM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig2 = go.Figure()\n",
        "fig2.add_trace(go.Bar(name='True labels', x=np.arange(10), y=test_labels_prop, marker_color='rgb(33, 75, 99)'))\n",
        "fig2.add_trace(go.Bar(name='Predicted labels CNN', x=np.arange(10), y=test_pred_prop, marker_color='rgb(79, 129, 102)'))\n",
        "\n",
        "\n",
        "fig2.update_layout(\n",
        "    barmode='group',\n",
        "    title=\"Pre-trained CNN model\",\n",
        "    width=1200,\n",
        "    height=500,\n",
        "    xaxis = dict(\n",
        "        tickmode = 'array',\n",
        "        tickvals = [x for x in range(10)],\n",
        "        ticktext = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "    )\n",
        ")\n",
        "fig2.show()"
      ],
      "metadata": {
        "id": "GHowY0LZ4Blw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cgan_generated_labels, cgan_generated_pred, cgan_generated_acc = cgan_accuracy()\n",
        "\n",
        "cgan_generated_freq = Counter(cgan_generated_labels).items()\n",
        "cgan_generated_freq = sorted(cgan_generated_freq)\n",
        "cgan_generated_freq = [x[1] for x in cgan_generated_freq]\n",
        "cgan_generated_prop = [x/(len(cgan_generated_labels)) for x in cgan_generated_freq]\n",
        "\n",
        "cgan_generated_pred_freq = Counter(cgan_generated_pred).items()\n",
        "cgan_generated_pred_freq = sorted(cgan_generated_pred_freq)\n",
        "cgan_generated_pred_freq = [x[1] for x in cgan_generated_pred_freq]\n",
        "cgan_generated_pred_prop = [x/(len(cgan_generated_pred)) for x in cgan_generated_pred_freq]\n",
        "\n",
        "print(f\"Our CNN model accuracy on generated image: {cgan_generated_acc/100}%\")"
      ],
      "metadata": {
        "id": "Rc68KzLasSvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig3 = go.Figure()\n",
        "fig3.add_trace(go.Bar(name='Assigned labels', x=np.arange(10), y=cgan_generated_prop, marker_color='rgb(33, 75, 99)'))\n",
        "fig3.add_trace(go.Bar(name='Predicted labels CNN', x=np.arange(10), y=cgan_generated_pred_prop, marker_color='rgb(79, 129, 102)'))\n",
        "\n",
        "\n",
        "fig3.update_layout(\n",
        "    barmode='group',\n",
        "    title=\"CGAN Generated\",\n",
        "    width=1200,\n",
        "    height=500,\n",
        "    xaxis = dict(\n",
        "        tickmode = 'array',\n",
        "        tickvals = [x for x in range(10)],\n",
        "        ticktext = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "    )\n",
        ")\n",
        "fig3.show()"
      ],
      "metadata": {
        "id": "2N2-AQgdwmCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Generate 1024 image for each class \n",
        "def cgan_10000(size):\n",
        "  cgan_loader = []\n",
        "  transform_back = transforms.Resize(28)\n",
        "  for i in range(size):\n",
        "    z = Variable(FloatTensor(np.random.normal(0, 1, (args.batch_size, opt.latent_dim))))\n",
        "    labels = np.random.randint(0, 10, args.batch_size)\n",
        "    labels = Variable(LongTensor(labels))\n",
        "    images = generator(z, labels)\n",
        "    transformed_image = transform_back(images)\n",
        "    cgan_loader.append((transformed_image, labels))\n",
        "  return cgan_loader"
      ],
      "metadata": {
        "id": "8Ww-WfePCtwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "percent = 100\n",
        "cgan_loader = cgan_10000(20)\n",
        "# train_loader_new = cgan_loader + random.sample(list(train_loader_), int((percent/100)*(len(train_loader_))))\n",
        "# random.shuffle(train_loader_new)"
      ],
      "metadata": {
        "id": "4ROhjRMmJKhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train new CNN with generated + percentage of trian data\n",
        "model_new = Net().to(device)\n",
        "optimizer = torch.optim.Adadelta(model_new.parameters(), lr=args.lr)\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    train(args, model_new, device, train_loader_new, optimizer, epoch)\n",
        "    test(model_new, device, test_loader_)\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "id": "yffrAJ8dLm9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, test_pred_new, test_acc = model_accuracy(model_new)\n",
        "\n",
        "test_pred_new_freq = Counter(test_pred_new).items()\n",
        "test_pred_new_freq = sorted(test_pred_new_freq)\n",
        "test_pred_new_freq = [x[1] for x in test_pred_new_freq]\n",
        "test_pred_new_prop = [x/(len(test_pred_new)) for x in test_pred_new_freq]\n",
        "print(f\"Our CNN model accuracy with Real + Fake: {test_acc/100}%\")"
      ],
      "metadata": {
        "id": "3gdkx4Hyz9X_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = [95.27, 98.07, 98.61, 99.05, 99.03, 99.1]\n",
        "percent = [0, 10, 20, 50, 70, 100]"
      ],
      "metadata": {
        "id": "mRG7IKMx3ZVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig4 = go.Figure()\n",
        "fig4.add_trace(go.Scatter(x=percent, y=accuracy, mode=\"markers+lines\"))\n",
        "fig4.update_layout(title=\"6,400 Generated Images\")"
      ],
      "metadata": {
        "id": "-DWu07ii4e4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pick 100 images from each\n",
        "images_list = []\n",
        "labels_list = []\n",
        "for i in range(10):\n",
        "  images_l = []\n",
        "  labels_l = []\n",
        "  for batch_idx, (images, labels) in enumerate(train_loader_):\n",
        "    for j in range(labels.shape[0]):\n",
        "      if labels[j] == i:\n",
        "        images_l.append(images[j])\n",
        "        labels_l.append(i)\n",
        "        break\n",
        "    if len(images_l) == 10:\n",
        "      break\n",
        "  images_list += images_l\n",
        "  labels_list += labels_l\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "  images_l = []\n",
        "  labels_l = []\n",
        "  for batch_idx, (images, labels) in enumerate(cgan_loader):\n",
        "    for j in range(labels.shape[0]):\n",
        "      if labels[j] == i:\n",
        "        images_l.append(images[j])\n",
        "        labels_l.append(i)\n",
        "        break\n",
        "    if len(images_l) == 10:\n",
        "      break\n",
        "  images_list += images_l\n",
        "  labels_list += labels_l\n"
      ],
      "metadata": {
        "id": "3Lv6wU_390JU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = [x.view(1,-1).cpu() for x in images_list]\n",
        "labels_list2 = [int(x) for x in labels_list]\n",
        "X = torch.cat(X)\n",
        "X = X.detach().numpy()\n",
        "X_embedded = TSNE(n_components=2, learning_rate='auto', init='random').fit_transform(X)"
      ],
      "metadata": {
        "id": "Mz8m_7FVBX9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(X_embedded, columns=[\"dim1\", \"dim2\"])\n",
        "binary_1or0 = [0 for x in range(100)]\n",
        "binary_1or0 += [1 for x in range(100)]\n",
        "df[\"binary\"] = binary_1or0"
      ],
      "metadata": {
        "id": "70_NKwNCHHki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig5 = px.scatter(df, x=\"dim1\", y=\"dim2\", color=\"binary\")\n",
        "fig5.update_layout(title=\"Embedded by tSNE\",template=\"plotly_dark\")\n",
        "fig5.update_xaxes(title_text='X')\n",
        "fig5.update_yaxes(title_text='Y')\n",
        "fig5.show()"
      ],
      "metadata": {
        "id": "b9HUeqydISkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig6 = go.Figure()\n",
        "fig6.add_trace(go.Bar(name='True labels', x=np.arange(10), y=test_labels_prop, marker_color='rgb(33, 75, 99)'))\n",
        "fig6.add_trace(go.Bar(name='Predicted labels Real CNN', x=np.arange(10), y=test_pred_prop, marker_color='rgb(79, 129, 102)'))\n",
        "fig6.add_trace(go.Bar(name='Predicted labels Real + Fake CNN', x=np.arange(10), y=test_pred_new_prop, marker_color= 'rgb(214, 39, 40)'))\n",
        "\n",
        "\n",
        "fig6.update_layout(\n",
        "    barmode='group',\n",
        "    title=\"CNN model trained on Fake + 10% Real\",\n",
        "    width=1200,\n",
        "    height=500,\n",
        "    xaxis = dict(\n",
        "        tickmode = 'array',\n",
        "        tickvals = [x for x in range(10)],\n",
        "        ticktext = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "    )\n",
        ")\n",
        "fig6.show()"
      ],
      "metadata": {
        "id": "7zUgkWl3Es8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Used on DCGAN\n",
        "def label_generated(how_many): \n",
        "  generated_labels = []\n",
        "  transform_back = transforms.Resize(28)\n",
        "\n",
        "  for i in range(how_many):\n",
        "    noise = Variable(Tensor(np.random.normal(0, 1, (32, opt.latent_dim))))\n",
        "    fake = generator(noise).detach().cpu()\n",
        "    image = fake.to(device)\n",
        "    transformed_image = transform_back(image)\n",
        "    prediction = model(transformed_image)\n",
        "    pred = prediction.argmax(dim=1, keepdim=True)\n",
        "    generated_labels += pred.squeeze(-1).cpu().numpy().tolist()\n",
        "\n",
        "  return generated_labels"
      ],
      "metadata": {
        "id": "yJ4UgUNKIn0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate = 2**11\n",
        "generated_labels = label_generated(generate)\n",
        "generated_freq = Counter(generated_labels).items()\n",
        "generated_freq = sorted(generated_freq)\n",
        "generated_freq = [x[1] for x in generated_freq]\n",
        "generated_prop = [x/(len(generated_labels)) for x in generated_freq]"
      ],
      "metadata": {
        "id": "s1h_2vQ3AT_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig7 = go.Figure()\n",
        "fig7.add_trace(go.Bar(name='Train Data', x=np.arange(10), y=count_train_freq, marker_color='rgb(33, 75, 99)'))\n",
        "fig7.add_trace(go.Bar(name='Test Data', x=np.arange(10), y=count_test_freq, marker_color='rgb(79, 129, 102)'))\n",
        "fig7.add_trace(go.Bar(name='Generated Data', x=np.arange(10), y=generated_freq, marker_color= 'rgb(214, 39, 40)'))\n",
        "\n",
        "\n",
        "fig7.update_layout(\n",
        "    barmode='group',\n",
        "    title=\"Frequency\",\n",
        "    width=1200,\n",
        "    height=500,\n",
        "    xaxis = dict(\n",
        "        tickmode = 'array',\n",
        "        tickvals = [x for x in range(10)],\n",
        "        ticktext = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "    )\n",
        ")\n",
        "fig7.show()"
      ],
      "metadata": {
        "id": "aEuqmbC-WmaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig8 = go.Figure()\n",
        "fig8.add_trace(go.Bar(name='Train Data', x=np.arange(10), y=count_train_prop, marker_color='rgb(33, 75, 99)'))\n",
        "fig8.add_trace(go.Bar(name='Test Data', x=np.arange(10), y=count_test_prop, marker_color='rgb(79, 129, 102)'))\n",
        "fig8.add_trace(go.Bar(name='Generated Data', x=np.arange(10), y=generated_prop, marker_color= 'rgb(214, 39, 40)'))\n",
        "\n",
        "fig8.update_layout(\n",
        "    barmode='group',\n",
        "    title=\"Ratio\",\n",
        "    width=1200,\n",
        "    height=500,\n",
        "    xaxis = dict(\n",
        "        tickmode = 'array',\n",
        "        tickvals = [x for x in range(10)],\n",
        "        ticktext = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "    )\n",
        ")\n",
        "fig3.show()"
      ],
      "metadata": {
        "id": "jRSF2VmPA0D7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}